{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "pnWO37v6oLFg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown\n",
        "from functools import partial\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import spacy\n",
        "import ast\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    DEVICE = 'mps'  # Apple GPU 사용\n",
        "elif torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'  # NVIDIA GPU 사용\n",
        "else:\n",
        "    DEVICE = 'cpu'   # CPU fallback\n",
        "\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "iuol8CxrHQZC"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzpEEDthSnhi",
        "outputId": "3677fb2b-d313-4960-fa2a-f5932daa0af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 162899\n",
            "Dev data size: 1065\n",
            "Test data size: 1081\n",
            "\n",
            "Train data sample:\n",
            "                      Title  \\\n",
            "0       No-Bake Nut Cookies   \n",
            "1               Creamy Corn   \n",
            "2      Reeses Cups(Candy)     \n",
            "3  Cheeseburger Potato Soup   \n",
            "4       Rhubarb Coffee Cake   \n",
            "\n",
            "                                         Ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "2  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "3  [\"6 baking potatoes\", \"1 lb. of extra lean gro...   \n",
            "4  [\"1 1/2 c. sugar\", \"1/2 c. butter\", \"1 egg\", \"...   \n",
            "\n",
            "                                              Recipe  \n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...  \n",
            "1  [\"In a slow cooker, combine all ingredients. C...  \n",
            "2  [\"Combine first four ingredients and press in ...  \n",
            "3  [\"Wash potatoes; prick several times with a fo...  \n",
            "4  [\"Cream sugar and butter.\", \"Add egg and beat ...  \n"
          ]
        }
      ],
      "source": [
        "# data 다운\n",
        "train_path = 'Cooking_Dataset/train.csv'\n",
        "dev_path = 'Cooking_Dataset/dev.csv'\n",
        "test_path = 'Cooking_Dataset/test.csv'\n",
        "\n",
        "\n",
        "if not os.path.exists('Cooking_Dataset'):\n",
        "    os.makedirs('Cooking_Dataset')\n",
        "    print(\"Downloading Dataset\")\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1uZdYjvllt0dSdKKtrCgKHUk-APKdmeNU\", train_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1SAMbkdtjGBYgojqobiwe7ZmnEq7SiGsF\", dev_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1v6Rr2et_4WA5mRwwlRxtLhn38pbmr9Yr\", test_path, quiet=False)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "dev_df = pd.read_csv(dev_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Dev data size: {len(dev_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")\n",
        "print(\"\\nTrain data sample:\")\n",
        "print(train_df.head())\n",
        "#No-Bake Nut Cookies\n",
        "# [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n",
        "# [\"In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\", \"Stir over medium heat until mixture bubbles all over top.\", \"Boil and stir 5 minutes more. Take off heat.\", \"Stir in vanilla and cereal; mix well.\", \"Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\", \"Let stand until firm, about 30 minutes.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQwUvtETjCF",
        "outputId": "86b57a8d-0dd5-4fa7-abdf-0d96cb367749"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenizer_ingredient_baseline(text):\n",
        "    \"\"\"\n",
        "    Baseline 전처리: 소문자화 + lemmatization + 간단한 필터링\n",
        "    - stopword 제거 있음\n",
        "    - 숫자, 구두점 제거 있음\n",
        "    - 불필요한 복잡 전처리 없음\n",
        "    \"\"\"\n",
        "    import ast\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.like_num or token.is_stop:\n",
        "                    continue\n",
        "                tokens.append(token.lemma_.strip())  # 기본 lemmatization만 유지\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_recipe_baseline(text):\n",
        "    \"\"\"\n",
        "    Recipe 전처리: 소문자화 + lemmatization만 수행 (구두점, stopword, 숫자는 유지)\n",
        "    - 조리 순서, 동사 등 자연스러운 문장 흐름을 보존해야 하므로 간단한 전처리만 적용\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        doc = spacy_en(text.lower())\n",
        "        for token in doc:\n",
        "            # 너무 공격적인 필터링은 하지 않음\n",
        "            if token.is_space:\n",
        "                continue\n",
        "            tokens.append(token.lemma_.strip())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_ingredient_extension(text, remove_stopwords=True, lemmatize=True):\n",
        "    text_list = ast.literal_eval(text)  # 문자열 → 리스트로 변환\n",
        "    unit_keywords = {\n",
        "        'c', 'cup', 'cups', 'tbsp', 'tablespoon', 'tsp', 'teaspoon',\n",
        "        'oz', 'ounce', 'lb', 'pound', 'g', 'kg', 'mg',\n",
        "        'pt', 'qt', 'gal', 'ml', 'l',\n",
        "        'package', 'pkg', 'envelope', 'box', 'bag', 'jar', 'can', 'cans', 'bottle',\n",
        "        'dash', 'pinch', 'slice', 'slices', 'head', 'inch', 'inches',\n",
        "        'stick', 'sticks', 'small', 'medium', 'large'\n",
        "    }\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue\n",
        "                if token.like_num:\n",
        "                    continue\n",
        "                if token.text.strip(\".\") in unit_keywords:\n",
        "                    continue\n",
        "                if remove_stopwords and token.is_stop:\n",
        "                    continue\n",
        "                if token.pos_ != \"NOUN\":  # 명사만\n",
        "                    continue\n",
        "\n",
        "                tokens.append(token.lemma_.strip() if lemmatize else token.text.strip())\n",
        "    return tokens\n",
        "\n",
        "def tokenizer_recipe_extension(text):  # 디폴트: lemmatize 안 함\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    # tagger는 유지해서 lemma 써도 warning 없음\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())  # 소문자화\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue  # 마침표, 쉼표 제거\n",
        "                if token.like_num:  # 숫자 유지\n",
        "                    tokens.append(token.text.strip())\n",
        "                    continue\n",
        "                \n",
        "                tokens.append(token.text.strip())\n",
        "                \n",
        "    return tokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"In a slow cooker, combine all ingredients. Cover and cook on low for 4 hours or until heated through and cheese is melted. Stir well before serving. Yields 6 servings.\"]\n",
            "['in', 'a', 'slow', 'cooker', 'combine', 'all', 'ingredients', 'cover', 'and', 'cook', 'on', 'low', 'for', '4', 'hours', 'or', 'until', 'heated', 'through', 'and', 'cheese', 'is', 'melted', 'stir', 'well', 'before', 'serving', 'yields', '6', 'servings']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "ing = train_df.iloc[1,2]\n",
        "print(ing)\n",
        "print(tokenizer_recipe_extension(ing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "O5IrjwMXuv3h"
      },
      "outputs": [],
      "source": [
        "def build_vocab(token_lists, min_freq=2):\n",
        "    # vocab 생성: 자주 등장하는 단어만 포함 + 특수 토큰 정의\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        token_lists,  # 토큰 리스트들을 직접 반복\n",
        "        min_freq=min_freq,  # 최소 등장 빈도\n",
        "        specials=['<pad>', '<sos>', '<eos>', '<unk>']  # 특수 토큰 추가\n",
        "    )\n",
        "    vocab.set_default_index(vocab['<unk>'])  # 없는 단어는 <unk>로 처리\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_or_tokenize_data(model_type, train_df):\n",
        "    if \"extension\" in model_type:\n",
        "        tokenizer_ingredient = tokenizer_ingredient_extension\n",
        "        tokenizer_recipe = tokenizer_recipe_extension\n",
        "        ingredient_cache_path = \"tokens/ingredient_tokens_ext.pkl\"\n",
        "        recipe_cache_path = \"tokens/recipe_tokens_ext.pkl\"\n",
        "        ingredient_cache_download = \"https://drive.google.com/uc?id=1uXHVNptWeQgkv0uSRLaKYF1SFpcng5cF\"\n",
        "        recipe_cache_dowload = \"https://drive.google.com/uc?id=1qXrpx_nxt8p-ErDPq5w4AkrqNahHki_o\"\n",
        "    else:\n",
        "        tokenizer_ingredient = tokenizer_ingredient_baseline\n",
        "        tokenizer_recipe = tokenizer_recipe_baseline\n",
        "        ingredient_cache_path = \"tokens/ingredient_tokens.pkl\"\n",
        "        recipe_cache_path = \"tokens/recipe_tokens.pkl\"\n",
        "        ingredient_cache_download = \"https://drive.google.com/uc?id=...\"\n",
        "        recipe_cache_dowload = \"https://drive.google.com/uc?id=...\"\n",
        "\n",
        "    if not os.path.exists('tokens'):\n",
        "        os.makedirs('tokens')\n",
        "        gdown.download(ingredient_cache_download, ingredient_cache_path, quiet=False)\n",
        "        gdown.download(recipe_cache_dowload, recipe_cache_path, quiet=False)\n",
        "\n",
        "    try:\n",
        "        with open(ingredient_cache_path, \"rb\") as f:\n",
        "            ingredient_token_lists = pickle.load(f)\n",
        "        with open(recipe_cache_path, \"rb\") as f:\n",
        "            recipe_token_lists = pickle.load(f)\n",
        "        print(\"✅ Loaded token cache.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ No cache → Tokenizing...\")\n",
        "        ingredient_token_lists = [tokenizer_ingredient(text) for text in tqdm(train_df['Ingredients'], desc=\"Tokenizing ingredients\")]\n",
        "        recipe_token_lists = [tokenizer_recipe(text) for text in tqdm(train_df['Recipe'], desc=\"Tokenizing recipes\")]\n",
        "        with open(ingredient_cache_path, \"wb\") as f:\n",
        "            pickle.dump(ingredient_token_lists, f)\n",
        "        with open(recipe_cache_path, \"wb\") as f:\n",
        "            pickle.dump(recipe_token_lists, f)\n",
        "\n",
        "    ingredient_vocab = build_vocab(ingredient_token_lists, min_freq=1)\n",
        "    recipe_vocab = build_vocab(recipe_token_lists)\n",
        "    return ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "u3aRuH1BcoQQ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, ingredient_vocab, recipe_vocab,\n",
        "                 tokenizer_ingredient, tokenizer_recipe):\n",
        "        self.df = df\n",
        "        self.ingredient_vocab = ingredient_vocab\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "        self.tokenizer_ingredient = tokenizer_ingredient\n",
        "        self.tokenizer_recipe = tokenizer_recipe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ingredient_tokens = self.tokenizer_ingredient(self.df.iloc[idx][\"Ingredients\"])\n",
        "        recipe_tokens = self.tokenizer_recipe(self.df.iloc[idx][\"Recipe\"])\n",
        "\n",
        "        ingredient_ids = [self.ingredient_vocab[token] for token in ingredient_tokens]\n",
        "        recipe_ids = [self.recipe_vocab['<sos>']] + \\\n",
        "                     [self.recipe_vocab[token] for token in recipe_tokens] + \\\n",
        "                     [self.recipe_vocab['<eos>']]\n",
        "\n",
        "        return torch.tensor(ingredient_ids), torch.tensor(recipe_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "zvtpEXhJyzRN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, ingredient_vocab, recipe_vocab, device):\n",
        "    ingredients, recipes = zip(*batch)\n",
        "    ingredients_padded = pad_sequence(ingredients, batch_first=True, padding_value=ingredient_vocab['<pad>'])\n",
        "    recipes_padded = pad_sequence(recipes, batch_first=True, padding_value=recipe_vocab['<pad>'])\n",
        "    return ingredients_padded.to(device), recipes_padded.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "ZHuvOqpGoe5N"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        # 임베딩\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        \n",
        "\n",
        "        # GRU 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src : [batch_size, src_len]\n",
        "        src = src.long() \n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded : [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # gru 통과\n",
        "        outputs, hidden = self.gru(embedded) # h0를 따로 주지 않으면, 디폴트로 h0가 0로 초기화되서 들어감\n",
        "        # outputs: [batch_size, src_len, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        return outputs,hidden\n",
        "\n",
        "class Decoder_GRU(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "\n",
        "        # 임베딩\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # fc 레이어\n",
        "        self.fc_out = nn.Linear(hidden_dim, recipe_vocab_size)\n",
        "\n",
        "        # 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.long()\n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, 단어의 개수=1]\n",
        "\n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, 단어의 개수=1, hidden_dim]\n",
        "\n",
        "        # GRU 통과\n",
        "        outputs, hidden = self.gru(embedded,hidden)\n",
        "        # outputs: [batch_size, 단어의 개수=1, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        # fc 통과\n",
        "        prediction = self.fc_out(outputs.squeeze(1))\n",
        "        # prediction: [batch_size, vocab_size]\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, use_attention):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "    def forward(self, src, target=None, teacher_forcing_ratio=0.5, max_len=50):\n",
        "        # 인코더\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        batch_size = src.size(0)\n",
        "        vocab_size = self.decoder.recipe_vocab_size\n",
        "\n",
        "        # 추론 모드\n",
        "        if target is None:\n",
        "            outputs = []\n",
        "            input_token = torch.tensor([recipe_vocab['<sos>']] * batch_size).to(self.device).long()\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                if self.use_attention:\n",
        "                    output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                else:\n",
        "                    output, hidden = self.decoder(input_token, hidden)\n",
        "                top1 = output.argmax(1)\n",
        "                outputs.append(top1.unsqueeze(1))\n",
        "                input_token = top1\n",
        "\n",
        "            return torch.cat(outputs, dim=1)  # [batch_size, max_len]\n",
        "\n",
        "        # 학습 모드\n",
        "        target = target.long()\n",
        "        target_len = target.shape[1]\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
        "        input_token = target[:, 0].long()  # <sos>\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            if self.use_attention:\n",
        "                output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            else:\n",
        "                output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:, t, :] = output\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input_token = target[:, t].long() if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "import torch.nn.functional as F\n",
        "    \n",
        "\n",
        "# Define a decoder with attention mechanism using PyTorch's nn.Module\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size,embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        # Initialize the base nn.Module class\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Save parameters\n",
        "        self.recipe_vocab_size = recipe_vocab_size              # Size of the output vocabulary\n",
        "        self.embedding_dim = embedding_dim                  # Dropout probability\n",
        "        self.hidden_size = hidden_size              # Size of the hidden state in GRU\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "                  \n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(self.recipe_vocab_size, self.hidden_size)  # Converts word indices to dense vectors\n",
        "        self.dropout = nn.Dropout(self.dropout_ratio)                          # Applies dropout for regularization\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.n_layers, dropout=self.dropout_ratio if self.n_layers>1 else 0, batch_first=True)\n",
        "             # GRU to process the embedded inputs\n",
        "        self.out = nn.Linear(self.hidden_size * 2, self.recipe_vocab_size)       # Linear layer for generating final output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.long() \n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, 단어의 개수=1]\n",
        "\n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, 단어의 개수=1, hidden_dim]\n",
        "\n",
        "        # Pass through GRU\n",
        "        output, hidden = self.gru(embedded, hidden)  # output: [batch, 1, hidden_size]\n",
        "\n",
        "        # Compute attention weights using dot-product attention:\n",
        "        # hidden[-1]: [batch, hidden_size]\n",
        "        # encoder_outputs: [batch, src_len, hidden_size]\n",
        "    \n",
        "        attn_weights = F.softmax(\n",
        "            torch.bmm(output, encoder_outputs.transpose(1, 2)), # [batch, 1, hidden_size] x [batch, hidden_size, src_len]\n",
        "            dim=-1\n",
        "        )  # [batch, 1, src_len]\n",
        "\n",
        "        # Apply attention weights to encoder outputs to get context vector\n",
        "        # attn_weights: (1, 1, max_length)\n",
        "        # encoder_outputs.unsqueeze(0): (1, max_length, hidden_size)\n",
        "        attn_output = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, hidden_size]\n",
        "\n",
        "        # Concatenate attention output and decoder hidden state\n",
        "        concat_output = torch.cat((output, attn_output), dim=2)  # [batch, 1, hidden*2]\n",
        "\n",
        "        # Pass through linear layer and softmax to get output word probabilities\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)  # [batch, vocab_size]\n",
        "\n",
        "        # Return output word distribution, updated hidden state, and attention weights\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_glove_embedding_matrix(glove_path, vocab, glove_dim=100):\n",
        "    print(\"🔎 Loading GloVe vectors...\")\n",
        "    glove_embeddings = {}\n",
        "\n",
        "    with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = torch.tensor(list(map(float, values[1:])))\n",
        "            glove_embeddings[word] = vector\n",
        "\n",
        "    # Initialize matrix with random vectors\n",
        "    embedding_matrix = torch.randn(len(vocab), glove_dim)\n",
        "\n",
        "    for word, idx in vocab.get_stoi().items():\n",
        "        if word in glove_embeddings:\n",
        "            embedding_matrix[idx] = glove_embeddings[word]\n",
        "\n",
        "    print(\"✅ GloVe embedding matrix created.\")\n",
        "    return embedding_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_epoch(model, dataloader, criterion, optimizer=None, teacher_forcing_ratio=0.5, max_len=50):\n",
        "    rloss = 0\n",
        "    batch_losses = []\n",
        "    \n",
        "\n",
        "    for i, (src_batch, trg_batch) in enumerate(tqdm(dataloader, desc=\"Training batches\", leave=False)):\n",
        "        src_batch = src_batch.to(DEVICE)\n",
        "        trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "        output = model(src_batch, trg_batch, teacher_forcing_ratio=teacher_forcing_ratio, max_len=max_len)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item() * src_batch.size(0)\n",
        "        batch_losses.append(batch_loss)\n",
        "        rloss += batch_loss\n",
        "        \n",
        "\n",
        "        tqdm.write(f\"[Batch {i+1}/{len(dataloader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = rloss / len(dataloader.dataset)\n",
        "    return avg_loss, batch_losses\n",
        "\n",
        "\n",
        "def Train(model, train_loader, val_loader, criterion, optimizer,\n",
        "          EPOCHS, BATCH_SIZE, TRAIN_RATIO,\n",
        "          save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs\n",
        "          ):\n",
        "    \"\"\"\n",
        "    이어서 학습할 수 있게 start_epoch와 best_val_loss를 인자로 받음\n",
        "    \"\"\"\n",
        "    if \"LR_STEP\" in kwargs:\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=kwargs[\"LR_STEP\"], gamma=kwargs[\"LR_GAMMA\"])\n",
        "    else:\n",
        "        scheduler = None\n",
        "    loss_history = {\"train_epoch\": [], \"train_iter\": [], \"val_epoch\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    train_start_time = time.time()\n",
        "    \n",
        "    for ep in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "        print(f\"Epoch {ep+1}/{EPOCHS}\")\n",
        "\n",
        "        ep_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_epoch_loss, train_batch_loss= loss_epoch(\n",
        "            model, train_loader, criterion, optimizer, \n",
        "            teacher_forcing_ratio=TEACHER_FORCING_RATIO,\n",
        "            max_len=MAX_LEN\n",
        "        )\n",
        "        loss_history[\"train_epoch\"].append(train_epoch_loss)\n",
        "        loss_history[\"train_iter\"].append(train_batch_loss)\n",
        "        \n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, _ = loss_epoch(\n",
        "                model, val_loader, criterion, optimizer=None,\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                max_len=MAX_LEN\n",
        "            )\n",
        "            loss_history[\"val_epoch\"].append(val_loss)\n",
        "\n",
        "        ep_elapsed_time = time.time() - ep_start_time\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            # 디렉토리 없으면 생성\n",
        "            os.makedirs(\"results\", exist_ok=True)\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": ep,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"train_loss\": train_epoch_loss,  # train_loss 저장\n",
        "            }, save_model_path)\n",
        "            print(\"Best model saved!\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {ep_elapsed_time:.2f}s\")\n",
        "    train_elapsed_time = time.time() - train_start_time\n",
        "    # Save training history\n",
        "    total_iterations = sum(len(batch_list) for batch_list in loss_history[\"train_iter\"])\n",
        "    torch.save({\n",
        "        \"loss_history\": loss_history,\n",
        "        \"EPOCHS\": EPOCHS,\n",
        "        \"BATCH_SIZE\": BATCH_SIZE,   \n",
        "        \"TRAIN_RATIO\": TRAIN_RATIO,\n",
        "        \"train_elapsed_time\": train_elapsed_time,\n",
        "        \"total_iterations\": total_iterations,\n",
        "        \"LR_STEP\": kwargs[\"LR_STEP\"] if \"LR_STEP\" in kwargs else None,\n",
        "        \"LR_GAMMA\": kwargs[\"LR_GAMMA\"] if \"LR_GAMMA\" in kwargs else None\n",
        "    }, save_history_path)\n",
        "    print(f\"Total number of iteration : {total_iterations}\")\n",
        "    print(f\"Training Completed! Total Time: {train_elapsed_time:.2f}s\")\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "\n",
        "def Test(model, test_loader, criterion, recipe_vocab, MAX_LEN):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss, _ = loss_epoch(model, test_loader, criterion, optimizer=None, teacher_forcing_ratio=0.0, max_len=MAX_LEN)\n",
        "\n",
        "    # 평가 지표 계산\n",
        "    bleu_score, meteor_avg, bertscore_f1 = compute_metrics(model, test_loader, recipe_vocab)\n",
        "\n",
        "    print(f\"Test Loss      : {test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score   : {bleu_score:.4f}\")\n",
        "    print(f\"METEOR Score   : {meteor_avg:.4f}\")\n",
        "    print(f\"BERTScore (F1) : {bertscore_f1:.4f}\")\n",
        "\n",
        "    return test_loss, bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(model, dataloader, recipe_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    테스트셋 전체에서 BLEU, METEOR, BERTScore 계산\n",
        "\n",
        "    Returns:\n",
        "        bleu_score (float), meteor_avg (float), bertscore_f1 (float)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    ref_list = []\n",
        "    hyp_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, trg_batch in tqdm(dataloader, desc=\"Evaluating Metrics\"):\n",
        "            src_batch = src_batch.to(DEVICE)\n",
        "            trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "            generated = model(src_batch, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "\n",
        "            for i in range(src_batch.size(0)):\n",
        "                pred_tokens = generated[i].tolist()\n",
        "                trg_tokens = trg_batch[i].tolist()\n",
        "\n",
        "                # <eos> 기준으로 자르기\n",
        "                if recipe_vocab['<eos>'] in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[:pred_tokens.index(recipe_vocab['<eos>'])]\n",
        "                if recipe_vocab['<eos>'] in trg_tokens:\n",
        "                    trg_tokens = trg_tokens[:trg_tokens.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "                pred_words = [recipe_vocab.get_itos()[idx] for idx in pred_tokens]\n",
        "                trg_words = [recipe_vocab.get_itos()[idx] for idx in trg_tokens]\n",
        "\n",
        "                ref_list.append(trg_words)\n",
        "                hyp_list.append(pred_words)\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_score = corpus_bleu([[ref] for ref in ref_list], hyp_list, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie) \n",
        "\n",
        "    # METEOR\n",
        "    meteor_scores = [meteor_score([ref], hyp) for ref, hyp in zip(ref_list, hyp_list)]\n",
        "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "    # BERTScore\n",
        "    refs = [\" \".join(ref) for ref in ref_list]\n",
        "    hyps = [\" \".join(hyp) for hyp in hyp_list]\n",
        "    _, _, f1 = bert_score_fn(hyps, refs, lang='en', verbose=False)\n",
        "    bertscore_f1 = f1.mean().item()\n",
        "\n",
        "    return bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "def plot_loss_epoch(name, loss_history):\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    train_loss = loss_history[\"train_epoch\"]\n",
        "    val_loss = loss_history[\"val_epoch\"]\n",
        "\n",
        "    plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(range(1, len(val_loss) + 1), val_loss, label=\"Validation Loss\", color=\"red\")\n",
        "\n",
        "    plt.xlabel(\"Epoch\", fontsize=10)\n",
        "    plt.ylabel(\"Loss\", fontsize=10)\n",
        "    plt.title(f\"Loss per Epoch: {name}\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss_iter(**models_histories):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for model_name, history in models_histories.items():\n",
        "        train_iter_losses = history.get(\"train_iter\", [])\n",
        "        if train_iter_losses:\n",
        "            flat_iter_losses = [loss for epoch_losses in train_iter_losses for loss in epoch_losses]\n",
        "            plt.plot(flat_iter_losses, label=model_name)\n",
        "        else:\n",
        "            print(f\"[경고] {model_name}에 train_iter 데이터가 없습니다.\")\n",
        "\n",
        "    plt.title(\"Training Iteration Loss\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(model_type: str, config: dict,\n",
        "         train_df, dev_df, test_df,\n",
        "         glove_path: str = \"./glove.6B.100d.txt\"):\n",
        "\n",
        "    # 1. Tokenize & Vocab\n",
        "    ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe = load_or_tokenize_data(model_type, train_df)\n",
        "\n",
        "    # 2. GloVe embedding 적용 (config에 \"embedding_weights\" 키가 있는 경우)\n",
        "    embedding_weights = None\n",
        "    freeze_embedding = False\n",
        "    if config.get(\"use_glove\", False):\n",
        "        ingredient_embedding_matrix = build_glove_embedding_matrix(glove_path, ingredient_vocab, glove_dim=config[\"EMBED_DIM\"])\n",
        "        embedding_weights = ingredient_embedding_matrix\n",
        "    else:\n",
        "        embedding_weights = None\n",
        "\n",
        "    # 3. Dataset & DataLoader\n",
        "    BATCH_SIZE = config.get(\"BATCH_SIZE\", 64)\n",
        "    train_dataset = CustomDataset(train_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    dev_dataset = CustomDataset(dev_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    test_dataset = CustomDataset(test_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "\n",
        "    collate = partial(collate_fn, ingredient_vocab=ingredient_vocab, recipe_vocab=recipe_vocab, device=DEVICE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, collate_fn=collate)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate)\n",
        "\n",
        "    # 4. Model 구성\n",
        "    INPUT_DIM = len(ingredient_vocab)\n",
        "    OUTPUT_DIM = len(recipe_vocab)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "\n",
        "    encoder = Encoder_GRU(\n",
        "        ingredient_vocab_size=INPUT_DIM,\n",
        "        embedding_dim=config[\"EMBED_DIM\"],\n",
        "        hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "        n_layers=config[\"N_LAYERS\"],\n",
        "        dropout_ratio=config[\"DROPOUT\"],\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze=freeze_embedding\n",
        "    )\n",
        "\n",
        "    if config[\"USE_ATTENTION\"]:\n",
        "        decoder = AttnDecoderRNN(\n",
        "            recipe_vocab_size=OUTPUT_DIM,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_size=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"]\n",
        "        )\n",
        "    else:\n",
        "        decoder = Decoder_GRU(\n",
        "            recipe_vocab_size=OUTPUT_DIM,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"]\n",
        "        )\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "\n",
        "    # 5. 학습 또는 로드\n",
        "    save_model_path = f\"results/{model_type}.pt\"\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    if config[\"new_model_train\"]:\n",
        "        print(f\"Training model: {model_type}\")\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n",
        "        loss_history = Train(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=dev_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            EPOCHS=config[\"EPOCHS\"],\n",
        "            BATCH_SIZE=BATCH_SIZE,\n",
        "            TRAIN_RATIO=1.0,\n",
        "            save_model_path=save_model_path,\n",
        "            save_history_path=save_history_path,\n",
        "            TEACHER_FORCING_RATIO=config[\"TEACHER_FORCING_RATIO\"],\n",
        "            MAX_LEN=config[\"MAX_LEN\"],\n",
        "            LR_STEP=config.get(\"LR_STEP\"),\n",
        "            LR_GAMMA=config.get(\"LR_GAMMA\")\n",
        "        )\n",
        "        return model, encoder, decoder, loss_history, save_model_path, save_history_path, test_loader, recipe_vocab\n",
        "    else:\n",
        "        return model, encoder, decoder, None, save_model_path, save_history_path, test_loader, recipe_vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 저장\n",
        "experiment_configs = {\n",
        "    \"baseline1\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": False,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.7,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"baseline2\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.7,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"mild_extension1\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 256,\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 3,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.7,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"mild_extension2\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 100,  # GloVe 6B 100D와 일치\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 3,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.7,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"use_glove\": True,   \n",
        "        \"freeze_embedding\": False,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def evaluate_and_report(model_type, config, encoder, decoder, save_model_path, save_history_path,\n",
        "                        test_loader, criterion, recipe_vocab):\n",
        "    if not os.path.exists(save_model_path) or not os.path.exists(save_history_path):\n",
        "        print(f\"⚠️ Checkpoint for {model_type} not found. Skipping evaluation.\\n\")\n",
        "        return\n",
        "\n",
        "    # 1. 모델 불러오기\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "    checkpoint = torch.load(save_model_path, map_location=DEVICE)\n",
        "    checkpoint2 = torch.load(save_history_path, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    # 2. 학습 정보 출력\n",
        "    best_epoch = checkpoint[\"epoch\"] + 1\n",
        "    best_train_loss = checkpoint[\"train_loss\"]\n",
        "    best_val_loss = checkpoint[\"val_loss\"]\n",
        "    train_elapsed_time = checkpoint2[\"train_elapsed_time\"]\n",
        "    total_iterations = checkpoint2[\"total_iterations\"]\n",
        "    print(f\"📌 {model_type} | Epoch {best_epoch} | Train Loss: {best_train_loss:.4f} | Val Loss: {best_val_loss:.4f}\")\n",
        "    print(f\"⏱️ Training Time: {train_elapsed_time:.2f}s\\n\")\n",
        "    print(f\"Total number of iteration : {total_iterations}\")\n",
        "\n",
        "    # 3. 그래프 그리기\n",
        "    loss_history = checkpoint2[\"loss_history\"]\n",
        "    plot_loss_epoch(model_type, loss_history)\n",
        "\n",
        "    # 4. 테스트\n",
        "    Test(model, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_type, config in experiment_configs.items():\n",
        "    print(f\"=== Evaluating {model_type} ===\")\n",
        "    model, encoder, decoder, _, save_model_path, save_history_path, test_loader, recipe_vocab = main(\n",
        "        model_type, config, train_df, dev_df, test_df\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "    evaluate_and_report(model_type, config, encoder, decoder, save_model_path, save_history_path,\n",
        "                        test_loader, criterion, recipe_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot for all model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 여러 모델들의 히스토리를 불러온 후\n",
        "# baseline1_history = torch.load(\"results/baseline1_history.pt\")[\"loss_history\"]\n",
        "# baseline2_history = torch.load(\"results/baseline2_history.pt\")[\"loss_history\"]\n",
        "# mild1_history = torch.load(\"results/mild_extension1_history.pt\")[\"loss_history\"]\n",
        "\n",
        "# plot_loss_iter(\n",
        "#     baseline1=baseline1_history,\n",
        "#     baseline2=baseline2_history,\n",
        "#     mild_extension1=mild1_history\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes(ingredient_list, ingredient_vocab, recipe_vocab, max_len=30, is_raw_string=False, **models):\n",
        "\n",
        "    # Tokenizer 적용 여부\n",
        "    if is_raw_string:\n",
        "        tokens = tokenizer_ingredient(str(ingredient_list))\n",
        "    else:\n",
        "        tokens = ingredient_list\n",
        "\n",
        "    # index로 변환\n",
        "    tokens_ids = [ ingredient_vocab[token] if token in ingredient_vocab else ingredient_vocab['<unk>'] for token in tokens]\n",
        "    src_tensor = torch.tensor(tokens_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
        "\n",
        "    print(\"Ingredient :\",', '.join(tokens))\n",
        "    for name, model in models.items():\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated = model(src_tensor, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "            pred_ids = generated[0].tolist()\n",
        "\n",
        "            # <eos> 기준으로 자르기\n",
        "            if recipe_vocab['<eos>'] in pred_ids:\n",
        "                pred_ids = pred_ids[:pred_ids.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "            pred_tokens = [recipe_vocab.get_itos()[idx] for idx in pred_ids]\n",
        "            print(f\"{name}: {' '.join(pred_tokens[:30])}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredient : sugar, lemon juice,  water,  orange juice, strawberries, icecream\n",
            "baseline1: and sugar and vanilla and pour into a 9 x 13 inch pan\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ingredient : philadelphia, cream, cheese, sweetened, condensed, milk, ts, vanilla,  , lemon, juice, canned, cherries, graham, cracker,  , pie, crusts\n",
            "baseline1: cream cheese and vanilla and vanilla in a large bowl add vanilla and vanilla mix well and pour into a 9 x 13 inch pan\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    \"baseline1\": load_baseline1,\n",
        "    # \"baseline2\": load_baseline2\n",
        "}\n",
        "\n",
        "# # Sample 1: 전처리된 리스트\n",
        "sample1_raw = \"sugar, lemon juice,  water,  orange juice, strawberries, icecream\"\n",
        "sample1 = sample1_raw.split(\", \")\n",
        "generate_recipes(sample1, ingredient_vocab, recipe_vocab, is_raw_string=False, **models)\n",
        "\n",
        "# Sample2 : \n",
        "sample2_raw =\"8 oz philadelphia cream cheese, 14 oz can sweetened condensed milk, 1 ts vanilla, 1/3 c  lemon juice, 48 oz canned cherries, 8 inch graham cracker,  pie crusts\"\n",
        "sample2 = sample2_raw.split(\", \")\n",
        "generate_recipes(sample2, ingredient_vocab, recipe_vocab, is_raw_string=True, **models)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
