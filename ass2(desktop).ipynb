{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pnWO37v6oLFg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown\n",
        "\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import spacy\n",
        "import ast\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iuol8CxrHQZC"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzpEEDthSnhi",
        "outputId": "3677fb2b-d313-4960-fa2a-f5932daa0af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 162899\n",
            "Dev data size: 1065\n",
            "Test data size: 1081\n",
            "\n",
            "Train data sample:\n",
            "                      Title  \\\n",
            "0       No-Bake Nut Cookies   \n",
            "1               Creamy Corn   \n",
            "2      Reeses Cups(Candy)     \n",
            "3  Cheeseburger Potato Soup   \n",
            "4       Rhubarb Coffee Cake   \n",
            "\n",
            "                                         Ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "2  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "3  [\"6 baking potatoes\", \"1 lb. of extra lean gro...   \n",
            "4  [\"1 1/2 c. sugar\", \"1/2 c. butter\", \"1 egg\", \"...   \n",
            "\n",
            "                                              Recipe  \n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...  \n",
            "1  [\"In a slow cooker, combine all ingredients. C...  \n",
            "2  [\"Combine first four ingredients and press in ...  \n",
            "3  [\"Wash potatoes; prick several times with a fo...  \n",
            "4  [\"Cream sugar and butter.\", \"Add egg and beat ...  \n"
          ]
        }
      ],
      "source": [
        "# data Îã§Ïö¥\n",
        "train_path = 'Cooking_Dataset/train.csv'\n",
        "dev_path = 'Cooking_Dataset/dev.csv'\n",
        "test_path = 'Cooking_Dataset/test.csv'\n",
        "\n",
        "\n",
        "if not os.path.exists('Cooking_Dataset'):\n",
        "    os.makedirs('Cooking_Dataset')\n",
        "    print(\"Downloading Dataset\")\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1uZdYjvllt0dSdKKtrCgKHUk-APKdmeNU\", train_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1SAMbkdtjGBYgojqobiwe7ZmnEq7SiGsF\", dev_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1v6Rr2et_4WA5mRwwlRxtLhn38pbmr9Yr\", test_path, quiet=False)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "dev_df = pd.read_csv(dev_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Dev data size: {len(dev_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")\n",
        "print(\"\\nTrain data sample:\")\n",
        "print(train_df.head())\n",
        "#No-Bake Nut Cookies\n",
        "# [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n",
        "# [\"In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\", \"Stir over medium heat until mixture bubbles all over top.\", \"Boil and stir 5 minutes more. Take off heat.\", \"Stir in vanilla and cereal; mix well.\", \"Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\", \"Let stand until firm, about 30 minutes.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQwUvtETjCF",
        "outputId": "86b57a8d-0dd5-4fa7-abdf-0d96cb367749"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenizer_ingredient(text, remove_stopwords=True, lemmatize=True):\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "    # unit_keywords = {'c', 'tbsp', 'tsp', 'oz', 'lb', 'pkg', 'inch'} # for baseline\n",
        "    unit_keywords = {\n",
        "        'c', 'cup', 'cups', 'tbsp', 'tablespoon', 'tsp', 'teaspoon',\n",
        "        'oz', 'ounce', 'lb', 'pound', 'g', 'kg', 'mg',\n",
        "        'pt', 'qt', 'gal', 'ml', 'l',\n",
        "        'package', 'pkg', 'envelope', 'box', 'bag', 'jar', 'can', 'cans', 'bottle',\n",
        "        'dash', 'pinch', 'slice', 'slices', 'head', 'inch', 'inches',\n",
        "        'stick', 'sticks', 'small', 'medium', 'large'\n",
        "    }\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct:\n",
        "                    continue\n",
        "                if token.like_num:\n",
        "                    continue\n",
        "                if token.text.lower().strip('.') in unit_keywords:\n",
        "                    continue\n",
        "                if remove_stopwords and token.is_stop:\n",
        "                    continue\n",
        "\n",
        "                # üëá Í≥µÎ∞± Ï†úÍ±∞ Ï∂îÍ∞Ä!\n",
        "                if lemmatize:\n",
        "                    tokens.append(token.lemma_.strip())\n",
        "                else:\n",
        "                    tokens.append(token.text.strip())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def tokenizer_recipe(text, lemmatize=True):\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "    unit_keywords = {\n",
        "        'c', 'cup', 'cups', 'tbsp', 'tablespoon', 'tsp', 'teaspoon',\n",
        "        'oz', 'ounce', 'lb', 'pound', 'g', 'kg', 'mg',\n",
        "        'pt', 'qt', 'gal', 'ml', 'l',\n",
        "        'package', 'pkg', 'envelope', 'box', 'bag', 'jar', 'can', 'cans', 'bottle',\n",
        "        'dash', 'pinch', 'slice', 'slices', 'head', 'inch', 'inches',\n",
        "        'stick', 'sticks', 'small', 'medium', 'large'\n",
        "    }\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"tagger\", \"parser\", \"ner\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if not token.is_alpha and not token.like_num:\n",
        "                    continue\n",
        "                if token.like_num:\n",
        "                    tokens.append(token.text.strip())\n",
        "                    continue\n",
        "                if token.text.lower() in unit_keywords:\n",
        "                    tokens.append(token.text.lower().strip())\n",
        "                    continue\n",
        "                if lemmatize:\n",
        "                    tokens.append(token.lemma_.strip())\n",
        "                else:\n",
        "                    tokens.append(token.text.strip())\n",
        "    return tokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"In a slow cooker, combine all ingredients. Cover and cook on low for 4 hours or until heated through and cheese is melted. Stir well before serving. Yields 6 servings.\"]\n",
            "['in', 'a', 'slow', 'cooker', 'combine', 'all', 'ingredients', 'cover', 'and', 'cook', 'on', 'low', 'for', '4', 'hours', 'or', 'until', 'heated', 'through', 'and', 'cheese', 'is', 'melted', 'stir', 'well', 'before', 'serving', 'yields', '6', 'servings']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "ing = train_df.iloc[1,2]\n",
        "print(ing)\n",
        "print(tokenizer_recipe(ing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "O5IrjwMXuv3h"
      },
      "outputs": [],
      "source": [
        "def build_vocab(token_lists, min_freq=2):\n",
        "    # vocab ÏÉùÏÑ±: ÏûêÏ£º Îì±Ïû•ÌïòÎäî Îã®Ïñ¥Îßå Ìè¨Ìï® + ÌäπÏàò ÌÜ†ÌÅ∞ Ï†ïÏùò\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        token_lists,  # ÌÜ†ÌÅ∞ Î¶¨Ïä§Ìä∏Îì§ÏùÑ ÏßÅÏ†ë Î∞òÎ≥µ\n",
        "        min_freq=min_freq,  # ÏµúÏÜå Îì±Ïû• ÎπàÎèÑ\n",
        "        specials=['<pad>', '<sos>', '<eos>', '<unk>']  # ÌäπÏàò ÌÜ†ÌÅ∞ Ï∂îÍ∞Ä\n",
        "    )\n",
        "    vocab.set_default_index(vocab['<unk>'])  # ÏóÜÎäî Îã®Ïñ¥Îäî <unk>Î°ú Ï≤òÎ¶¨\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded the cached token list!\n",
            "Ingredient vocab size: 8991\n",
            "Recipe vocab size: 8471\n",
            "Sample ingredient tokens: [(0, '<pad>'), (1, '<sos>'), (2, '<eos>'), (3, '<unk>'), (4, 'chopped'), (5, 'sugar'), (6, 'salt'), (7, 'pepper'), (8, 'cream'), (9, 'cheese')]\n",
            "Sample recipe tokens: [(0, '<pad>'), (1, '<sos>'), (2, '<eos>'), (3, '<unk>'), (4, 'and'), (5, 'in'), (6, 'add'), (7, 'to'), (8, 'until'), (9, 'with')]\n"
          ]
        }
      ],
      "source": [
        "# Ï∫êÏãúÎêú ÌååÏùºÎ™Ö\n",
        "ingredient_cache_path = \"tokens/ingredient_tokens.pkl\"\n",
        "recipe_cache_path = \"tokens/recipe_tokens.pkl\"\n",
        "\n",
        "# ingredient_cache_download = \"https://drive.google.com/uc?id=1QLlXnSKMNtI9N2VFFT4zdSokoTQ-jo6j\"\n",
        "# recipe_cache_dowload = \"https://drive.google.com/uc?id=1pc_hcD9OCUaggWBhMd_EFiyPdo4tplA6\"\n",
        "ingredient_cache_download = \"https://drive.google.com/uc?id=135xr2X5RRQcd_JNQCXd1onKqMWSlDRLY\"\n",
        "recipe_cache_dowload = \"https://drive.google.com/uc?id=1H6zq4YQfaAQn82TNIM19K6t5URl3ENxD\"\n",
        "\n",
        "\n",
        "if not os.path.exists('tokens'):\n",
        "    os.makedirs('tokens')\n",
        "    print(\"Downloading caches\")\n",
        "    gdown.download(ingredient_cache_download, ingredient_cache_path, quiet=False)\n",
        "    gdown.download(recipe_cache_dowload, recipe_cache_path, quiet=False)\n",
        "\n",
        "\n",
        "# Ï∫êÏãúÍ∞Ä ÏûàÎã§Î©¥ Î∂àÎü¨Ïò§Í∏∞, ÏóÜÏúºÎ©¥ ÌÜ†ÌÅ∞ÌôîÌï¥ÏÑú Ï†ÄÏû•\n",
        "try:\n",
        "    with open(ingredient_cache_path, \"rb\") as f:\n",
        "        ingredient_token_lists = pickle.load(f)\n",
        "    with open(recipe_cache_path, \"rb\") as f:\n",
        "        recipe_token_lists = pickle.load(f)\n",
        "    print(\"Successfully loaded the cached token list!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No cache found ‚Üí Starting tokenization...\")\n",
        "    ingredient_token_lists = [tokenizer_ingredient(text) for text in tqdm(train_df['Ingredients'], desc=\"Tokenizing ingredients\")]\n",
        "    recipe_token_lists = [tokenizer_recipe(text) for text in tqdm(train_df['Recipe'], desc=\"Tokenizing recipes\")]\n",
        "    # Ï†ÄÏû•\n",
        "    with open(ingredient_cache_path, \"wb\") as f:\n",
        "        pickle.dump(ingredient_token_lists, f)\n",
        "    with open(recipe_cache_path, \"wb\") as f:\n",
        "        pickle.dump(recipe_token_lists, f)\n",
        "    print(\"Saved token list!\")\n",
        "\n",
        "\n",
        "\n",
        "# Vocab ÏÉùÏÑ± (2Î≤à Ïù¥ÏÉÅ Îì±Ïû•Ìïú Îã®Ïñ¥Îßå Ìè¨Ìï®)\n",
        "ingredient_vocab = build_vocab(ingredient_token_lists, min_freq=1)\n",
        "recipe_vocab = build_vocab(recipe_token_lists)\n",
        "\n",
        "# ÌôïÏù∏\n",
        "print(\"Ingredient vocab size:\", len(ingredient_vocab))\n",
        "print(\"Recipe vocab size:\", len(recipe_vocab))\n",
        "\n",
        "# ÏòàÏãúÎ°ú ÏùºÎ∂Ä Îã®Ïñ¥ Ï∂úÎ†•\n",
        "print(\"Sample ingredient tokens:\", list(enumerate(ingredient_vocab.get_itos()))[:10])\n",
        "print(\"Sample recipe tokens:\", list(enumerate(recipe_vocab.get_itos()))[:10])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "u3aRuH1BcoQQ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,df,ingredient_vocab,recipe_vocab):\n",
        "        self.df = df\n",
        "        self.ingredient_vocab = ingredient_vocab\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ï†ÑÏ≤òÎ¶¨Îêú ÌÖçÏä§Ìä∏ ÌÜ†ÌÅ∞Ìôî\n",
        "        ingredient_tokens = tokenizer_ingredient(self.df.iloc[idx][\"Ingredients\"])\n",
        "        recipe_tokens = tokenizer_recipe(self.df.iloc[idx][\"Recipe\"])\n",
        "\n",
        "        # Ïù∏Îç±Ïä§Î°ú Î≥ÄÌôò\n",
        "        ingredient_ids = [self.ingredient_vocab[token] for token in ingredient_tokens]\n",
        "        recipe_ids = [self.recipe_vocab['<sos>']] + [self.recipe_vocab[token] for token in recipe_tokens ]+[self.recipe_vocab['<eos>']]\n",
        "\n",
        "        # ÌÖêÏÑúÎ°ú\n",
        "        return torch.tensor(ingredient_ids), torch.tensor(recipe_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zvtpEXhJyzRN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    ingredients, recipes = zip(*batch)\n",
        "    ingredients_padded = pad_sequence(ingredients, batch_first=True, padding_value=ingredient_vocab['<pad>'])\n",
        "    recipes_padded = pad_sequence(recipes, batch_first=True, padding_value=recipe_vocab['<pad>'])\n",
        "    return ingredients_padded.to(DEVICE), recipes_padded.to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ZHuvOqpGoe5N"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        \n",
        "\n",
        "        # GRU Î†àÏù¥Ïñ¥\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # ÎìúÎ°≠ÏïÑÏõÉ\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src : [batch_size, src_len]\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded : [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # gru ÌÜµÍ≥º\n",
        "        outputs, hidden = self.gru(embedded) # h0Î•º Îî∞Î°ú Ï£ºÏßÄ ÏïäÏúºÎ©¥, ÎîîÌè¥Ìä∏Î°ú h0Í∞Ä 0Î°ú Ï¥àÍ∏∞ÌôîÎêòÏÑú Îì§Ïñ¥Í∞ê\n",
        "        # outputs: [batch_size, src_len, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        return outputs,hidden\n",
        "\n",
        "class Decoder_GRU(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU Î†àÏù¥Ïñ¥\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # fc Î†àÏù¥Ïñ¥\n",
        "        self.fc_out = nn.Linear(hidden_dim, recipe_vocab_size)\n",
        "\n",
        "        # ÎìúÎ°≠ÏïÑÏõÉ\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1]\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_dim]\n",
        "\n",
        "        # GRU ÌÜµÍ≥º\n",
        "        outputs, hidden = self.gru(embedded,hidden)\n",
        "        # outputs: [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        # fc ÌÜµÍ≥º\n",
        "        prediction = self.fc_out(outputs.squeeze(1))\n",
        "        # prediction: [batch_size, vocab_size]\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, use_attention):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "    def forward(self, src, target=None, teacher_forcing_ratio=0.5, max_len=50):\n",
        "        # Ïù∏ÏΩîÎçî\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        batch_size = src.size(0)\n",
        "        vocab_size = self.decoder.recipe_vocab_size\n",
        "\n",
        "        # Ï∂îÎ°† Î™®Îìú\n",
        "        if target is None:\n",
        "            outputs = []\n",
        "            input_token = torch.tensor([recipe_vocab['<sos>']] * batch_size).to(self.device)\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                if self.use_attention:\n",
        "                    output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                else:\n",
        "                    output, hidden = self.decoder(input_token, hidden)\n",
        "                top1 = output.argmax(1)\n",
        "                outputs.append(top1.unsqueeze(1))\n",
        "                input_token = top1\n",
        "\n",
        "            return torch.cat(outputs, dim=1)  # [batch_size, max_len]\n",
        "\n",
        "        # ÌïôÏäµ Î™®Îìú\n",
        "        target_len = target.shape[1]\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
        "        input_token = target[:, 0]  # <sos>\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            if self.use_attention:\n",
        "                output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            else:\n",
        "                output, hidden = self.decoder(input_token, hidden)\n",
        "            outputs[:, t, :] = output\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input_token = target[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "import torch.nn.functional as F\n",
        "    \n",
        "\n",
        "# Define a decoder with attention mechanism using PyTorch's nn.Module\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size,embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        # Initialize the base nn.Module class\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Save parameters\n",
        "        self.recipe_vocab_size = recipe_vocab_size              # Size of the output vocabulary\n",
        "        self.embedding_dim = embedding_dim                  # Dropout probability\n",
        "        self.hidden_size = hidden_size              # Size of the hidden state in GRU\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "                  \n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(self.recipe_vocab_size, self.hidden_size)  # Converts word indices to dense vectors\n",
        "        self.dropout = nn.Dropout(self.dropout_ratio)                          # Applies dropout for regularization\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.n_layers, dropout=self.dropout_ratio if self.n_layers>1 else 0, batch_first=True)\n",
        "             # GRU to process the embedded inputs\n",
        "        self.out = nn.Linear(self.hidden_size * 2, self.recipe_vocab_size)       # Linear layer for generating final output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1]\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_dim]\n",
        "\n",
        "        # Pass through GRU\n",
        "        output, hidden = self.gru(embedded, hidden)  # output: [batch, 1, hidden_size]\n",
        "\n",
        "        # Compute attention weights using dot-product attention:\n",
        "        # hidden[-1]: [batch, hidden_size]\n",
        "        # encoder_outputs: [batch, src_len, hidden_size]\n",
        "    \n",
        "        attn_weights = F.softmax(\n",
        "            torch.bmm(output, encoder_outputs.transpose(1, 2)), # [batch, 1, hidden_size] x [batch, hidden_size, src_len]\n",
        "            dim=-1\n",
        "        )  # [batch, 1, src_len]\n",
        "\n",
        "        # Apply attention weights to encoder outputs to get context vector\n",
        "        # attn_weights: (1, 1, max_length)\n",
        "        # encoder_outputs.unsqueeze(0): (1, max_length, hidden_size)\n",
        "        attn_output = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, hidden_size]\n",
        "\n",
        "        # Concatenate attention output and decoder hidden state\n",
        "        concat_output = torch.cat((output, attn_output), dim=2)  # [batch, 1, hidden*2]\n",
        "\n",
        "        # Pass through linear layer and softmax to get output word probabilities\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)  # [batch, vocab_size]\n",
        "\n",
        "        # Return output word distribution, updated hidden state, and attention weights\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# glove.6B.100d.txtÎ•º ÎØ∏Î¶¨ Î∂àÎü¨ÏôÄÏÑú vocabÏóê ÎßûÎäî ÏûÑÎ≤†Îî© Îß§Ìä∏Î¶≠Ïä§ ÏÉùÏÑ±\n",
        "glove_path = \"./glove.6B.100d.txt\"\n",
        "glove_dim = 100\n",
        "\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor(list(map(float, values[1:])))\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "ingredient_embedding_matrix = torch.randn(len(ingredient_vocab), glove_dim)  # OOVÎäî ÎûúÎç§ Ï¥àÍ∏∞Ìôî\n",
        "for word, idx in ingredient_vocab.get_stoi().items():\n",
        "    if word in glove_embeddings:\n",
        "        ingredient_embedding_matrix[idx] = glove_embeddings[word]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_epoch(model, dataloader, criterion, optimizer=None, teacher_forcing_ratio=0.5, max_len=50):\n",
        "    rloss = 0\n",
        "    batch_losses = []\n",
        "\n",
        "    for i, (src_batch, trg_batch) in enumerate(tqdm(dataloader, desc=\"Training batches\", leave=False)):\n",
        "        src_batch = src_batch.to(DEVICE)\n",
        "        trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "        output = model(src_batch, trg_batch, teacher_forcing_ratio=teacher_forcing_ratio, max_len=max_len)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item() * src_batch.size(0)\n",
        "        batch_losses.append(batch_loss)\n",
        "        rloss += batch_loss\n",
        "\n",
        "        tqdm.write(f\"[Batch {i+1}/{len(dataloader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = rloss / len(dataloader.dataset)\n",
        "    return avg_loss, batch_losses\n",
        "\n",
        "\n",
        "def Train(model, train_loader, val_loader, criterion, optimizer,\n",
        "          EPOCHS, BATCH_SIZE, TRAIN_RATIO,\n",
        "          save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs\n",
        "          ):\n",
        "    \"\"\"\n",
        "    Ïù¥Ïñ¥ÏÑú ÌïôÏäµÌï† Ïàò ÏûàÍ≤å start_epochÏôÄ best_val_lossÎ•º Ïù∏ÏûêÎ°ú Î∞õÏùå\n",
        "    \"\"\"\n",
        "    if \"LR_STEP\" in kwargs:\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=kwargs[\"LR_STEP\"], gamma=kwargs[\"LR_GAMMA\"])\n",
        "    else:\n",
        "        scheduler = None\n",
        "    loss_history = {\"train_epoch\": [], \"train_iter\": [], \"val_epoch\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    train_start_time = time.time()\n",
        "    for ep in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "        print(f\"Epoch {ep+1}/{EPOCHS}\")\n",
        "\n",
        "        ep_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_epoch_loss, train_batch_loss = loss_epoch(\n",
        "            model, train_loader, criterion, optimizer, \n",
        "            teacher_forcing_ratio=TEACHER_FORCING_RATIO,\n",
        "            max_len=MAX_LEN\n",
        "        )\n",
        "        loss_history[\"train_epoch\"].append(train_epoch_loss)\n",
        "        loss_history[\"train_iter\"].append(train_batch_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, _ = loss_epoch(\n",
        "                model, val_loader, criterion, optimizer=None,\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                max_len=MAX_LEN\n",
        "            )\n",
        "            loss_history[\"val_epoch\"].append(val_loss)\n",
        "\n",
        "        ep_elapsed_time = time.time() - ep_start_time\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            # ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏúºÎ©¥ ÏÉùÏÑ±\n",
        "            os.makedirs(\"results\", exist_ok=True)\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": ep,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"train_loss\": train_epoch_loss,  # train_loss Ï†ÄÏû•\n",
        "            }, save_model_path)\n",
        "            print(\"Best model saved!\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\"Train Loss: {train_epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {ep_elapsed_time:.2f}s\")\n",
        "    train_elapsed_time = time.time() - train_start_time\n",
        "    # Save training history\n",
        "    \n",
        "    torch.save({\n",
        "        \"loss_history\": loss_history,\n",
        "        \"EPOCHS\": EPOCHS,\n",
        "        \"BATCH_SIZE\": BATCH_SIZE,   \n",
        "        \"TRAIN_RATIO\": TRAIN_RATIO,\n",
        "        \"train_elapsed_time\": train_elapsed_time,\n",
        "        \"LR_STEP\": kwargs[\"LR_STEP\"] if \"LR_STEP\" in kwargs else None,\n",
        "        \"LR_GAMMA\": kwargs[\"LR_GAMMA\"] if \"LR_GAMMA\" in kwargs else None\n",
        "    }, save_history_path)\n",
        "    total_iterations = sum(len(batch_list) for batch_list in loss_history[\"train_iter\"])\n",
        "    print(f\"Total number of iteration : {total_iterations}\")\n",
        "    print(f\"Training Completed! Total Time: {train_elapsed_time:.2f}s\")\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "\n",
        "def Test(model, test_loader, criterion, recipe_vocab, MAX_LEN):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss, _ = loss_epoch(model, test_loader, criterion, optimizer=None, teacher_forcing_ratio=0.0, max_len=MAX_LEN)\n",
        "\n",
        "    # ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞\n",
        "    bleu_score, meteor_avg, bertscore_f1 = compute_metrics(model, test_loader, recipe_vocab)\n",
        "\n",
        "    print(f\"Test Loss      : {test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score   : {bleu_score:.4f}\")\n",
        "    print(f\"METEOR Score   : {meteor_avg:.4f}\")\n",
        "    print(f\"BERTScore (F1) : {bertscore_f1:.4f}\")\n",
        "\n",
        "    return test_loss, bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(model, dataloader, recipe_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    ÌÖåÏä§Ìä∏ÏÖã Ï†ÑÏ≤¥ÏóêÏÑú BLEU, METEOR, BERTScore Í≥ÑÏÇ∞\n",
        "\n",
        "    Returns:\n",
        "        bleu_score (float), meteor_avg (float), bertscore_f1 (float)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    ref_list = []\n",
        "    hyp_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, trg_batch in tqdm(dataloader, desc=\"Evaluating Metrics\"):\n",
        "            src_batch = src_batch.to(DEVICE)\n",
        "            trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "            generated = model(src_batch, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "\n",
        "            for i in range(src_batch.size(0)):\n",
        "                pred_tokens = generated[i].tolist()\n",
        "                trg_tokens = trg_batch[i].tolist()\n",
        "\n",
        "                # <eos> Í∏∞Ï§ÄÏúºÎ°ú ÏûêÎ•¥Í∏∞\n",
        "                if recipe_vocab['<eos>'] in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[:pred_tokens.index(recipe_vocab['<eos>'])]\n",
        "                if recipe_vocab['<eos>'] in trg_tokens:\n",
        "                    trg_tokens = trg_tokens[:trg_tokens.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "                pred_words = [recipe_vocab.get_itos()[idx] for idx in pred_tokens]\n",
        "                trg_words = [recipe_vocab.get_itos()[idx] for idx in trg_tokens]\n",
        "\n",
        "                ref_list.append(trg_words)\n",
        "                hyp_list.append(pred_words)\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_score = corpus_bleu([[ref] for ref in ref_list], hyp_list, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie) \n",
        "\n",
        "    # METEOR\n",
        "    meteor_scores = [meteor_score([ref], hyp) for ref, hyp in zip(ref_list, hyp_list)]\n",
        "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "    # BERTScore\n",
        "    refs = [\" \".join(ref) for ref in ref_list]\n",
        "    hyps = [\" \".join(hyp) for hyp in hyp_list]\n",
        "    _, _, f1 = bert_score_fn(hyps, refs, lang='en', verbose=False)\n",
        "    bertscore_f1 = f1.mean().item()\n",
        "\n",
        "    return bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "def plot_loss_epoch(name, loss_history):\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    train_loss = loss_history[\"train_epoch\"]\n",
        "    val_loss = loss_history[\"val_epoch\"]\n",
        "\n",
        "    plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(range(1, len(val_loss) + 1), val_loss, label=\"Validation Loss\", color=\"red\")\n",
        "\n",
        "    plt.xlabel(\"Epoch\", fontsize=10)\n",
        "    plt.ylabel(\"Loss\", fontsize=10)\n",
        "    plt.title(f\"Loss per Epoch: {name}\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss_iter(**models_histories):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for model_name, history in models_histories.items():\n",
        "        train_iter_losses = history.get(\"train_iter\", [])\n",
        "        if train_iter_losses:\n",
        "            plt.plot(train_iter_losses, label=model_name)\n",
        "        else:\n",
        "            print(f\"[Í≤ΩÍ≥†] {model_name}Ïóê train_iter Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "\n",
        "    plt.title(\"Training Iteration Loss\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def run_train(model_type: str, config: dict):\n",
        "    INPUT_DIM = len(ingredient_vocab)\n",
        "    OUTPUT_DIM = len(recipe_vocab)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "    BATCH_SIZE = 64\n",
        "    TRAIN_RATIO = 1.0\n",
        "\n",
        "    save_model_path = f\"results/{model_type}.pt\"\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    # GloVe Îì± ÏûÑÎ≤†Îî© Í¥ÄÎ†® ÏÑ§Ï†ï (ÏóÜÏúºÎ©¥ NoneÏúºÎ°ú Ï≤òÎ¶¨)\n",
        "    embedding_weights = config.get(\"embedding_weights\", None)\n",
        "    freeze_embedding = config.get(\"freeze_embedding\", False)\n",
        "    lr_step = config.get(\"LR_STEP\", None)\n",
        "    lr_gamma = config.get(\"LR_GAMMA\", None)\n",
        "\n",
        "    # Ïù∏ÏΩîÎçî Íµ¨ÏÑ±\n",
        "    encoder = Encoder_GRU(\n",
        "        ingredient_vocab_size=INPUT_DIM,\n",
        "        embedding_dim=config[\"EMBED_DIM\"],\n",
        "        hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "        n_layers=config[\"N_LAYERS\"],\n",
        "        dropout_ratio=config[\"DROPOUT\"],\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze=freeze_embedding\n",
        "    )\n",
        "\n",
        "    # ÎîîÏΩîÎçî Íµ¨ÏÑ± (attention Ïó¨Î∂ÄÏóê Îî∞Îùº)\n",
        "    if config[\"USE_ATTENTION\"]:\n",
        "        decoder = AttnDecoderRNN(\n",
        "            recipe_vocab_size=OUTPUT_DIM,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_size=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"]\n",
        "        )\n",
        "    else:\n",
        "        decoder = Decoder_GRU(\n",
        "            recipe_vocab_size=OUTPUT_DIM,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"]\n",
        "        )\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "    print(model)\n",
        "\n",
        "    # ÌïôÏäµ ÎòêÎäî Î°úÎìú\n",
        "    if config[\"new_model_train\"]:\n",
        "        print(f\"Training model: {model_type}\")\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n",
        "\n",
        "        loss_history = Train(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=dev_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            EPOCHS=config[\"EPOCHS\"],\n",
        "            BATCH_SIZE=64,\n",
        "            TRAIN_RATIO=1.0,\n",
        "            save_model_path=save_model_path,\n",
        "            save_history_path=save_history_path,\n",
        "            TEACHER_FORCING_RATIO=config[\"TEACHER_FORCING_RATIO\"],\n",
        "            MAX_LEN=config[\"MAX_LEN\"],\n",
        "            LR_STEP=lr_step,\n",
        "            LR_GAMMA=lr_gamma\n",
        "        )\n",
        "\n",
        "        return model, encoder, decoder, loss_history, save_model_path, save_history_path\n",
        "    else:\n",
        "        return model, encoder, decoder, None, save_model_path, save_history_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
        "INPUT_DIM = len(ingredient_vocab)\n",
        "OUTPUT_DIM = len(recipe_vocab)\n",
        "BATCH_SIZE = 64\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "TRAIN_RATIO = 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredients batch shape: torch.Size([64, 32])\n",
            "Recipes batch shape: torch.Size([64, 100])\n"
          ]
        }
      ],
      "source": [
        "train_dataset = CustomDataset(train_df, ingredient_vocab, recipe_vocab)\n",
        "dev_dataset = CustomDataset(dev_df, ingredient_vocab, recipe_vocab)\n",
        "test_dataset = CustomDataset(test_df, ingredient_vocab, recipe_vocab)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# ÌôïÏù∏\n",
        "sample_ingredients, sample_recipes = next(iter(train_loader))\n",
        "print(\"Ingredients batch shape:\", sample_ingredients.shape)\n",
        "print(\"Recipes batch shape:\", sample_recipes.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï†ÄÏû•\n",
        "experiment_configs = {\n",
        "    \"baseline1\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": False,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.5 \n",
        "    },\n",
        "    \"baseline2\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.5 \n",
        "    },\n",
        "    \"mild_extension1\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 256,\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 3,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.5 \n",
        "    },\n",
        "    \"mild_extension2\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 100,  # GloVe 6B 100DÏôÄ ÏùºÏπò\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 3,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.5,\n",
        "        \"embedding_weights\": ingredient_embedding_matrix,\n",
        "        \"freeze_embedding\": False\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder_GRU(\n",
            "    (embedding): Embedding(8991, 128)\n",
            "    (gru): GRU(128, 256, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder_GRU(\n",
            "    (embedding): Embedding(8471, 128)\n",
            "    (gru): GRU(128, 256, batch_first=True)\n",
            "    (fc_out): Linear(in_features=256, out_features=8471, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model_type = \"baseline1\"\n",
        "config = experiment_configs[model_type]\n",
        "\n",
        "model, encoder, decoder, loss_history, save_model_path, save_history_path = run_train(model_type, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([5465, 128]) from checkpoint, the shape in current model is torch.Size([8991, 128]).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[75], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Í∞ôÏùÄ Íµ¨Ï°∞Î°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\u001b[39;00m\n\u001b[1;32m      6\u001b[0m load_baseline1 \u001b[38;5;241m=\u001b[39m Seq2Seq(encoder, decoder, DEVICE, use_attention\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_ATTENTION\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mload_baseline1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Ï†ÄÏû•Îêú Ïù¥Î†• Ï§ë loss history Í∞ÄÏ†∏Ïò§Í∏∞\u001b[39;00m\n\u001b[1;32m     10\u001b[0m loss_history_loss_history_baseline1 \u001b[38;5;241m=\u001b[39m checkpoint2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_history\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([5465, 128]) from checkpoint, the shape in current model is torch.Size([8991, 128])."
          ]
        }
      ],
      "source": [
        "# Ï†ÄÏû•Îêú Î™®Îç∏Í≥º ÌïôÏäµ Ïù¥Î†• Î∂àÎü¨Ïò§Í∏∞\n",
        "checkpoint = torch.load(save_model_path, map_location=DEVICE)\n",
        "checkpoint2 = torch.load(save_history_path, map_location=DEVICE)\n",
        "\n",
        "# Í∞ôÏùÄ Íµ¨Ï°∞Î°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\n",
        "load_baseline1 = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "load_baseline1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# Ï†ÄÏû•Îêú Ïù¥Î†• Ï§ë loss history Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "loss_history_loss_history_baseline1 = checkpoint2[\"loss_history\"]\n",
        "train_elapsed_time = checkpoint2[\"train_elapsed_time\"]\n",
        "\n",
        "#  Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
        "best_epoch = checkpoint[\"epoch\"] + 1  \n",
        "best_train_loss = checkpoint[\"train_loss\"]\n",
        "best_val_loss = checkpoint[\"val_loss\"]\n",
        "print(f\"Best model was saved at Epoch {best_epoch}\")\n",
        "print(f\"Train Loss: {best_train_loss:.4f} | Val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Total training time : {train_elapsed_time:.2f} s\")\n",
        "\n",
        "# Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
        "plot_loss_epoch(model_type, loss_history_loss_history_baseline1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e6915d6dc6440f2b36c537b7b9ecee3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Batch 1/17] Loss: 6.3220\n",
            "[Batch 2/17] Loss: 6.0829\n",
            "[Batch 3/17] Loss: 6.1686\n",
            "[Batch 4/17] Loss: 6.2933\n",
            "[Batch 5/17] Loss: 6.3347\n",
            "[Batch 6/17] Loss: 6.1810\n",
            "[Batch 7/17] Loss: 6.2771\n",
            "[Batch 8/17] Loss: 6.4080\n",
            "[Batch 9/17] Loss: 6.0855\n",
            "[Batch 10/17] Loss: 6.0942\n",
            "[Batch 11/17] Loss: 6.3267\n",
            "[Batch 12/17] Loss: 6.2767\n",
            "[Batch 13/17] Loss: 6.2921\n",
            "[Batch 14/17] Loss: 6.1031\n",
            "[Batch 15/17] Loss: 6.3598\n",
            "[Batch 16/17] Loss: 6.4224\n",
            "[Batch 17/17] Loss: 6.3856\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68aceb6cf417433bb04ec0a7594def28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating Metrics:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss      : 6.2588\n",
            "BLEU-4 Score   : 0.0458\n",
            "METEOR Score   : 0.1944\n",
            "BERTScore (F1) : 0.8428\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(6.258806762818822,\n",
              " 0.04579663792237396,\n",
              " 0.1943934029951878,\n",
              " 0.8428406119346619)"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ïù¥Ï†ú Test Í∞ÄÎä•\n",
        "Test(load_baseline1, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model_type = \"baseline2\"\n",
        "config = experiment_configs[model_type]\n",
        "\n",
        "model, encoder, decoder, loss_history, save_model_path, save_history_path = run_train(model_type, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder_GRU(\n",
            "    (embedding): Embedding(5465, 128)\n",
            "    (gru): GRU(128, 256, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): AttnDecoderRNN(\n",
            "    (embedding): Embedding(8471, 256)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (gru): GRU(256, 256, batch_first=True)\n",
            "    (out): Linear(in_features=512, out_features=8471, bias=True)\n",
            "  )\n",
            ")\n",
            "Training model: baseline2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d73191d1be54c0cacbd2d76e5d93a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db02b67a63594253af9f6fbba6f17fd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches:   0%|          | 0/2546 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[140], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m experiment_configs[model_type]\n\u001b[0;32m----> 4\u001b[0m model, encoder, decoder, loss_history, save_model_path, save_history_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[128], line 236\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(model_type, config)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 236\u001b[0m     loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTRAIN_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_history_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_history_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEACHER_FORCING_RATIO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAX_LEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, encoder, decoder, loss_history, save_model_path, save_history_path\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "Cell \u001b[0;32mIn[128], line 49\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, EPOCHS, BATCH_SIZE, TRAIN_RATIO, save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 49\u001b[0m train_epoch_loss, train_batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n\u001b[1;32m     55\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_batch_loss)\n",
            "Cell \u001b[0;32mIn[128], line 18\u001b[0m, in \u001b[0;36mloss_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, teacher_forcing_ratio, max_len)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_type = \"baseline2\"\n",
        "config = experiment_configs[model_type]\n",
        "\n",
        "model, encoder, decoder, loss_history, save_model_path, save_history_path = run_train(model_type, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model was saved at Epoch 4\n",
            "Train Loss: 3.9742 | Val Loss: 5.8047\n",
            "Total training time : 15572.66 s\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Ï†ÄÏû•Îêú Î™®Îç∏Í≥º ÌïôÏäµ Ïù¥Î†• Î∂àÎü¨Ïò§Í∏∞\n",
        "checkpoint = torch.load(save_model_path, map_location=DEVICE)\n",
        "checkpoint2 = torch.load(save_history_path, map_location=DEVICE)\n",
        "\n",
        "# Í∞ôÏùÄ Íµ¨Ï°∞Î°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\n",
        "load_baseline2 = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "load_baseline2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# Ï†ÄÏû•Îêú Ïù¥Î†• Ï§ë loss history Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "loss_history_loss_history_baseline2 = checkpoint2[\"loss_history\"]\n",
        "train_elapsed_time = checkpoint2[\"train_elapsed_time\"]\n",
        "\n",
        "#  Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
        "best_epoch = checkpoint[\"epoch\"] + 1  \n",
        "best_train_loss = checkpoint[\"train_loss\"]\n",
        "best_val_loss = checkpoint[\"val_loss\"]\n",
        "print(f\"Best model was saved at Epoch {best_epoch}\")\n",
        "print(f\"Train Loss: {best_train_loss:.4f} | Val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Total training time : {train_elapsed_time:.2f} s\")\n",
        "\n",
        "# Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
        "plot_loss_epoch(model_type, loss_history_loss_history_baseline1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "Evaluating Metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:23<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss      : 5.7656\n",
            "BLEU-4 Score   : 0.0527\n",
            "METEOR Score   : 0.2104\n",
            "BERTScore (F1) : 0.8421\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(5.76562103356177, 0.05269045547005537, 0.21038731724608936, 0.842138946056366)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ïù¥Ï†ú Test Í∞ÄÎä•\n",
        "Test(load_baseline1, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# mild_extension1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder_GRU(\n",
            "    (embedding): Embedding(8991, 256)\n",
            "    (gru): GRU(256, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): AttnDecoderRNN(\n",
            "    (embedding): Embedding(8471, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (gru): GRU(512, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
            "    (out): Linear(in_features=1024, out_features=8471, bias=True)\n",
            "  )\n",
            ")\n",
            "Training model: mild_extension1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce6bf6616d354c24a0ae2a05c09d6d40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d265bda93c492186bed7c78c2cc254",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches:   0%|          | 0/2546 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[78], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmild_extension1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m experiment_configs[model_type]\n\u001b[0;32m----> 4\u001b[0m model, encoder, decoder, loss_history, save_model_path, save_history_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[70], line 269\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(model_type, config)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 269\u001b[0m     loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTRAIN_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_history_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_history_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEACHER_FORCING_RATIO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAX_LEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLR_STEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLR_GAMMA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_gamma\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, encoder, decoder, loss_history, save_model_path, save_history_path\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "Cell \u001b[0;32mIn[70], line 53\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, EPOCHS, BATCH_SIZE, TRAIN_RATIO, save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 53\u001b[0m train_epoch_loss, train_batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n\u001b[1;32m     59\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_batch_loss)\n",
            "Cell \u001b[0;32mIn[70], line 18\u001b[0m, in \u001b[0;36mloss_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, teacher_forcing_ratio, max_len)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_type = \"mild_extension1\"\n",
        "config = experiment_configs[model_type]\n",
        "\n",
        "model, encoder, decoder, loss_history, save_model_path, save_history_path = run_train(model_type, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ï†ÄÏû•Îêú Î™®Îç∏Í≥º ÌïôÏäµ Ïù¥Î†• Î∂àÎü¨Ïò§Í∏∞\n",
        "checkpoint = torch.load(save_model_path, map_location=DEVICE)\n",
        "checkpoint2 = torch.load(save_history_path, map_location=DEVICE)\n",
        "\n",
        "# Í∞ôÏùÄ Íµ¨Ï°∞Î°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\n",
        "load_mild_extension1 = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "load_mild_extension1.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# Ï†ÄÏû•Îêú Ïù¥Î†• Ï§ë loss history Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "loss_history_loss_history_mild_extension1 = checkpoint2[\"loss_history\"]\n",
        "train_elapsed_time = checkpoint2[\"train_elapsed_time\"]\n",
        "\n",
        "#  Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
        "best_epoch = checkpoint[\"epoch\"] + 1  \n",
        "best_train_loss = checkpoint[\"train_loss\"]\n",
        "best_val_loss = checkpoint[\"val_loss\"]\n",
        "print(f\"Best model was saved at Epoch {best_epoch}\")\n",
        "print(f\"Train Loss: {best_train_loss:.4f} | Val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Total training time : {train_elapsed_time:.2f} s\")\n",
        "\n",
        "# Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
        "plot_loss_epoch(model_type, loss_history_loss_history_mild_extension1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ïù¥Ï†ú Test Í∞ÄÎä•\n",
        "Test(load_mild_extension1, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# mild_extension2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder_GRU(\n",
            "    (embedding): Embedding(8991, 100)\n",
            "    (gru): GRU(100, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): AttnDecoderRNN(\n",
            "    (embedding): Embedding(8471, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (gru): GRU(512, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
            "    (out): Linear(in_features=1024, out_features=8471, bias=True)\n",
            "  )\n",
            ")\n",
            "Training model: mild_extension2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "513e62617c6d4da28cd96c0f093b2790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caa0fb65830448d0a9adce0afe83b529",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches:   0%|          | 0/2546 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmild_extension2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m experiment_configs[model_type]\n\u001b[0;32m----> 4\u001b[0m model, encoder, decoder, loss_history, save_model_path, save_history_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[70], line 269\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(model_type, config)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 269\u001b[0m     loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTRAIN_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_history_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_history_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEACHER_FORCING_RATIO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAX_LEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLR_STEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLR_GAMMA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_gamma\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, encoder, decoder, loss_history, save_model_path, save_history_path\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "Cell \u001b[0;32mIn[70], line 53\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, EPOCHS, BATCH_SIZE, TRAIN_RATIO, save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 53\u001b[0m train_epoch_loss, train_batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEACHER_FORCING_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n\u001b[1;32m     59\u001b[0m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_batch_loss)\n",
            "Cell \u001b[0;32mIn[70], line 18\u001b[0m, in \u001b[0;36mloss_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, teacher_forcing_ratio, max_len)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_type = \"mild_extension2\"\n",
        "config = experiment_configs[model_type]\n",
        "\n",
        "model, encoder, decoder, loss_history, save_model_path, save_history_path = run_train(model_type, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ï†ÄÏû•Îêú Î™®Îç∏Í≥º ÌïôÏäµ Ïù¥Î†• Î∂àÎü¨Ïò§Í∏∞\n",
        "checkpoint = torch.load(save_model_path, map_location=DEVICE)\n",
        "checkpoint2 = torch.load(save_history_path, map_location=DEVICE)\n",
        "\n",
        "# Í∞ôÏùÄ Íµ¨Ï°∞Î°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\n",
        "load_mild_extension2 = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"]).to(DEVICE)\n",
        "load_mild_extension2.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# Ï†ÄÏû•Îêú Ïù¥Î†• Ï§ë loss history Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "loss_history_loss_history_mild_extension2 = checkpoint2[\"loss_history\"]\n",
        "train_elapsed_time = checkpoint2[\"train_elapsed_time\"]\n",
        "\n",
        "#  Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
        "best_epoch = checkpoint[\"epoch\"] + 1  \n",
        "best_train_loss = checkpoint[\"train_loss\"]\n",
        "best_val_loss = checkpoint[\"val_loss\"]\n",
        "print(f\"Best model was saved at Epoch {best_epoch}\")\n",
        "print(f\"Train Loss: {best_train_loss:.4f} | Val Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Total training time : {train_elapsed_time:.2f} s\")\n",
        "\n",
        "# Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
        "plot_loss_epoch(model_type, loss_history_loss_history_mild_extension2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ïù¥Ï†ú Test Í∞ÄÎä•\n",
        "Test(load_mild_extension2, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot for all model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_iter(\n",
        "    baseline1=loss_history_loss_history_baseline1,\n",
        "    baseline2=loss_history_loss_history_baseline2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes(ingredient_list, ingredient_vocab, recipe_vocab, max_len=30, is_raw_string=False, **models):\n",
        "\n",
        "    # Tokenizer Ï†ÅÏö© Ïó¨Î∂Ä\n",
        "    if is_raw_string:\n",
        "        tokens = tokenizer_ingredient(str(ingredient_list))\n",
        "    else:\n",
        "        tokens = ingredient_list\n",
        "\n",
        "    # indexÎ°ú Î≥ÄÌôò\n",
        "    tokens_ids = [ ingredient_vocab[token] if token in ingredient_vocab else ingredient_vocab['<unk>'] for token in tokens]\n",
        "    src_tensor = torch.tensor(tokens_ids, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
        "\n",
        "    print(\"Ingredient :\",', '.join(tokens))\n",
        "    for name, model in models.items():\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated = model(src_tensor, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "            pred_ids = generated[0].tolist()\n",
        "\n",
        "            # <eos> Í∏∞Ï§ÄÏúºÎ°ú ÏûêÎ•¥Í∏∞\n",
        "            if recipe_vocab['<eos>'] in pred_ids:\n",
        "                pred_ids = pred_ids[:pred_ids.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "            pred_tokens = [recipe_vocab.get_itos()[idx] for idx in pred_ids]\n",
        "            print(f\"{name}: {' '.join(pred_tokens[:30])}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredient : sugar, lemon juice,  water,  orange juice, strawberries, icecream\n",
            "baseline1: and sugar and vanilla and pour into a 9 x 13 inch pan\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ingredient : philadelphia, cream, cheese, sweetened, condensed, milk, ts, vanilla,  , lemon, juice, canned, cherries, graham, cracker,  , pie, crusts\n",
            "baseline1: cream cheese and vanilla and vanilla in a large bowl add vanilla and vanilla mix well and pour into a 9 x 13 inch pan\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    \"baseline1\": load_baseline1,\n",
        "    # \"baseline2\": load_baseline2\n",
        "}\n",
        "\n",
        "# # Sample 1: Ï†ÑÏ≤òÎ¶¨Îêú Î¶¨Ïä§Ìä∏\n",
        "sample1_raw = \"sugar, lemon juice,  water,  orange juice, strawberries, icecream\"\n",
        "sample1 = sample1_raw.split(\", \")\n",
        "generate_recipes(sample1, ingredient_vocab, recipe_vocab, is_raw_string=False, **models)\n",
        "\n",
        "# Sample2 : \n",
        "sample2_raw =\"8 oz philadelphia cream cheese, 14 oz can sweetened condensed milk, 1 ts vanilla, 1/3 c  lemon juice, 48 oz canned cherries, 8 inch graham cracker,  pie crusts\"\n",
        "sample2 = sample2_raw.split(\", \")\n",
        "generate_recipes(sample2, ingredient_vocab, recipe_vocab, is_raw_string=True, **models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7NLnAN8Mmem"
      },
      "outputs": [],
      "source": [
        "##### ÏòàÏ†ÑÍ∫º(Í≤∞Í≥ºÏûàÏùå!!!) #####\n",
        "def compute_bleu(model, dataloader, recipe_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    Seq2Seq Î™®Îç∏Ïùò BLEU Ï†êÏàòÎ•º Í≥ÑÏÇ∞ (1~4-gram Í∏∞Ï§Ä)\n",
        "\n",
        "    Args:\n",
        "        model: ÌïôÏäµÎêú Seq2Seq Î™®Îç∏\n",
        "        dataloader: Í≤ÄÏ¶ù ÎòêÎäî ÌÖåÏä§Ìä∏ DataLoader\n",
        "        recipe_vocab: recipe vocab Í∞ùÏ≤¥ (Ïù∏Îç±Ïä§ ‚Üí Îã®Ïñ¥ Î≥ÄÌôòÏö©)\n",
        "        max_len: ÏÉùÏÑ±Ìï† ÏµúÎåÄ Î¨∏Ïû• Í∏∏Ïù¥\n",
        "\n",
        "    Returns:\n",
        "        bleu_score (float): 0~100 ÏÇ¨Ïù¥Ïùò BLEU Ï†êÏàò\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, trg_batch in tqdm(dataloader, desc=\"Evaluating BLEU\"):\n",
        "            src_batch = src_batch.to(DEVICE)\n",
        "            trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "            # ÏÉùÏÑ±Îêú ÏòàÏ∏° ÏãúÌÄÄÏä§: [batch_size, max_len]\n",
        "            generated = model(src_batch, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "\n",
        "            for i in range(src_batch.size(0)):\n",
        "                pred_tokens = generated[i].tolist()\n",
        "                trg_tokens = trg_batch[i].tolist()\n",
        "\n",
        "                # <eos> ÌÜ†ÌÅ∞Ïù¥ ÎÇòÏò§Î©¥ Í±∞Í∏∞ÏÑú ÏûêÎ¶Ñ\n",
        "                if recipe_vocab['<eos>'] in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[:pred_tokens.index(recipe_vocab['<eos>'])]\n",
        "                if recipe_vocab['<eos>'] in trg_tokens:\n",
        "                    trg_tokens = trg_tokens[:trg_tokens.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "                preds.append(pred_tokens)\n",
        "                targets.append([trg_tokens])  # corpus_bleuÎäî list of list ÌïÑÏöî\n",
        "\n",
        "    bleu = corpus_bleu(targets, preds) * 100\n",
        "    print(f\"\\nBLEU Score: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "\n",
        "def loss_epoch(model, dataloader, criterion, optimizer=None, teacher_forcing_ratio=0.5):\n",
        "    \"\"\"\n",
        "    ÌïôÏäµ ÎòêÎäî ÌèâÍ∞Ä Î£®ÌîÑÏóêÏÑú 1 epoch ÎèôÏïà lossÎßå Í≥ÑÏÇ∞ÌïòÎäî Ìï®Ïàò.\n",
        "\n",
        "    Args:\n",
        "        model: Seq2Seq Î™®Îç∏\n",
        "        dataloader: DataLoader\n",
        "        criterion: ÏÜêÏã§ Ìï®Ïàò (CrossEntropyLoss)\n",
        "        optimizer: ÏòµÌã∞ÎßàÏù¥Ï†Ä (NoneÏù¥Î©¥ eval Î™®ÎìúÎ°ú ÎèôÏûë)\n",
        "        teacher_forcing_ratio: ÌïôÏäµ Ï§ë Teacher Forcing ÎπÑÏú®\n",
        "\n",
        "    Returns:\n",
        "        epoch_loss: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÎåÄÌïú ÌèâÍ∑† loss\n",
        "    \"\"\"\n",
        "    model.train() if optimizer else model.eval()\n",
        "    rloss = 0\n",
        "\n",
        "    for src_batch, trg_batch in tqdm(dataloader, leave=False):\n",
        "        src_batch = src_batch.to(DEVICE)\n",
        "        trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "        output = model(src_batch, trg_batch, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        # CrossEntropyLoss Í≥ÑÏÇ∞ÏùÑ ÏúÑÌïú reshape\n",
        "        output = output[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        rloss += loss.item() * src_batch.shape[0]\n",
        "\n",
        "    return rloss / len(dataloader.dataset)\n",
        "\n",
        "def Train(model, train_loader, val_loader, criterion, optimizer,\n",
        "          EPOCHS, BATCH_SIZE, TRAIN_RATIO,\n",
        "          save_model_path, save_history_path,\n",
        "          ):\n",
        "    \"\"\"\n",
        "    Ïù¥Ïñ¥ÏÑú ÌïôÏäµÌï† Ïàò ÏûàÍ≤å start_epochÏôÄ best_val_lossÎ•º Ïù∏ÏûêÎ°ú Î∞õÏùå\n",
        "    \"\"\"\n",
        "\n",
        "    loss_history = {\"train\": [], \"val\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    train_start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "        ep_start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        train_loss = loss_epoch(model, train_loader, criterion, optimizer, teacher_forcing_ratio=0.5)\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = loss_epoch(model, val_loader, criterion, optimizer=None, teacher_forcing_ratio=0.0)\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "\n",
        "        ep_elapsed_time = time.time() - ep_start_time\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": epoch,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"train_loss\": train_loss,  # train_loss Ï†ÄÏû•\n",
        "            }, save_model_path)\n",
        "            print(\"Best model saved!\")\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {ep_elapsed_time:.2f}s\")\n",
        "    train_elapsed_time = time.time() - train_start_time\n",
        "    # Save training history\n",
        "    torch.save({\n",
        "        \"loss_history\": loss_history,\n",
        "        \"EPOCHS\": EPOCHS,\n",
        "        \"BATCH_SIZE\": BATCH_SIZE,\n",
        "        \"TRAIN_RATIO\": TRAIN_RATIO\n",
        "    }, save_history_path)\n",
        "\n",
        "    print(f\"\\nTraining Completed! History saved!| Elapsed Time : {train_elapsed_time}\")\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "def Test(model, test_loader, criterion, recipe_vocab):\n",
        "    \"\"\"\n",
        "    ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú ÏÜêÏã§Í≥º BLEU Ï†êÏàòÎ•º Í≥ÑÏÇ∞ÌïòÎäî Ìï®Ïàò.\n",
        "\n",
        "    Args:\n",
        "        model: ÌïôÏäµÎêú Seq2Seq Î™®Îç∏\n",
        "        test_loader: ÌÖåÏä§Ìä∏ DataLoader\n",
        "        criterion: ÏÜêÏã§ Ìï®Ïàò\n",
        "        recipe_vocab: vocab Í∞ùÏ≤¥ (BLEU Í≥ÑÏÇ∞Ïö©)\n",
        "\n",
        "    Returns:\n",
        "        test_loss (float), bleu_score (float)\n",
        "    \"\"\"\n",
        "    print(\"\\n Testing on test set...\")\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss = loss_epoch(model, test_loader, criterion, optimizer=None, teacher_forcing_ratio=0.0)\n",
        "\n",
        "    bleu_score = compute_bleu(model, test_loader, recipe_vocab)\n",
        "    print(f\"Test Loss: {test_loss:.4f} | BLEU Score: {bleu_score:.2f}\")\n",
        "\n",
        "    return test_loss, bleu_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMJsudpjHp_O",
        "outputId": "e6f98c97-7965-4c15-8363-35e66b1a4453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New model training!\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2546 [00:00<?, ?it/s]/home/psarda/repos/NLP/.venv/lib/python3.11/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved!\n",
            "Train Loss: 4.3775 | Val Loss: 4.9679 | Time: 3727.94s\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved!\n",
            "Train Loss: 3.9285 | Val Loss: 4.9464 | Time: 3716.95s\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved!\n",
            "Train Loss: 3.8209 | Val Loss: 4.8882 | Time: 3724.51s\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.7594 | Val Loss: 4.8932 | Time: 3715.59s\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.7219 | Val Loss: 4.9373 | Time: 3987.15s\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.6916 | Val Loss: 4.8978 | Time: 3766.76s\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.6670 | Val Loss: 4.9374 | Time: 3943.18s\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.6451 | Val Loss: 4.8948 | Time: 4250.35s\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.6278 | Val Loss: 4.9209 | Time: 4195.73s\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                     \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.6148 | Val Loss: 4.9444 | Time: 4038.07s\n",
            "\n",
            "Training Completed! History saved!| Elapsed Time : 39066.561606884\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##### ÏòàÏ†ÑÍ∫º(Í≤∞Í≥ºÏûàÏùå!!!) #####\n",
        "\n",
        "# Î™®Îç∏ ÏÉùÏÑ±\n",
        "encoder = Encoder_GRU(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
        "decoder = Decoder_GRU(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "\n",
        "if new_model_train:\n",
        "    print(\"New model training!\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    loss_history = Train(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=dev_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        EPOCHS=EPOCHS,\n",
        "        BATCH_SIZE=BATCH_SIZE,\n",
        "        TRAIN_RATIO=TRAIN_RATIO,\n",
        "        save_model_path=save_model_path,\n",
        "        save_history_path=save_history_path,\n",
        "    )\n",
        "\n",
        "    # ÌîåÎ°Ø Í∑∏Î¶¨Í∏∞\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(1, EPOCHS+1), loss_history[\"train\"], label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(range(1, EPOCHS+1), loss_history[\"val\"], label=\"Validation Loss\", color=\"red\", linestyle='--')\n",
        "    plt.xlabel(\"Epoch\", fontsize=18)\n",
        "    plt.ylabel(\"Loss\", fontsize=18)\n",
        "    plt.title(\"Training and Validation Loss\", fontsize=20)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
