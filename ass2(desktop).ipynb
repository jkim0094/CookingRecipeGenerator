{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "pnWO37v6oLFg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown\n",
        "from functools import partial\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import spacy\n",
        "import ast\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    DEVICE = 'mps'  # Apple GPU 사용\n",
        "elif torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'  # NVIDIA GPU 사용\n",
        "else:\n",
        "    DEVICE = 'cpu'   # CPU fallback\n",
        "\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "iuol8CxrHQZC"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzpEEDthSnhi",
        "outputId": "3677fb2b-d313-4960-fa2a-f5932daa0af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 162899\n",
            "Dev data size: 1065\n",
            "Test data size: 1081\n",
            "\n",
            "Train data sample:\n",
            "                      Title  \\\n",
            "0       No-Bake Nut Cookies   \n",
            "1               Creamy Corn   \n",
            "2      Reeses Cups(Candy)     \n",
            "3  Cheeseburger Potato Soup   \n",
            "4       Rhubarb Coffee Cake   \n",
            "\n",
            "                                         Ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "2  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "3  [\"6 baking potatoes\", \"1 lb. of extra lean gro...   \n",
            "4  [\"1 1/2 c. sugar\", \"1/2 c. butter\", \"1 egg\", \"...   \n",
            "\n",
            "                                              Recipe  \n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...  \n",
            "1  [\"In a slow cooker, combine all ingredients. C...  \n",
            "2  [\"Combine first four ingredients and press in ...  \n",
            "3  [\"Wash potatoes; prick several times with a fo...  \n",
            "4  [\"Cream sugar and butter.\", \"Add egg and beat ...  \n"
          ]
        }
      ],
      "source": [
        "# data 다운\n",
        "train_path = 'Cooking_Dataset/train.csv'\n",
        "dev_path = 'Cooking_Dataset/dev.csv'\n",
        "test_path = 'Cooking_Dataset/test.csv'\n",
        "\n",
        "\n",
        "if not os.path.exists('Cooking_Dataset'):\n",
        "    os.makedirs('Cooking_Dataset')\n",
        "    print(\"Downloading Dataset\") \n",
        "    gdown.download(\"https://drive.google.com/uc?id=1uZdYjvllt0dSdKKtrCgKHUk-APKdmeNU\", train_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1SAMbkdtjGBYgojqobiwe7ZmnEq7SiGsF\", dev_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1v6Rr2et_4WA5mRwwlRxtLhn38pbmr9Yr\", test_path, quiet=False)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "#train_df = train_df.sample(n=200,random_state=42)\n",
        "dev_df = pd.read_csv(dev_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Dev data size: {len(dev_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")\n",
        "print(\"\\nTrain data sample:\")\n",
        "print(train_df.head())\n",
        "#No-Bake Nut Cookies\n",
        "# [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n",
        "# [\"In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\", \"Stir over medium heat until mixture bubbles all over top.\", \"Boil and stir 5 minutes more. Take off heat.\", \"Stir in vanilla and cereal; mix well.\", \"Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\", \"Let stand until firm, about 30 minutes.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQwUvtETjCF",
        "outputId": "86b57a8d-0dd5-4fa7-abdf-0d96cb367749"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenizer_ingredient_baseline(text):\n",
        "    \"\"\"\n",
        "    Baseline 전처리: 소문자화 + lemmatization + 간단한 필터링\n",
        "    - stopword 제거 있음\n",
        "    - 숫자, 구두점 제거 있음\n",
        "    - 불필요한 복잡 전처리 없음\n",
        "    \"\"\"\n",
        "    import ast\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.like_num or token.is_stop:\n",
        "                    continue\n",
        "                tokens.append(token.lemma_.strip())  # 기본 lemmatization만 유지\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_recipe_baseline(text):\n",
        "    \"\"\"\n",
        "    Recipe 전처리: 소문자화 + lemmatization만 수행 (구두점, stopword, 숫자는 유지)\n",
        "    - 조리 순서, 동사 등 자연스러운 문장 흐름을 보존해야 하므로 간단한 전처리만 적용\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        doc = spacy_en(text.lower())\n",
        "        for token in doc:\n",
        "            # 너무 공격적인 필터링은 하지 않음\n",
        "            if token.is_space:\n",
        "                continue\n",
        "            tokens.append(token.lemma_.strip())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_ingredient_checklist(text, remove_stopwords=True, lemmatize=True):\n",
        "    text_list = ast.literal_eval(text)  # 문자열 → 리스트로 변환\n",
        "    unit_keywords = {\n",
        "        'c', 'cup', 'cups', 'tbsp', 'tablespoon', 'tsp', 'teaspoon',\n",
        "        'oz', 'ounce', 'lb', 'pound', 'g', 'kg', 'mg',\n",
        "        'pt', 'qt', 'gal', 'ml', 'l','carton','container',\n",
        "        'package', 'pkg', 'envelope', 'box', 'bag', 'jar', 'can', 'cans', 'bottle',\n",
        "        'dash', 'pinch', 'slice', 'slices', 'head', 'inch', 'inches',\n",
        "        'stick', 'sticks', 'small', 'medium', 'large', 'size','graham'\n",
        "    }\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue\n",
        "                if token.like_num:\n",
        "                    continue\n",
        "                if token.text.strip(\".\") in unit_keywords:\n",
        "                    continue\n",
        "                if remove_stopwords and token.is_stop:\n",
        "                    continue\n",
        "                if token.pos_ in {\"ADJ\", \"VERB\", \"ADV\", \"PRON\"}:\n",
        "                    continue\n",
        "\n",
        "                tokens.append(token.lemma_.strip() if lemmatize else token.text.strip())\n",
        "    \n",
        "\n",
        "    return tokens\n",
        "\n",
        "def tokenizer_recipe_extension(text):  # 디폴트: lemmatize 안 함\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    # tagger는 유지해서 lemma 써도 warning 없음\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())  # 소문자화\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue  # 마침표, 쉼표 제거\n",
        "                if token.like_num:  # 숫자 유지\n",
        "                    tokens.append(token.text.strip())\n",
        "                    continue\n",
        "                \n",
        "                tokens.append(token.text.strip())\n",
        "                \n",
        "    return tokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"In a slow cooker, combine all ingredients. Cover and cook on low for 4 hours or until heated through and cheese is melted. Stir well before serving. Yields 6 servings.\"]\n",
            "['in', 'a', 'slow', 'cooker', 'combine', 'all', 'ingredients', 'cover', 'and', 'cook', 'on', 'low', 'for', '4', 'hours', 'or', 'until', 'heated', 'through', 'and', 'cheese', 'is', 'melted', 'stir', 'well', 'before', 'serving', 'yields', '6', 'servings']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/psarda/repos/jkim0094-CookingRecipeGenerato/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "ing = train_df.iloc[1,2]\n",
        "print(ing)\n",
        "print(tokenizer_recipe_extension(ing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "O5IrjwMXuv3h"
      },
      "outputs": [],
      "source": [
        "def build_vocab(token_lists, min_freq=2):\n",
        "    # vocab 생성: 자주 등장하는 단어만 포함 + 특수 토큰 정의\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        token_lists,  # 토큰 리스트들을 직접 반복\n",
        "        min_freq=min_freq,  # 최소 등장 빈도\n",
        "        specials=['<pad>', '<sos>', '<eos>', '<unk>']  # 특수 토큰 추가\n",
        "    )\n",
        "    vocab.set_default_index(vocab['<unk>'])  # 없는 단어는 <unk>로 처리\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_or_tokenize_data(model_type, train_df, config=None):\n",
        "    use_checklist = config.get(\"USE_CHECKLIST\", False)\n",
        "\n",
        "    tokenizer_ingredient = tokenizer_ingredient_baseline\n",
        "    tokenizer_recipe = tokenizer_recipe_baseline\n",
        "    tokenizer_checklist = tokenizer_ingredient_checklist if use_checklist else None\n",
        "\n",
        "    ingredient_cache_path = \"tokens/ingredient_tokens.pkl\"\n",
        "    recipe_cache_path = \"tokens/recipe_tokens.pkl\"\n",
        "    checklist_cache_path = \"tokens/checklist_tokens.pkl\"\n",
        "\n",
        "    ingredient_cache_download = \"https://drive.google.com/uc?id=1Wxvq-qy4ifbzPKmcm_VuNRRXrEOSqisJ\"\n",
        "    recipe_cache_download = \"https://drive.google.com/uc?id=1IyBlDfL9sE8_Ip3muDyciCK9Hiv_VZF8\"\n",
        "    checklist_cache_download = \"https://drive.google.com/uc?id=1-WVksjq8Cgj6UiJ7wtemU2CfP4hhPrci\"\n",
        "\n",
        "    if not os.path.exists('tokens'):\n",
        "        os.makedirs('tokens')\n",
        "\n",
        "    cache_targets = [\n",
        "        (ingredient_cache_path, ingredient_cache_download),\n",
        "        (recipe_cache_path, recipe_cache_download)\n",
        "    ]\n",
        "    if use_checklist:\n",
        "        cache_targets.append((checklist_cache_path, checklist_cache_download))\n",
        "\n",
        "    for path, url in cache_targets:\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"⬇️  Downloading: {path}\")\n",
        "            try:\n",
        "                r = requests.get(url, allow_redirects=True)\n",
        "                if r.status_code == 200:\n",
        "                    with open(path, 'wb') as f:\n",
        "                        f.write(r.content)\n",
        "                    print(f\"✅ Downloaded: {path}\")\n",
        "                else:\n",
        "                    print(f\"❌ Download failed for {path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Download error: {e}\")\n",
        "\n",
        "    if os.path.exists(ingredient_cache_path):\n",
        "        with open(ingredient_cache_path, \"rb\") as f:\n",
        "            ingredient_token_lists = pickle.load(f)\n",
        "        print(\"✅ Loaded ingredient token cache.\")\n",
        "    else:\n",
        "        print(\"⚠️ No ingredient cache → Tokenizing...\")\n",
        "        ingredient_token_lists = [tokenizer_ingredient(text) for text in tqdm(train_df['Ingredients'], desc=\"Tokenizing ingredients\")]\n",
        "        with open(ingredient_cache_path, \"wb\") as f:\n",
        "            pickle.dump(ingredient_token_lists, f)\n",
        "\n",
        "    if os.path.exists(recipe_cache_path):\n",
        "        with open(recipe_cache_path, \"rb\") as f:\n",
        "            recipe_token_lists = pickle.load(f)\n",
        "        print(\"✅ Loaded recipe token cache.\")\n",
        "    else:\n",
        "        print(\"⚠️ No recipe cache → Tokenizing...\")\n",
        "        recipe_token_lists = [tokenizer_recipe(text) for text in tqdm(train_df['Recipe'], desc=\"Tokenizing recipes\")]\n",
        "        with open(recipe_cache_path, \"wb\") as f:\n",
        "            pickle.dump(recipe_token_lists, f)\n",
        "\n",
        "    ingredient_vocab = build_vocab(ingredient_token_lists, min_freq=1)\n",
        "    recipe_vocab = build_vocab(recipe_token_lists, min_freq=2)\n",
        "\n",
        "    checklist_vocab = None\n",
        "    if use_checklist:\n",
        "        if os.path.exists(checklist_cache_path):\n",
        "            with open(checklist_cache_path, \"rb\") as f:\n",
        "                checklist_token_lists = pickle.load(f)\n",
        "            print(\"✅ Loaded checklist token cache.\")\n",
        "        else:\n",
        "            print(\"⚠️ No checklist cache → Tokenizing...\")\n",
        "            checklist_token_lists = [tokenizer_checklist(text) for text in tqdm(train_df['Ingredients'], desc=\"Checklist tokenize\")]\n",
        "            with open(checklist_cache_path, \"wb\") as f:\n",
        "                pickle.dump(checklist_token_lists, f)\n",
        "\n",
        "        checklist_vocab = build_vocab(checklist_token_lists, min_freq=1)\n",
        "\n",
        "    return ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe, checklist_vocab, tokenizer_checklist\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_checklist_tensor(checklist_vocab, checklist_tokenizer, ingredient_texts, device, embedding_layer):\n",
        "    batch_ids = []\n",
        "\n",
        "\n",
        "\n",
        "    for text in ingredient_texts:\n",
        "        tokens = checklist_tokenizer(text)\n",
        "        ids = [checklist_vocab[token] for token in tokens]\n",
        "        batch_ids.append(torch.tensor(ids, dtype=torch.long))\n",
        "\n",
        "    checklist_padded = pad_sequence(batch_ids, batch_first=True, padding_value=checklist_vocab['<pad>']).to(device)\n",
        "    checklist_mask = (checklist_padded != checklist_vocab['<pad>']).float().to(device)\n",
        "    checklist_embeds = embedding_layer(checklist_padded)\n",
        "\n",
        "\n",
        "\n",
        "    return checklist_embeds, checklist_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "u3aRuH1BcoQQ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe):\n",
        "        self.df = df\n",
        "        self.ingredient_vocab = ingredient_vocab\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "        self.tokenizer_ingredient = tokenizer_ingredient\n",
        "        self.tokenizer_recipe = tokenizer_recipe\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ingredient_text = self.df.iloc[idx]['Ingredients']\n",
        "        recipe_text = self.df.iloc[idx]['Recipe']\n",
        "\n",
        "        ingredient_tokens = self.tokenizer_ingredient(ingredient_text)\n",
        "        recipe_tokens = self.tokenizer_recipe(recipe_text)\n",
        "\n",
        "        ingredient_ids = [self.ingredient_vocab['<sos>']] + [self.ingredient_vocab[token] for token in ingredient_tokens] + [self.ingredient_vocab['<eos>']]\n",
        "        recipe_ids = [self.recipe_vocab['<sos>']] + [self.recipe_vocab[token] for token in recipe_tokens] + [self.recipe_vocab['<eos>']]\n",
        "\n",
        "        return torch.tensor(ingredient_ids), torch.tensor(recipe_ids), ingredient_text  # ✅ 3개 반환\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "zvtpEXhJyzRN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, ingredient_vocab, recipe_vocab, device):\n",
        "    ingredients, recipes, ingredient_texts = zip(*batch)  # ingredient_texts: str\n",
        "    ingredients_padded = pad_sequence(ingredients, batch_first=True, padding_value=ingredient_vocab['<pad>'])\n",
        "    recipes_padded = pad_sequence(recipes, batch_first=True, padding_value=recipe_vocab['<pad>'])\n",
        "    return ingredients_padded.to(device), recipes_padded.to(device), list(ingredient_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "ZHuvOqpGoe5N"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        # 임베딩\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        \n",
        "\n",
        "        # GRU 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src : [batch_size, src_len]\n",
        "        src = src.long() \n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded : [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # gru 통과\n",
        "        outputs, hidden = self.gru(embedded) # h0를 따로 주지 않으면, 디폴트로 h0가 0로 초기화되서 들어감\n",
        "        # outputs: [batch_size, src_len, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        return outputs,hidden\n",
        "\n",
        "class Encoder_GRU_extension(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        self.ingredient_vocab_size = ingredient_vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        self.skip_proj = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self._init_weights()  # ✅ 초기화 적용\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # embedding 초기화 (from_pretrained 아닌 경우만)\n",
        "        if not hasattr(self.embedding, 'weight') or self.embedding.weight.requires_grad:\n",
        "            nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        # GRU 내부 weight 초기화\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='leaky_relu')\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "        # skip connection projection 초기화\n",
        "        nn.init.kaiming_normal_(self.skip_proj.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        nn.init.constant_(self.skip_proj.bias, 0)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = src.long()\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        skip = self.skip_proj(embedded)\n",
        "        outputs = self.leaky_relu(outputs + skip)\n",
        "        outputs = self.layer_norm(outputs)\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "\n",
        "class Decoder_GRU(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "\n",
        "        # 임베딩\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU 레이어\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # fc 레이어\n",
        "        self.fc_out = nn.Linear(hidden_dim, recipe_vocab_size)\n",
        "\n",
        "        # 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.long()\n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, 단어의 개수=1]\n",
        "\n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, 단어의 개수=1, hidden_dim]\n",
        "\n",
        "        # GRU 통과\n",
        "        outputs, hidden = self.gru(embedded,hidden)\n",
        "        # outputs: [batch_size, 단어의 개수=1, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        # fc 통과\n",
        "        prediction = self.fc_out(outputs.squeeze(1))\n",
        "        # prediction: [batch_size, vocab_size]\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "# Define a decoder with attention mechanism using PyTorch's nn.Module\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size,embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        # Initialize the base nn.Module class\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Save parameters\n",
        "        self.recipe_vocab_size = recipe_vocab_size              # Size of the output vocabulary\n",
        "        self.embedding_dim = embedding_dim                  # Dropout probability\n",
        "        self.hidden_size = hidden_size              # Size of the hidden state in GRU\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "                  \n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(self.recipe_vocab_size, self.hidden_size)  # Converts word indices to dense vectors\n",
        "        self.dropout = nn.Dropout(self.dropout_ratio)                          # Applies dropout for regularization\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.n_layers, dropout=self.dropout_ratio if self.n_layers>1 else 0, batch_first=True)\n",
        "             # GRU to process the embedded inputs\n",
        "        self.out = nn.Linear(self.hidden_size * 2, self.recipe_vocab_size)       # Linear layer for generating final output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.long() \n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, 단어의 개수=1]\n",
        "\n",
        "        # 임베딩\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, 단어의 개수=1, hidden_dim]\n",
        "\n",
        "        # Pass through GRU\n",
        "        output, hidden = self.gru(embedded, hidden)  # output: [batch, 1, hidden_size]\n",
        "\n",
        "        # Compute attention weights using dot-product attention:\n",
        "        # hidden[-1]: [batch, hidden_size]\n",
        "        # encoder_outputs: [batch, src_len, hidden_size]\n",
        "    \n",
        "        attn_weights = F.softmax(\n",
        "            torch.bmm(output, encoder_outputs.transpose(1, 2)), # [batch, 1, hidden_size] x [batch, hidden_size, src_len]\n",
        "            dim=-1\n",
        "        )  # [batch, 1, src_len]\n",
        "\n",
        "        # Apply attention weights to encoder outputs to get context vector\n",
        "        # attn_weights: (1, 1, max_length)\n",
        "        # encoder_outputs.unsqueeze(0): (1, max_length, hidden_size)\n",
        "        attn_output = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, hidden_size]\n",
        "\n",
        "        # Concatenate attention output and decoder hidden state\n",
        "        concat_output = torch.cat((output, attn_output), dim=2)  # [batch, 1, hidden*2]\n",
        "\n",
        "        # Pass through linear layer and softmax to get output word probabilities\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)  # [batch, vocab_size]\n",
        "\n",
        "        # Return output word distribution, updated hidden state, and attention weights\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "class AttnDecoderRNN_extension(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size * 2, recipe_vocab_size)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self._init_weights()  # ✅ He 초기화 호출\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Embedding\n",
        "        nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        # GRU weights & biases\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='leaky_relu')\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "        # Linear layer\n",
        "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        nn.init.constant_(self.out.bias, 0)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.long().unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.leaky_relu(output)\n",
        "        output = self.layer_norm(output)\n",
        "\n",
        "        attn_weights = F.softmax(torch.bmm(output, encoder_outputs.transpose(1, 2)), dim=-1)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)\n",
        "        concat_output = torch.cat((output, context), dim=2)\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "class DecoderWithChecklistCopy(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_size, n_layers, dropout_ratio,\n",
        "                 checklist_vocab_size, checklist_vocab, tokenizer_checklist,\n",
        "                 use_checklist=True, use_copy=False):\n",
        "        super().__init__()\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        self.out_proj = nn.Linear(hidden_size, recipe_vocab_size)\n",
        "        self.attn_proj = nn.Linear(hidden_size, hidden_size)  # for both checklist & encoder attention\n",
        "        self.ref_selector = nn.Linear(hidden_size, 3)\n",
        "\n",
        "        self.use_checklist = use_checklist\n",
        "        self.use_copy = use_copy\n",
        "\n",
        "        # Checklist\n",
        "        if self.use_checklist:\n",
        "            self.checklist_embedding = nn.Embedding(checklist_vocab_size, hidden_size)\n",
        "            self.checklist_max_len = checklist_vocab_size\n",
        "            self.checklist_vocab = checklist_vocab\n",
        "            self.tokenizer_checklist = tokenizer_checklist\n",
        "            self.a_prev_list = []\n",
        "\n",
        "        # Copy\n",
        "        if self.use_copy:\n",
        "            self.copy_attn = nn.Linear(hidden_size, hidden_size)\n",
        "            self.copy_score = nn.Linear(hidden_size, 1)  # to compute p_gen\n",
        "\n",
        "    def forward(self, input_token, hidden, encoder_outputs=None,\n",
        "                ingredient_texts=None, a_prev=None, checklist_embeds=None,\n",
        "                checklist_mask=None, encoder_input_ids=None, **kwargs):\n",
        "\n",
        "        input_token = input_token.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        gru_out, hidden = self.gru(embedded, hidden)\n",
        "        h_t = gru_out.squeeze(1)  # [batch, hidden_dim]\n",
        "\n",
        "        # === Checklist ===\n",
        "        if self.use_checklist and ingredient_texts is not None and a_prev is not None:\n",
        "            batch_ids = []\n",
        "            for text in ingredient_texts:\n",
        "                tokens = self.tokenizer_checklist(text)\n",
        "                ids = [self.checklist_vocab[token] for token in tokens]\n",
        "                batch_ids.append(torch.tensor(ids, dtype=torch.long))\n",
        "            padded = pad_sequence(batch_ids, batch_first=True, padding_value=0)\n",
        "            checklist_embeds = self.checklist_embedding(padded.to(input_token.device))\n",
        "            checklist_mask = (padded != 0).float().to(input_token.device)\n",
        "\n",
        "            used_mask = a_prev.clamp(0, 1).unsqueeze(2)\n",
        "            unused_mask = (1 - a_prev).clamp(0, 1).unsqueeze(2)\n",
        "            E_new = checklist_embeds * unused_mask\n",
        "            E_used = checklist_embeds * used_mask\n",
        "\n",
        "            h_proj = self.attn_proj(h_t).unsqueeze(2)\n",
        "            scores_new = torch.bmm(E_new, h_proj).squeeze(2)\n",
        "            scores_used = torch.bmm(E_used, h_proj).squeeze(2)\n",
        "\n",
        "            scores_new = scores_new.masked_fill(checklist_mask == 0, -1e9)\n",
        "            scores_used = scores_used.masked_fill(checklist_mask == 0, -1e9)\n",
        "\n",
        "            alpha_new = F.softmax(scores_new, dim=1)\n",
        "            alpha_used = F.softmax(scores_used, dim=1)\n",
        "\n",
        "            c_new = torch.bmm(alpha_new.unsqueeze(1), checklist_embeds).squeeze(1)\n",
        "            c_used = torch.bmm(alpha_used.unsqueeze(1), checklist_embeds).squeeze(1)\n",
        "        else:\n",
        "            alpha_new = alpha_used = None\n",
        "            c_new = c_used = torch.zeros_like(h_t)\n",
        "\n",
        "        # === Copy ===\n",
        "        if self.use_copy and encoder_outputs is not None:\n",
        "            attn_scores = torch.bmm(encoder_outputs, h_t.unsqueeze(2)).squeeze(2)\n",
        "            attn_weights = F.softmax(attn_scores, dim=1)\n",
        "            context_vector = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
        "            # p_gen gate\n",
        "            p_gen_input = torch.cat([h_t, context_vector], dim=1)\n",
        "            p_gen = torch.sigmoid(self.copy_score(p_gen_input))\n",
        "        else:\n",
        "            context_vector = torch.zeros_like(h_t)\n",
        "            p_gen = torch.ones((h_t.size(0), 1), device=h_t.device)\n",
        "\n",
        "        # === Output ===\n",
        "        f_logits = self.ref_selector(h_t)\n",
        "        f = F.softmax(f_logits, dim=-1)\n",
        "        f_gru, f_new, f_used = f.chunk(3, dim=1)\n",
        "\n",
        "        o_t = f_gru * h_t + f_new * c_new + f_used * c_used + context_vector\n",
        "        output = self.out_proj(o_t)\n",
        "\n",
        "        # === Coverage update ===\n",
        "        if self.use_checklist and self.training:\n",
        "            if not hasattr(self, \"a_prev_list\"):\n",
        "                self.a_prev_list = []\n",
        "            self.a_prev_list.append((a_prev.detach(), alpha_new.detach()))\n",
        "\n",
        "        a_t = a_prev + f_new * alpha_new if self.use_checklist else None\n",
        "        return output, hidden, a_t, alpha_new, alpha_used\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, use_attention, recipe_vocab):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.use_attention = use_attention\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "\n",
        "    def forward(self, src, ingredient_texts=None, target=None,\n",
        "                teacher_forcing_ratio=0.5, max_len=50):\n",
        "        \n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        batch_size = src.size(0)\n",
        "        vocab_size = self.decoder.recipe_vocab_size\n",
        "\n",
        "        # ✅ Decoder 기능 판단\n",
        "        use_checklist = getattr(self.decoder, 'use_checklist', False)\n",
        "        use_copy = getattr(self.decoder, 'use_copy', False)\n",
        "\n",
        "        # ✅ Checklist 준비\n",
        "        checklist_embed, checklist_mask = None, None\n",
        "        if use_checklist:\n",
        "            checklist_embed, checklist_mask = get_checklist_tensor(\n",
        "                checklist_vocab=self.decoder.checklist_vocab,\n",
        "                checklist_tokenizer=self.decoder.tokenizer_checklist,\n",
        "                ingredient_texts=ingredient_texts,\n",
        "                device=self.device,\n",
        "                embedding_layer=self.decoder.checklist_embedding\n",
        "            )\n",
        "\n",
        "        a_prev = None\n",
        "        if checklist_mask is not None:\n",
        "            checklist_len = checklist_mask.size(1)\n",
        "            a_prev = torch.zeros(batch_size, checklist_len, device=self.device)\n",
        "\n",
        "        # ▶️ Inference Mode\n",
        "        if target is None:\n",
        "            outputs = []\n",
        "            input_token = torch.tensor([self.recipe_vocab['<sos>']] * batch_size).to(self.device).long()\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                if use_checklist or use_copy:\n",
        "                    output, hidden, a_prev, *_ = self.decoder(\n",
        "                        input_token, hidden, encoder_outputs,\n",
        "                        ingredient_texts=ingredient_texts,\n",
        "                        a_prev=a_prev,\n",
        "                        checklist_embeds=checklist_embed,\n",
        "                        checklist_mask=checklist_mask,\n",
        "                        encoder_input_ids=src\n",
        "                    )\n",
        "                elif self.use_attention:\n",
        "                    result = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                    output, hidden = result[:2] if isinstance(result, (tuple, list)) else result\n",
        "                else:\n",
        "                    output, hidden = self.decoder(input_token, hidden)\n",
        "\n",
        "                top1 = output.argmax(1)\n",
        "                outputs.append(top1.unsqueeze(1))\n",
        "                input_token = top1\n",
        "\n",
        "            return torch.cat(outputs, dim=1)\n",
        "\n",
        "        # 🟢 Training Mode\n",
        "        target = target.long()\n",
        "        target_len = target.shape[1]\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
        "        input_token = target[:, 0].long()\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            if use_checklist or use_copy:\n",
        "                output, hidden, a_prev, *_ = self.decoder(\n",
        "                    input_token, hidden, encoder_outputs,\n",
        "                    ingredient_texts=ingredient_texts,\n",
        "                    a_prev=a_prev,\n",
        "                    checklist_embeds=checklist_embed,\n",
        "                    checklist_mask=checklist_mask,\n",
        "                    encoder_input_ids=src\n",
        "                )\n",
        "            elif self.use_attention:\n",
        "                result = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                output, hidden = result[:2] if isinstance(result, (tuple, list)) else result\n",
        "            else:\n",
        "                output, hidden = self.decoder(input_token, hidden)\n",
        "\n",
        "            outputs[:, t, :] = output\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            input_token = target[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class IngredientAutoEncoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, src):\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        input_token = src[:, 0]  # <sos> token\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(1, src.size(1)):\n",
        "            output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            outputs.append(output.unsqueeze(1))  # [batch_size, 1, vocab_size]\n",
        "\n",
        "            # ✅ Teacher Forcing\n",
        "            input_token = src[:, t]  # use ground-truth token\n",
        "\n",
        "        # [batch_size, T-1, vocab_size]\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_glove_embedding_matrix(glove_path, vocab, glove_dim=200):\n",
        "    print(\"🔎 Loading GloVe vectors...\")\n",
        "    glove_embeddings = {}\n",
        "\n",
        "    with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = torch.tensor(list(map(float, values[1:])))\n",
        "            glove_embeddings[word] = vector\n",
        "\n",
        "    # Initialize matrix with random vectors\n",
        "    embedding_matrix = torch.randn(len(vocab), glove_dim)\n",
        "\n",
        "    for word, idx in vocab.get_stoi().items():\n",
        "        if word in glove_embeddings:\n",
        "            embedding_matrix[idx] = glove_embeddings[word]\n",
        "\n",
        "    print(\"✅ GloVe embedding matrix created.\")\n",
        "    return embedding_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_epoch(model, dataloader, criterion, optimizer=None,\n",
        "               teacher_forcing_ratio=0.5, max_len=50,\n",
        "               USE_PENALTY=False, penalty_lambda=0.2):\n",
        "    total_loss = 0\n",
        "    batch_losses = []\n",
        "\n",
        "    if hasattr(model.decoder, \"a_prev_list\"):\n",
        "        model.decoder.a_prev_list = []\n",
        "\n",
        "    for i, (src_batch, trg_batch, ingredient_texts) in enumerate(dataloader):\n",
        "        src_batch = src_batch.to(DEVICE)\n",
        "        trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "        output = model(src_batch, ingredient_texts, trg_batch,\n",
        "                       teacher_forcing_ratio=teacher_forcing_ratio,\n",
        "                       max_len=max_len)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        if USE_PENALTY and hasattr(model.decoder, 'a_prev_list'):\n",
        "            penalty = 0.0\n",
        "            for a_prev, alpha_new in model.decoder.a_prev_list:\n",
        "                penalty += torch.sum(torch.min(a_prev, alpha_new))\n",
        "            penalty = penalty / src_batch.size(0)\n",
        "            loss += penalty_lambda * penalty\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item() * src_batch.shape[0]\n",
        "        batch_losses.append(batch_loss)\n",
        "        total_loss += batch_loss\n",
        "        print(f\"Batch {i+1}/{len(dataloader)} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader.dataset)\n",
        "    return epoch_loss, batch_losses\n",
        "\n",
        "\n",
        "def Train(model, train_loader, val_loader, criterion, optimizer, recipe_vocab,\n",
        "          EPOCHS, BATCH_SIZE, TRAIN_RATIO,\n",
        "          save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs):\n",
        "\n",
        "    lr_step = kwargs.get(\"LR_STEP\")\n",
        "    lr_gamma = kwargs.get(\"LR_GAMMA\")\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=lr_gamma) if lr_step and lr_gamma else None\n",
        "\n",
        "    USE_PENALTY = kwargs.get(\"USE_PENALTY\", False)\n",
        "    PENALTY_LAMBDA = kwargs.get(\"PENALTY_LAMBDA\", 0.2)\n",
        "\n",
        "    loss_history = {\"train_epoch\": [], \"train_iter\": [], \"val_epoch\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    train_start_time = time.time()\n",
        "    best_epoch = -1\n",
        "    best_train_loss = None\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        ep_start_time = time.time()\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        print(f\"[Epoch: {ep+1}/{EPOCHS}] current_LR = {current_lr}\")\n",
        "\n",
        "        model.train()\n",
        "        train_epoch_loss, train_batch_loss = loss_epoch(\n",
        "            model, train_loader, criterion, optimizer,\n",
        "            teacher_forcing_ratio=TEACHER_FORCING_RATIO,\n",
        "            max_len=MAX_LEN,\n",
        "            USE_PENALTY=USE_PENALTY,\n",
        "            penalty_lambda=PENALTY_LAMBDA\n",
        "        )\n",
        "        loss_history[\"train_epoch\"].append(train_epoch_loss)\n",
        "        loss_history[\"train_iter\"].append(train_batch_loss)\n",
        "        print(f\"{ep+1} Epoch Train Completed!\")\n",
        "\n",
        "        print(\"Validation Start!\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, _ = loss_epoch(\n",
        "                model, val_loader, criterion, optimizer=None,\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                max_len=MAX_LEN,\n",
        "                USE_PENALTY=USE_PENALTY,\n",
        "                penalty_lambda=PENALTY_LAMBDA\n",
        "            )\n",
        "            loss_history[\"val_epoch\"].append(val_loss)\n",
        "        print(\"Validation Completed!\")\n",
        "\n",
        "        ep_elapsed_time = time.time() - ep_start_time\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"[Epoch {ep+1}/{EPOCHS}] \")\n",
        "        print(f\"Train Loss: {train_epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {ep_elapsed_time:.2f}s\")\n",
        "        bleu, meteor, bert_f1 = compute_metrics(model, val_loader, recipe_vocab, max_len=MAX_LEN)\n",
        "        print(f\"Validation Metrics:\")\n",
        "        print(f\"📊 BLEU: {bleu:.4f} | METEOR: {meteor:.4f} | BERTScore-F1: {bert_f1:.4f}\")  \n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = ep+1\n",
        "            best_train_loss = train_epoch_loss\n",
        "            best_bleu, best_meteor, best_bert_f1 = bleu, meteor, bert_f1\n",
        "            os.makedirs(\"results\", exist_ok=True)\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": ep+1,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"train_loss\": train_epoch_loss,\n",
        "            }, save_model_path)\n",
        "            print(\"Best model saved!\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    final_model_path = save_model_path.replace(\".pt\", \"_final.pt\")\n",
        "    torch.save({\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"epoch\": EPOCHS,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"train_loss\": train_epoch_loss,\n",
        "    }, final_model_path)\n",
        "    print(\"Final model saved!\")\n",
        "\n",
        "    train_elapsed_time = time.time() - train_start_time\n",
        "    total_iterations = sum(len(batch_list) for batch_list in loss_history[\"train_iter\"])\n",
        "    torch.save({\n",
        "        \"loss_history\": loss_history,\n",
        "        \"EPOCHS\": EPOCHS,\n",
        "        \"BATCH_SIZE\": BATCH_SIZE,   \n",
        "        \"TRAIN_RATIO\": TRAIN_RATIO,\n",
        "        \"train_elapsed_time\": train_elapsed_time,\n",
        "        \"total_iterations\": total_iterations,\n",
        "        \"LR_STEP\": kwargs.get(\"LR_STEP\"),\n",
        "        \"LR_GAMMA\": kwargs.get(\"LR_GAMMA\")\n",
        "    }, save_history_path)\n",
        "    print(\"Training Completed!\")\n",
        "    print(f\"Total number of iteration : {total_iterations}\")\n",
        "    print(f\"Total Time for Training: {train_elapsed_time:.2f}s\")\n",
        "\n",
        "    print(\"\\n======= Training Summary =======\")\n",
        "    print(f\"Best Model:    Epoch {best_epoch}\")\n",
        "    if best_epoch == EPOCHS:\n",
        "        print(f\"(Best model is the final model)\")\n",
        "    print(f\"Train Loss:    {best_train_loss:.4f}\")\n",
        "    print(f\"Val Loss:      {best_val_loss:.4f}\")\n",
        "    print(f\"BLEU:          {best_bleu:.4f}\")\n",
        "    print(f\"METEOR:        {best_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1:  {best_bert_f1:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"Final Model:   Epoch {EPOCHS}\")\n",
        "    print(f\"Train Loss:    {train_epoch_loss:.4f}\")\n",
        "    print(f\"Val Loss:      {val_loss:.4f}\")\n",
        "    print(f\"BLEU:          {bleu:.4f}\")\n",
        "    print(f\"METEOR:        {meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1:  {bert_f1:.4f}\")\n",
        "    print(f\"Total Time:     {train_elapsed_time:.2f}s\")\n",
        "    print(\"==================================\\n\")\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import gc\n",
        "\n",
        "def train_autoencoder(model, dataloader, criterion, optimizer, epochs, device, label=\"AutoEncoder\"):\n",
        "    model.train()\n",
        "    scaler = GradScaler()  # mixed precision scaler\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src_batch, _, _ in dataloader:\n",
        "            src_batch = src_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():  # AMP 시작\n",
        "                output = model(src_batch)\n",
        "                trg = src_batch[:, 1:].contiguous()\n",
        "\n",
        "                output = output.view(-1, output.size(-1))\n",
        "                trg = trg.view(-1)\n",
        "\n",
        "                loss = criterion(output, trg)\n",
        "\n",
        "            # backward + optimizer step (with scaler)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"[Epoch {ep+1}] {label} Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "def Test(model, test_loader, criterion, recipe_vocab, MAX_LEN,\n",
        "         USE_PENALTY=False, penalty_lambda=0.2):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss, _ = loss_epoch(\n",
        "            model,\n",
        "            test_loader,\n",
        "            criterion,\n",
        "            optimizer=None,\n",
        "            teacher_forcing_ratio=0.0,\n",
        "            max_len=MAX_LEN,\n",
        "            USE_PENALTY=USE_PENALTY,\n",
        "            penalty_lambda=penalty_lambda\n",
        "        )\n",
        "\n",
        "    # 평가 지표 계산\n",
        "    bleu_score, meteor_avg, bertscore_f1 = compute_metrics(model, test_loader, recipe_vocab)\n",
        "\n",
        "    print(f\"Test Loss      : {test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score   : {bleu_score:.4f}\")\n",
        "    print(f\"METEOR Score   : {meteor_avg:.4f}\")\n",
        "    print(f\"BERTScore (F1) : {bertscore_f1:.4f}\")\n",
        "\n",
        "    return test_loss, bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(model, dataloader, recipe_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    테스트셋 전체에서 BLEU, METEOR, BERTScore 계산\n",
        "\n",
        "    Returns:\n",
        "        bleu_score (float), meteor_avg (float), bertscore_f1 (float)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    ref_list = []\n",
        "    hyp_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, trg_batch, ingredient_texts in tqdm(dataloader, desc=\"Evaluating Metrics\"):\n",
        "\n",
        "            src_batch = src_batch.to(DEVICE)\n",
        "            trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "            generated = model(src_batch, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "\n",
        "            for i in range(src_batch.size(0)):\n",
        "                pred_tokens = generated[i].tolist()\n",
        "                trg_tokens = trg_batch[i].tolist()\n",
        "\n",
        "                # <eos> 기준으로 자르기\n",
        "                if recipe_vocab['<eos>'] in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[:pred_tokens.index(recipe_vocab['<eos>'])]\n",
        "                if recipe_vocab['<eos>'] in trg_tokens:\n",
        "                    trg_tokens = trg_tokens[:trg_tokens.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "                pred_words = [recipe_vocab.get_itos()[idx] for idx in pred_tokens]\n",
        "                trg_words = [recipe_vocab.get_itos()[idx] for idx in trg_tokens]\n",
        "\n",
        "                ref_list.append(trg_words)\n",
        "                hyp_list.append(pred_words)\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_score = corpus_bleu([[ref] for ref in ref_list], hyp_list, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie) \n",
        "\n",
        "    # METEOR\n",
        "    meteor_scores = [meteor_score([ref], hyp) for ref, hyp in zip(ref_list, hyp_list)]\n",
        "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "    # BERTScore\n",
        "    refs = [\" \".join(ref) for ref in ref_list]\n",
        "    hyps = [\" \".join(hyp) for hyp in hyp_list]\n",
        "    _, _, f1 = bert_score_fn(hyps, refs, lang='en', verbose=False)\n",
        "    bertscore_f1 = f1.mean().item()\n",
        "\n",
        "    return bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "def plot_loss_epoch(name, loss_history):\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    train_loss = loss_history[\"train_epoch\"]\n",
        "    val_loss = loss_history[\"val_epoch\"]\n",
        "\n",
        "    plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(range(1, len(val_loss) + 1), val_loss, label=\"Validation Loss\", color=\"red\")\n",
        "\n",
        "    plt.xlabel(\"Epoch\", fontsize=10)\n",
        "    plt.ylabel(\"Loss\", fontsize=10)\n",
        "    plt.title(f\"Loss per Epoch: {name}\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_encoder_decoder(model_type, config, input_dim, output_dim, embedding_weights=None, freeze_embedding=False, checklist_vocab=None, tokenizer_checklist=None):\n",
        "    use_attention = config[\"USE_ATTENTION\"]\n",
        "    is_extension = \"extension\" in model_type\n",
        "\n",
        "    if is_extension:\n",
        "        encoder = Encoder_GRU_extension(\n",
        "            ingredient_vocab_size=input_dim,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"],\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze=freeze_embedding\n",
        "        )\n",
        "        if config.get(\"USE_CHECKLIST\", False):\n",
        "            decoder = DecoderWithChecklistCopy(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"],\n",
        "                checklist_vocab_size=len(checklist_vocab),\n",
        "                checklist_vocab=checklist_vocab,\n",
        "                tokenizer_checklist=tokenizer_checklist\n",
        "            )\n",
        "        else:\n",
        "            decoder = AttnDecoderRNN_extension(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "    else:\n",
        "        encoder = Encoder_GRU(\n",
        "            ingredient_vocab_size=input_dim,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"],\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze=freeze_embedding\n",
        "        )\n",
        "        if use_attention:\n",
        "            decoder = AttnDecoderRNN(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "        else:\n",
        "            decoder = Decoder_GRU(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "\n",
        "    return encoder, decoder\n",
        "\n",
        "\n",
        "\n",
        "def main(model_type: str, config: dict,\n",
        "         train_df, dev_df, test_df,\n",
        "         glove_path: str = \"./glove.6B.200d.txt\"):\n",
        "\n",
        "    # 1. Tokenize & Vocab\n",
        "    ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe, checklist_vocab, tokenizer_checklist = load_or_tokenize_data(model_type, train_df, config)\n",
        "\n",
        "    # 2. GloVe 임베딩 적용 여부\n",
        "    embedding_weights = None\n",
        "    freeze_embedding = config.get(\"freeze_embedding\", False)\n",
        "    if config.get(\"use_glove\", False):\n",
        "        print(f\"🔎 Using GloVe embeddings for {model_type}\")\n",
        "        ingredient_embedding_matrix = build_glove_embedding_matrix(\n",
        "            glove_path, ingredient_vocab, glove_dim=config[\"EMBED_DIM\"]\n",
        "        )\n",
        "        embedding_weights = ingredient_embedding_matrix\n",
        "\n",
        "    # 3. Dataset & DataLoader\n",
        "    BATCH_SIZE = config.get(\"BATCH_SIZE\", 64)\n",
        "    BATCH_SIZE_AUTOENCODER = config.get(\"BATCH_SIZE_AUTOENCODER\", 32)\n",
        "    train_dataset = CustomDataset(train_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    dev_dataset = CustomDataset(dev_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    test_dataset = CustomDataset(test_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    collate = partial(collate_fn, ingredient_vocab=ingredient_vocab, recipe_vocab=recipe_vocab, device=DEVICE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
        "    train_loader_autoencoder = DataLoader(train_dataset, batch_size=BATCH_SIZE_AUTOENCODER, shuffle=True, collate_fn=collate)\n",
        "\n",
        "    # ✅ 4. AutoEncoder 사전학습 여부에 따라 사전학습 실행 (ingredient_vocab 사용)\n",
        "    if config.get(\"USE_AUTOENCODER\", False):\n",
        "        print(f\"📦 AutoEncoder pretraining required for {model_type}\")\n",
        "        MakingAutoEncoder(\n",
        "            model_type=model_type,\n",
        "            config=config,\n",
        "            input_vocab=ingredient_vocab,\n",
        "            train_loader=train_loader_autoencoder,\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze_embedding=freeze_embedding,\n",
        "            device=DEVICE\n",
        "        )\n",
        "\n",
        "    # 5. Model 구성 (recipe_vocab 사용)\n",
        "    INPUT_DIM = len(ingredient_vocab)\n",
        "    OUTPUT_DIM = len(recipe_vocab)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "\n",
        "    encoder, decoder = get_encoder_decoder(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze_embedding=freeze_embedding,\n",
        "        checklist_vocab=checklist_vocab,\n",
        "        tokenizer_checklist=tokenizer_checklist\n",
        "    )\n",
        "\n",
        "    # ✅ 6. 사전학습된 AutoEncoder 인코더 가중치만 로드\n",
        "    if config.get(\"USE_AUTOENCODER\", False):\n",
        "        encoder_path = f\"results/{model_type}_encoder_pretrained.pt\"\n",
        "        print(f\"🔁 Loading pretrained AutoEncoder encoder weights for {model_type}\")\n",
        "        encoder.load_state_dict(torch.load(encoder_path, map_location=DEVICE))\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"], recipe_vocab=recipe_vocab).to(DEVICE)\n",
        "\n",
        "    # 7. 학습 또는 로드\n",
        "    save_model_path = f\"results/{model_type}.pt\"\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    if config[\"new_model_train\"]:\n",
        "        print(f\"Training model: {model_type}\")\n",
        "        print(model)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n",
        "        loss_history = Train(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=dev_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            recipe_vocab=recipe_vocab,\n",
        "            EPOCHS=config[\"EPOCHS\"],\n",
        "            BATCH_SIZE=BATCH_SIZE,\n",
        "            TRAIN_RATIO=1.0,\n",
        "            save_model_path=save_model_path,\n",
        "            save_history_path=save_history_path,\n",
        "            TEACHER_FORCING_RATIO=config[\"TEACHER_FORCING_RATIO\"],\n",
        "            MAX_LEN=config[\"MAX_LEN\"],\n",
        "            LR_STEP=config.get(\"LR_STEP\"),\n",
        "            LR_GAMMA=config.get(\"LR_GAMMA\"),\n",
        "            USE_PENALTY=config.get(\"USE_PENALTY\", False),\n",
        "            PENALTY_LAMBDA=config.get(\"PENALTY_LAMBDA\", 0.2)\n",
        "        )\n",
        "        return model, encoder, decoder, loss_history, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab\n",
        "\n",
        "    else:\n",
        "        return model, encoder, decoder, None, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 저장\n",
        "experiment_configs = {\n",
        "    \"baseline1\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": False,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"baseline2\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"mild_extension1\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 256,\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 3,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"BATCH_SIZE\": 64,\n",
        "        \"USE_AUTOENCODER\": True,\n",
        "        \"AUTOENCODER_EPOCHS\": 5,\n",
        "    },\n",
        "    \"mild_extension2\": {\n",
        "        \"new_model_train\" : True,\n",
        "        \"EMBED_DIM\": 200,  # GloVe 6B 200D와 일치\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 2,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"use_glove\": True,   \n",
        "        \"freeze_embedding\": False,\n",
        "        \"BATCH_SIZE\": 64,\n",
        "        \"USE_AUTOENCODER\": True,\n",
        "        \"AUTOENCODER_EPOCHS\": 5,\n",
        "    },\n",
        "    \"spicy_extension1\": {\n",
        "    \"new_model_train\": False,\n",
        "    \"EMBED_DIM\": 256,\n",
        "    \"HIDDEN_DIM\": 512,\n",
        "    \"DROPOUT\": 0.5,\n",
        "    \"N_LAYERS\": 3,\n",
        "    \"LR\": 0.001,\n",
        "    \"EPOCHS\": 2,\n",
        "    \"USE_ATTENTION\": True,\n",
        "    \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "    \"MAX_LEN\": 100,\n",
        "    \"LR_STEP\": 1,\n",
        "    \"LR_GAMMA\": 0.7,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"USE_CHECKLIST\": True,       # checklist 메커니즘\n",
        "    \"USE_PENALTY\": True,         # coverage loss 사용\n",
        "    \"PENALTY_LAMBDA\": 0.2        # coverage loss 가중치\n",
        "},\n",
        "\"spicy_extension2\": {\n",
        "    \"new_model_train\": False,\n",
        "    \"EMBED_DIM\": 256,\n",
        "    \"HIDDEN_DIM\": 512,\n",
        "    \"DROPOUT\": 0.5,\n",
        "    \"N_LAYERS\": 2,\n",
        "    \"LR\": 0.001,\n",
        "    \"EPOCHS\": 2,\n",
        "    \"USE_ATTENTION\": True,\n",
        "    \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "    \"MAX_LEN\": 100,\n",
        "    \"LR_STEP\": 1,\n",
        "    \"LR_GAMMA\": 0.7,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"USE_CHECKLIST\": True,   # checklist attention\n",
        "    \"USE_COPY\": True         # copy mechanism\n",
        "}\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MakingAutoEncoder(model_type, config, input_vocab, train_loader,\n",
        "                      embedding_weights=None, freeze_embedding=False,device=DEVICE):\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "    INPUT_DIM = len(input_vocab)\n",
        "\n",
        "    # 1. Encoder / Decoder 준비 (입력 = 출력)\n",
        "    encoder, decoder = get_encoder_decoder(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=INPUT_DIM,\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze_embedding=freeze_embedding\n",
        "    )\n",
        "\n",
        "    # 2. AutoEncoder 구성\n",
        "    autoencoder = IngredientAutoEncoder(encoder, decoder, vocab_size=INPUT_DIM).to(device)\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=config.get(\"LR\", 0.001))\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=input_vocab['<pad>'])\n",
        "\n",
        "    # 3. 학습\n",
        "    print(f\"🚀 Pretraining AutoEncoder for {model_type}\")\n",
        "    train_autoencoder(autoencoder, train_loader, criterion, optimizer,\n",
        "                      epochs=config.get(\"AUTOENCODER_EPOCHS\", 5), device=device)\n",
        "\n",
        "    # 4. 저장\n",
        "    torch.save(encoder.state_dict(), f\"results/{model_type}_encoder_pretrained.pt\")\n",
        "    torch.save(decoder.state_dict(), f\"results/{model_type}_decoder_pretrained.pt\")\n",
        "    print(f\"✅ Saved pretrained encoder/decoder for {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_trained_model(model_type: str, config: dict, device=DEVICE):\n",
        "    \"\"\"\n",
        "    best model과 final model을 모두 불러옵니다.\n",
        "\n",
        "    Args:\n",
        "        model_type (str): 저장 파일 이름 결정에 사용되는 모델 이름\n",
        "        config (dict): 설정 정보 (input_dim, output_dim, attention 등 포함)\n",
        "        device (torch.device): 모델을 로드할 디바이스\n",
        "\n",
        "    Returns:\n",
        "        best_model (nn.Module)\n",
        "        final_model (nn.Module)\n",
        "        loss_history (dict)\n",
        "        best_checkpoint (dict)\n",
        "        final_checkpoint (dict)\n",
        "    \"\"\"\n",
        "    # 경로 구성\n",
        "    best_model_path = f\"results/{model_type}.pt\"\n",
        "    final_model_path = best_model_path.replace(\".pt\", \"_final.pt\")\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    INPUT_DIM = config[\"input_dim\"]\n",
        "    OUTPUT_DIM = config[\"output_dim\"]\n",
        "    embedding_weights = config.get(\"embedding_weights\", None)\n",
        "    freeze_embedding = config.get(\"freeze_embedding\", False)\n",
        "    checklist_vocab = config.get(\"checklist_vocab\", None)\n",
        "    tokenizer_checklist = config.get(\"tokenizer_checklist\", None)\n",
        "    recipe_vocab = config[\"recipe_vocab\"]\n",
        "\n",
        "    def build_model():\n",
        "        encoder, decoder = get_encoder_decoder(\n",
        "            model_type=model_type,\n",
        "            config=config,\n",
        "            input_dim=INPUT_DIM,\n",
        "            output_dim=OUTPUT_DIM,\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze_embedding=freeze_embedding,\n",
        "            checklist_vocab=checklist_vocab,\n",
        "            tokenizer_checklist=tokenizer_checklist\n",
        "        )\n",
        "        return Seq2Seq(encoder, decoder, device, use_attention=config[\"USE_ATTENTION\"], recipe_vocab=recipe_vocab).to(device)\n",
        "\n",
        "    # ✅ Best model\n",
        "    best_model = build_model()\n",
        "    best_checkpoint = torch.load(best_model_path, map_location=device)\n",
        "    best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    # ✅ Final model\n",
        "    final_model = build_model()\n",
        "    final_checkpoint = torch.load(final_model_path, map_location=device)\n",
        "    final_model.load_state_dict(final_checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    # ✅ 학습 이력\n",
        "    history = torch.load(save_history_path, map_location=device)\n",
        "    loss_history = history[\"loss_history\"]\n",
        "\n",
        "    print(f\"📥 Loaded BEST model (Epoch {best_checkpoint['epoch']})\")\n",
        "    print(f\"📥 Loaded FINAL model (Epoch {final_checkpoint['epoch']})\")\n",
        "\n",
        "    return best_model, final_model, loss_history, best_checkpoint, final_checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_and_test_model(model_type: str,\n",
        "                             config: dict,\n",
        "                             ingredient_vocab,\n",
        "                             recipe_vocab,\n",
        "                             test_loader,\n",
        "                             criterion,\n",
        "                             tokenizer_checklist=None,\n",
        "                             checklist_vocab=None,\n",
        "                             embedding_weights=None,\n",
        "                             device=DEVICE):\n",
        "    \"\"\"\n",
        "    저장된 best/final 모델을 불러와 summary, 그래프, 테스트 수행\n",
        "    \"\"\"\n",
        "\n",
        "    # config에 input/output dim 등 필요한 정보 추가 (원본 손상 X)\n",
        "    config = config.copy()\n",
        "    config[\"input_dim\"] = len(ingredient_vocab)\n",
        "    config[\"output_dim\"] = len(recipe_vocab)\n",
        "    config[\"recipe_vocab\"] = recipe_vocab\n",
        "    config[\"embedding_weights\"] = embedding_weights\n",
        "    config[\"checklist_vocab\"] = checklist_vocab\n",
        "    config[\"tokenizer_checklist\"] = tokenizer_checklist\n",
        "\n",
        "    # ✅ 모델 두 개 모두 불러오기\n",
        "    best_model, final_model, loss_history, best_ckpt, final_ckpt = load_trained_model(\n",
        "        model_type, config, device\n",
        "    )\n",
        "\n",
        "    # ✅ 손실 곡선 시각화\n",
        "    plot_loss_epoch(model_type, loss_history)\n",
        "\n",
        "    # ✅ BEST 모델 평가\n",
        "    print(f\"\\n========== BEST MODEL SUMMARY ({model_type}) ==========\")\n",
        "    print(f\"Epoch:         {best_ckpt['epoch']}\")\n",
        "    print(f\"Train Loss:    {best_ckpt['train_loss']:.4f}\")\n",
        "    print(f\"Val Loss:      {best_ckpt['val_loss']:.4f}\")\n",
        "    print(f\"Parameters:    {sum(p.numel() for p in best_model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    print(\"\\nRunning test on BEST model...\")\n",
        "    best_test_loss, best_bleu, best_meteor, best_bert = Test(\n",
        "        best_model, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"]\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- BEST MODEL TEST RESULTS ---\")\n",
        "    print(f\"Test Loss    : {best_test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score : {best_bleu:.4f}\")\n",
        "    print(f\"METEOR Score : {best_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1 : {best_bert:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # ✅ FINAL 모델 평가\n",
        "    print(f\"\\n========== FINAL MODEL SUMMARY ({model_type}) ==========\")\n",
        "    print(f\"Epoch:         {final_ckpt['epoch']}\")\n",
        "    print(f\"Train Loss:    {final_ckpt['train_loss']:.4f}\")\n",
        "    print(f\"Val Loss:      {final_ckpt['val_loss']:.4f}\")\n",
        "    print(f\"Parameters:    {sum(p.numel() for p in final_model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    print(\"\\nRunning test on FINAL model...\")\n",
        "    final_test_loss, final_bleu, final_meteor, final_bert = Test(\n",
        "        final_model, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"]\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- FINAL MODEL TEST RESULTS ---\")\n",
        "    print(f\"Test Loss    : {final_test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score : {final_bleu:.4f}\")\n",
        "    print(f\"METEOR Score : {final_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1 : {final_bert:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return {\n",
        "        \"best\": {\n",
        "            \"test_loss\": best_test_loss,\n",
        "            \"BLEU\": best_bleu,\n",
        "            \"METEOR\": best_meteor,\n",
        "            \"BERTScore\": best_bert,\n",
        "        },\n",
        "        \"final\": {\n",
        "            \"test_loss\": final_test_loss,\n",
        "            \"BLEU\": final_bleu,\n",
        "            \"METEOR\": final_meteor,\n",
        "            \"BERTScore\": final_bert,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================== 🔧 Training & Evaluating: baseline1 ==================\n",
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "⚠️ Checkpoint for baseline1 not found. Skipping evaluation.\n",
            "\n",
            "\n",
            "================== 🔧 Training & Evaluating: baseline2 ==================\n",
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "⚠️ Checkpoint for baseline2 not found. Skipping evaluation.\n",
            "\n",
            "\n",
            "================== 🔧 Training & Evaluating: mild_extension1 ==================\n",
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "📦 AutoEncoder pretraining required for mild_extension1\n",
            "🚀 Pretraining AutoEncoder for mild_extension1\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 15.60 GiB of which 61.81 MiB is free. Including non-PyTorch memory, this process has 13.62 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 171.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[160], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m base_config\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# main 실행\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model, encoder, decoder, _, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ✅ config에 필요한 정보 추가\u001b[39;00m\n\u001b[1;32m     13\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ingredient_vocab)\n",
            "Cell \u001b[0;32mIn[155], line 98\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model_type, config, train_df, dev_df, test_df, glove_path)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_AUTOENCODER\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📦 AutoEncoder pretraining required for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mMakingAutoEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mingredient_vocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader_autoencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreeze_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# 5. Model 구성 (recipe_vocab 사용)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m INPUT_DIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ingredient_vocab)\n",
            "Cell \u001b[0;32mIn[157], line 25\u001b[0m, in \u001b[0;36mMakingAutoEncoder\u001b[0;34m(model_type, config, input_vocab, train_loader, embedding_weights, freeze_embedding, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 3. 학습\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Pretraining AutoEncoder for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAUTOENCODER_EPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 4. 저장\u001b[39;00m\n\u001b[1;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(encoder\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoder_pretrained.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[154], line 182\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataloader, criterion, optimizer, epochs, device, label)\u001b[0m\n\u001b[1;32m    179\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():  \u001b[38;5;66;03m# AMP 시작\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     trg \u001b[38;5;241m=\u001b[39m src_batch[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    185\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[0;32m~/repos/jkim0094-CookingRecipeGenerato/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/repos/jkim0094-CookingRecipeGenerato/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[152], line 453\u001b[0m, in \u001b[0;36mIngredientAutoEncoder.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    450\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 453\u001b[0m     output, hidden, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# [batch_size, 1, vocab_size]\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# ✅ Teacher Forcing\u001b[39;00m\n",
            "File \u001b[0;32m~/repos/jkim0094-CookingRecipeGenerato/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/repos/jkim0094-CookingRecipeGenerato/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[152], line 231\u001b[0m, in \u001b[0;36mAttnDecoderRNN_extension.forward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(output)\n\u001b[1;32m    229\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(output)\n\u001b[0;32m--> 231\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    232\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_weights, encoder_outputs)\n\u001b[1;32m    233\u001b[0m concat_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output, context), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 15.60 GiB of which 61.81 MiB is free. Including non-PyTorch memory, this process has 13.62 GiB memory in use. Of the allocated memory 13.13 GiB is allocated by PyTorch, and 171.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "for model_type, base_config in experiment_configs.items():\n",
        "    print(f\"\\n================== 🔧 Training & Evaluating: {model_type} ==================\")\n",
        "\n",
        "    # ✅ config 복사 및 설정\n",
        "    config = base_config.copy()\n",
        "\n",
        "    # main 실행\n",
        "    model, encoder, decoder, _, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab = main(\n",
        "        model_type, config, train_df, dev_df, test_df\n",
        "    )\n",
        "\n",
        "    # ✅ config에 필요한 정보 추가\n",
        "    config[\"input_dim\"] = len(ingredient_vocab)\n",
        "    config[\"output_dim\"] = len(recipe_vocab)\n",
        "    config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "    # optional: GloVe embedding이 사용되었다면 전달\n",
        "    config[\"embedding_weights\"] = config.get(\"embedding_weights\", None)\n",
        "\n",
        "    # optional: checklist/copy 관련 키 추가\n",
        "    config[\"checklist_vocab\"] = config.get(\"checklist_vocab\", None)\n",
        "    config[\"tokenizer_checklist\"] = config.get(\"tokenizer_checklist\", None)\n",
        "\n",
        "    # 🔸 파일 존재 여부 확인\n",
        "    if not os.path.exists(save_model_path) or not os.path.exists(save_history_path):\n",
        "        print(f\"⚠️ Checkpoint for {model_type} not found. Skipping evaluation.\\n\")\n",
        "        continue\n",
        "\n",
        "    # 손실 함수 정의\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "\n",
        "    # 평가 실행\n",
        "    summarize_and_test_model(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        ingredient_vocab=ingredient_vocab,\n",
        "        recipe_vocab=recipe_vocab,\n",
        "        test_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        checklist_vocab=config.get(\"checklist_vocab\"),\n",
        "        tokenizer_checklist=config.get(\"tokenizer_checklist\"),\n",
        "        embedding_weights=config.get(\"embedding_weights\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot for all model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def plot_loss_iter_multi(model_list, experiment_configs, device=DEVICE):\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "    \n",
        "#     for model_type in model_list:\n",
        "#         config = experiment_configs[model_type].copy()\n",
        "#         ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "#             load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "    \n",
        "#         config[\"input_dim\"] = len(ingredient_vocab)\n",
        "#         config[\"output_dim\"] = len(recipe_vocab)\n",
        "#         config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "#         # 📥 모델, 기록 불러오기\n",
        "#         _, _, loss_history, _, _ = load_trained_model(model_type, config, device)\n",
        "#         train_iter_loss = loss_history[\"train_iter\"]  # 리스트 of 리스트\n",
        "\n",
        "#         # 리스트 평탄화 (iteration 기준)\n",
        "#         iter_losses = [loss for epoch_losses in train_iter_loss for loss in epoch_losses]\n",
        "#         plt.plot(iter_losses, label=model_type)\n",
        "\n",
        "#     plt.title(\"Training Loss per Iteration\")\n",
        "#     plt.xlabel(\"Iteration\")\n",
        "#     plt.ylabel(\"Loss\")\n",
        "#     plt.legend()\n",
        "#     plt.grid(True)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def smooth(values, window=100):\n",
        "    return np.convolve(values, np.ones(window)/window, mode='valid')\n",
        "\n",
        "def plot_loss_iter_multi(model_list, experiment_configs, device=DEVICE):\n",
        "    plt.style.use(\"seaborn-v0_8\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for model_type in model_list:\n",
        "        config = experiment_configs[model_type].copy()\n",
        "        ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "            load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "\n",
        "        config[\"input_dim\"] = len(ingredient_vocab)\n",
        "        config[\"output_dim\"] = len(recipe_vocab)\n",
        "        config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "        _, _, loss_history, _, _ = load_trained_model(model_type, config, device)\n",
        "        train_iter_loss = loss_history[\"train_iter\"]\n",
        "\n",
        "        iter_losses = [loss for epoch in train_iter_loss for loss in epoch]\n",
        "        smoothed = smooth(iter_losses, window=100)\n",
        "\n",
        "        plt.plot(smoothed, label=model_type, linewidth=2)\n",
        "\n",
        "    plt.title(\"Smoothed Training Loss per Iteration\", fontsize=14)\n",
        "    plt.xlabel(\"Iteration\", fontsize=12)\n",
        "    plt.ylabel(\"Loss\", fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "📥 Loaded BEST model (Epoch 4)\n",
            "📥 Loaded FINAL model (Epoch 5)\n",
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "📥 Loaded BEST model (Epoch 3)\n",
            "📥 Loaded FINAL model (Epoch 5)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss_iter_multi(\n",
        "    model_list=[\"baseline1\", \"baseline2\"],\n",
        "    experiment_configs=experiment_configs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes(sample_raw, model_names, experiment_configs):\n",
        "    \"\"\"\n",
        "    여러 모델을 불러와 주어진 input에 대해 recipe를 생성하는 함수\n",
        "    \"\"\"\n",
        "    # 🧾 입력을 리스트로 정리\n",
        "    if isinstance(sample_raw, str):\n",
        "        ingredient_list = [i.strip() for i in sample_raw.split(',')]\n",
        "    elif isinstance(sample_raw, list):\n",
        "        ingredient_list = sample_raw\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a comma-separated string or a list.\")\n",
        "\n",
        "    print(f\"🧾 Ingredients: {ingredient_list}\")\n",
        "\n",
        "    results = {}\n",
        "    for model_type in model_names:\n",
        "        print(f\"\\n🔍 Generating with model: {model_type}\")\n",
        "        config = experiment_configs[model_type].copy()\n",
        "\n",
        "        # ✅ vocab, tokenizer 불러오기\n",
        "        ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "            load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "\n",
        "        config[\"input_dim\"] = len(ingredient_vocab)\n",
        "        config[\"output_dim\"] = len(recipe_vocab)\n",
        "        config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "        # ✅ 모델 불러오기\n",
        "        _, final_model, _, _, _ = load_trained_model(model_type, config, device=DEVICE)\n",
        "\n",
        "        # ✅ ingredient_list → 문자열로 변환 후 토크나이징\n",
        "        ingredient_str = str(ingredient_list)\n",
        "        tokenized = tokenizer_ing(ingredient_str)\n",
        "        input_ids = torch.tensor([ingredient_vocab[token] for token in tokenized], dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        # ✅ 예측\n",
        "        final_model.eval()\n",
        "        with torch.no_grad():\n",
        "            prediction_ids = final_model(input_ids, ingredient_texts=[ingredient_list], target=None)\n",
        "\n",
        "        # ✅ 디코딩\n",
        "        pred_tokens = [recipe_vocab.lookup_token(tok.item()) for tok in prediction_ids[0]]\n",
        "        recipe = ' '.join([\n",
        "            t for t in pred_tokens \n",
        "            if t not in [ '', ',', '[', ']', '\"'] # '<pad>', '<sos>', '<eos>',\n",
        "        ]).strip()\n",
        "        results[model_type] = recipe\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧾 Ingredients: ['8 oz philadelphia cream cheese', '14 oz can sweetened condensed milk', '1 ts vanilla', '1/3 c  lemon juice', '48 oz canned cherries', '8 inch graham cracker', 'pie crusts']\n",
            "\n",
            "🔍 Generating with model: baseline1\n",
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "📥 Loaded BEST model (Epoch 4)\n",
            "📥 Loaded FINAL model (Epoch 5)\n",
            "\n",
            "🔍 Generating with model: baseline2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded ingredient token cache.\n",
            "✅ Loaded recipe token cache.\n",
            "📥 Loaded BEST model (Epoch 3)\n",
            "📥 Loaded FINAL model (Epoch 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧠 Model: baseline1\n",
            "🍽️ Recipe: combine first 5 ingredients in a large saucepan . stir in milk\n",
            "--------------------------------------------------\n",
            "\n",
            "🧠 Model: baseline2\n",
            "🍽️ Recipe: in a large bowl combine cream cheese milk add milk and milk . beat until smooth . add in milk and beat until smooth . fold in whipped cream .\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "sample1_raw = \"sugar, lemon juice,  water,  orange juice, strawberries, icecream\"\n",
        "sample2_raw = \"8 oz philadelphia cream cheese, 14 oz can sweetened condensed milk, 1 ts vanilla, 1/3 c  lemon juice, 48 oz canned cherries, 8 inch graham cracker,  pie crusts\"\n",
        "\n",
        "# 예시 config\n",
        "model_names = [\"baseline1\", \"baseline2\"]\n",
        "results = generate_recipes(sample2_raw, model_names, experiment_configs)\n",
        "\n",
        "for model, recipe in results.items():\n",
        "    print(f\"\\n🧠 Model: {model}\\n🍽️ Recipe: {recipe}\")\n",
        "    print(\"-\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fill in the XLSX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes_from_excel(xlsx_path, output_path, model_names, experiment_configs):\n",
        "    df = pd.read_excel(xlsx_path)\n",
        "\n",
        "    # 결과 컬럼 초기화\n",
        "    for model in model_names:\n",
        "        col_name = f\"Recipe - {model}\"\n",
        "        if col_name not in df.columns:\n",
        "            df[col_name] = \"\"\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Recipes\"):\n",
        "        try:\n",
        "            ingredient_raw = row[\"Ingredients\"]\n",
        "            ingredient_list = ast.literal_eval(ingredient_raw) if isinstance(ingredient_raw, str) else ingredient_raw\n",
        "            results = generate_recipes(\n",
        "                sample_raw=ingredient_list,\n",
        "                model_names=model_names,\n",
        "                tokenizer_ingredient=None,  # 내부에서 처리\n",
        "                experiment_configs=experiment_configs\n",
        "            )\n",
        "            for model in model_names:\n",
        "                df.at[i, f\"Recipe - {model}\"] = results.get(model, \"\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error at row {i}: {e}\")\n",
        "\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"✅ Saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xlsx_path = \"recipes_input.xlsx\"\n",
        "output_path = \"recipes_output.xlsx\"\n",
        "model_names = [\"Baseline 1\", \"Mild Ext 1\", \"Spicy Ext 1\"]\n",
        "generate_recipes_from_excel(xlsx_path, output_path, model_names, experiment_configs)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
