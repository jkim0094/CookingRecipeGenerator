{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pnWO37v6oLFg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import gdown\n",
        "from functools import partial\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import spacy\n",
        "import ast\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    DEVICE = 'mps'  # Apple GPU ÏÇ¨Ïö©\n",
        "elif torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'  # NVIDIA GPU ÏÇ¨Ïö©\n",
        "else:\n",
        "    DEVICE = 'cpu'   # CPU fallback\n",
        "\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iuol8CxrHQZC"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzpEEDthSnhi",
        "outputId": "3677fb2b-d313-4960-fa2a-f5932daa0af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 162899\n",
            "Dev data size: 1065\n",
            "Test data size: 1081\n",
            "\n",
            "Train data sample:\n",
            "                      Title  \\\n",
            "0       No-Bake Nut Cookies   \n",
            "1               Creamy Corn   \n",
            "2      Reeses Cups(Candy)     \n",
            "3  Cheeseburger Potato Soup   \n",
            "4       Rhubarb Coffee Cake   \n",
            "\n",
            "                                         Ingredients  \\\n",
            "0  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
            "1  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
            "2  [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
            "3  [\"6 baking potatoes\", \"1 lb. of extra lean gro...   \n",
            "4  [\"1 1/2 c. sugar\", \"1/2 c. butter\", \"1 egg\", \"...   \n",
            "\n",
            "                                              Recipe  \n",
            "0  [\"In a heavy 2-quart saucepan, mix brown sugar...  \n",
            "1  [\"In a slow cooker, combine all ingredients. C...  \n",
            "2  [\"Combine first four ingredients and press in ...  \n",
            "3  [\"Wash potatoes; prick several times with a fo...  \n",
            "4  [\"Cream sugar and butter.\", \"Add egg and beat ...  \n"
          ]
        }
      ],
      "source": [
        "# data Îã§Ïö¥\n",
        "train_path = 'Cooking_Dataset/train.csv'\n",
        "dev_path = 'Cooking_Dataset/dev.csv'\n",
        "test_path = 'Cooking_Dataset/test.csv'\n",
        "\n",
        "\n",
        "if not os.path.exists('Cooking_Dataset'):\n",
        "    os.makedirs('Cooking_Dataset')\n",
        "    print(\"Downloading Dataset\") \n",
        "    gdown.download(\"https://drive.google.com/uc?id=1uZdYjvllt0dSdKKtrCgKHUk-APKdmeNU\", train_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1SAMbkdtjGBYgojqobiwe7ZmnEq7SiGsF\", dev_path, quiet=False)\n",
        "    gdown.download(\"https://drive.google.com/uc?id=1v6Rr2et_4WA5mRwwlRxtLhn38pbmr9Yr\", test_path, quiet=False)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "#train_df = train_df.sample(n=200,random_state=42)\n",
        "dev_df = pd.read_csv(dev_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
        "print(f\"Train data size: {len(train_df)}\")\n",
        "print(f\"Dev data size: {len(dev_df)}\")\n",
        "print(f\"Test data size: {len(test_df)}\")\n",
        "print(\"\\nTrain data sample:\")\n",
        "print(train_df.head())\n",
        "#No-Bake Nut Cookies\n",
        "# [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\n",
        "# [\"In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\", \"Stir over medium heat until mixture bubbles all over top.\", \"Boil and stir 5 minutes more. Take off heat.\", \"Stir in vanilla and cereal; mix well.\", \"Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\", \"Let stand until firm, about 30 minutes.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQwUvtETjCF",
        "outputId": "86b57a8d-0dd5-4fa7-abdf-0d96cb367749"
      },
      "outputs": [],
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenizer_ingredient_baseline(text):\n",
        "    \"\"\"\n",
        "    Baseline Ï†ÑÏ≤òÎ¶¨: ÏÜåÎ¨∏ÏûêÌôî + lemmatization + Í∞ÑÎã®Ìïú ÌïÑÌÑ∞ÎßÅ\n",
        "    - stopword Ï†úÍ±∞ ÏûàÏùå\n",
        "    - Ïà´Ïûê, Íµ¨ÎëêÏ†ê Ï†úÍ±∞ ÏûàÏùå\n",
        "    - Î∂àÌïÑÏöîÌïú Î≥µÏû° Ï†ÑÏ≤òÎ¶¨ ÏóÜÏùå\n",
        "    \"\"\"\n",
        "    import ast\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.like_num or token.is_stop:\n",
        "                    continue\n",
        "                tokens.append(token.lemma_.strip())  # Í∏∞Î≥∏ lemmatizationÎßå Ïú†ÏßÄ\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_recipe_baseline(text):\n",
        "    \"\"\"\n",
        "    Recipe Ï†ÑÏ≤òÎ¶¨: ÏÜåÎ¨∏ÏûêÌôî + lemmatizationÎßå ÏàòÌñâ (Íµ¨ÎëêÏ†ê, stopword, Ïà´ÏûêÎäî Ïú†ÏßÄ)\n",
        "    - Ï°∞Î¶¨ ÏàúÏÑú, ÎèôÏÇ¨ Îì± ÏûêÏó∞Ïä§Îü¨Ïö¥ Î¨∏Ïû• ÌùêÎ¶ÑÏùÑ Î≥¥Ï°¥Ìï¥Ïïº ÌïòÎØÄÎ°ú Í∞ÑÎã®Ìïú Ï†ÑÏ≤òÎ¶¨Îßå Ï†ÅÏö©\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        doc = spacy_en(text.lower())\n",
        "        for token in doc:\n",
        "            # ÎÑàÎ¨¥ Í≥µÍ≤©Ï†ÅÏù∏ ÌïÑÌÑ∞ÎßÅÏùÄ ÌïòÏßÄ ÏïäÏùå\n",
        "            if token.is_space:\n",
        "                continue\n",
        "            tokens.append(token.lemma_.strip())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "def tokenizer_ingredient_checklist(text, remove_stopwords=True, lemmatize=True):\n",
        "    text_list = ast.literal_eval(text)  # Î¨∏ÏûêÏó¥ ‚Üí Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
        "    unit_keywords = {\n",
        "        'c', 'cup', 'cups', 'tbsp', 'tablespoon', 'tsp', 'teaspoon',\n",
        "        'oz', 'ounce', 'lb', 'pound', 'g', 'kg', 'mg',\n",
        "        'pt', 'qt', 'gal', 'ml', 'l','carton','container',\n",
        "        'package', 'pkg', 'envelope', 'box', 'bag', 'jar', 'can', 'cans', 'bottle',\n",
        "        'dash', 'pinch', 'slice', 'slices', 'head', 'inch', 'inches',\n",
        "        'stick', 'sticks', 'small', 'medium', 'large', 'size','graham'\n",
        "    }\n",
        "\n",
        "    tokens = []\n",
        "\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue\n",
        "                if token.like_num:\n",
        "                    continue\n",
        "                if token.text.strip(\".\") in unit_keywords:\n",
        "                    continue\n",
        "                if remove_stopwords and token.is_stop:\n",
        "                    continue\n",
        "                if token.pos_ in {\"ADJ\", \"VERB\", \"ADV\", \"PRON\"}:\n",
        "                    continue\n",
        "\n",
        "                tokens.append(token.lemma_.strip() if lemmatize else token.text.strip())\n",
        "    \n",
        "\n",
        "    return tokens\n",
        "\n",
        "def tokenizer_recipe_extension(text):  # ÎîîÌè¥Ìä∏: lemmatize Ïïà Ìï®\n",
        "    text_list = ast.literal_eval(text)\n",
        "    tokens = []\n",
        "\n",
        "    # taggerÎäî Ïú†ÏßÄÌï¥ÏÑú lemma Ïç®ÎèÑ warning ÏóÜÏùå\n",
        "    with spacy_en.select_pipes(disable=[\"parser\", \"ner\", \"tagger\"]):\n",
        "        for item in text_list:\n",
        "            doc = spacy_en(item.lower())  # ÏÜåÎ¨∏ÏûêÌôî\n",
        "            for token in doc:\n",
        "                if token.is_punct or token.is_space:\n",
        "                    continue  # ÎßàÏπ®Ìëú, ÏâºÌëú Ï†úÍ±∞\n",
        "                if token.like_num:  # Ïà´Ïûê Ïú†ÏßÄ\n",
        "                    tokens.append(token.text.strip())\n",
        "                    continue\n",
        "                \n",
        "                tokens.append(token.text.strip())\n",
        "                \n",
        "    return tokens\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"In a slow cooker, combine all ingredients. Cover and cook on low for 4 hours or until heated through and cheese is melted. Stir well before serving. Yields 6 servings.\"]\n",
            "['in', 'a', 'slow', 'cooker', 'combine', 'all', 'ingredients', 'cover', 'and', 'cook', 'on', 'low', 'for', '4', 'hours', 'or', 'until', 'heated', 'through', 'and', 'cheese', 'is', 'melted', 'stir', 'well', 'before', 'serving', 'yields', '6', 'servings']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        }
      ],
      "source": [
        "ing = train_df.iloc[1,2]\n",
        "print(ing)\n",
        "print(tokenizer_recipe_extension(ing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O5IrjwMXuv3h"
      },
      "outputs": [],
      "source": [
        "def build_vocab(token_lists, min_freq=2):\n",
        "    # vocab ÏÉùÏÑ±: ÏûêÏ£º Îì±Ïû•ÌïòÎäî Îã®Ïñ¥Îßå Ìè¨Ìï® + ÌäπÏàò ÌÜ†ÌÅ∞ Ï†ïÏùò\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        token_lists,  # ÌÜ†ÌÅ∞ Î¶¨Ïä§Ìä∏Îì§ÏùÑ ÏßÅÏ†ë Î∞òÎ≥µ\n",
        "        min_freq=min_freq,  # ÏµúÏÜå Îì±Ïû• ÎπàÎèÑ\n",
        "        specials=['<pad>', '<sos>', '<eos>', '<unk>']  # ÌäπÏàò ÌÜ†ÌÅ∞ Ï∂îÍ∞Ä\n",
        "    )\n",
        "    vocab.set_default_index(vocab['<unk>'])  # ÏóÜÎäî Îã®Ïñ¥Îäî <unk>Î°ú Ï≤òÎ¶¨\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_or_tokenize_data(model_type, train_df, config=None):\n",
        "    use_checklist = config.get(\"USE_CHECKLIST\", False)\n",
        "\n",
        "    tokenizer_ingredient = tokenizer_ingredient_baseline\n",
        "    tokenizer_recipe = tokenizer_recipe_baseline\n",
        "    tokenizer_checklist = tokenizer_ingredient_checklist if use_checklist else None\n",
        "\n",
        "    ingredient_cache_path = \"tokens/ingredient_tokens.pkl\"\n",
        "    recipe_cache_path = \"tokens/recipe_tokens.pkl\"\n",
        "    checklist_cache_path = \"tokens/checklist_tokens.pkl\"\n",
        "\n",
        "    ingredient_cache_download = \"https://drive.google.com/uc?id=1Wxvq-qy4ifbzPKmcm_VuNRRXrEOSqisJ\"\n",
        "    recipe_cache_download = \"https://drive.google.com/uc?id=1IyBlDfL9sE8_Ip3muDyciCK9Hiv_VZF8\"\n",
        "    checklist_cache_download = \"https://drive.google.com/uc?id=1-WVksjq8Cgj6UiJ7wtemU2CfP4hhPrci\"\n",
        "\n",
        "    if not os.path.exists('tokens'):\n",
        "        os.makedirs('tokens')\n",
        "\n",
        "    cache_targets = [\n",
        "        (ingredient_cache_path, ingredient_cache_download),\n",
        "        (recipe_cache_path, recipe_cache_download)\n",
        "    ]\n",
        "    if use_checklist:\n",
        "        cache_targets.append((checklist_cache_path, checklist_cache_download))\n",
        "\n",
        "    for path, url in cache_targets:\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"‚¨áÔ∏è  Downloading: {path}\")\n",
        "            try:\n",
        "                r = requests.get(url, allow_redirects=True)\n",
        "                if r.status_code == 200:\n",
        "                    with open(path, 'wb') as f:\n",
        "                        f.write(r.content)\n",
        "                    print(f\"‚úÖ Downloaded: {path}\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Download failed for {path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Download error: {e}\")\n",
        "\n",
        "    if os.path.exists(ingredient_cache_path):\n",
        "        with open(ingredient_cache_path, \"rb\") as f:\n",
        "            ingredient_token_lists = pickle.load(f)\n",
        "        print(\"‚úÖ Loaded ingredient token cache.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No ingredient cache ‚Üí Tokenizing...\")\n",
        "        ingredient_token_lists = [tokenizer_ingredient(text) for text in tqdm(train_df['Ingredients'], desc=\"Tokenizing ingredients\")]\n",
        "        with open(ingredient_cache_path, \"wb\") as f:\n",
        "            pickle.dump(ingredient_token_lists, f)\n",
        "\n",
        "    if os.path.exists(recipe_cache_path):\n",
        "        with open(recipe_cache_path, \"rb\") as f:\n",
        "            recipe_token_lists = pickle.load(f)\n",
        "        print(\"‚úÖ Loaded recipe token cache.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No recipe cache ‚Üí Tokenizing...\")\n",
        "        recipe_token_lists = [tokenizer_recipe(text) for text in tqdm(train_df['Recipe'], desc=\"Tokenizing recipes\")]\n",
        "        with open(recipe_cache_path, \"wb\") as f:\n",
        "            pickle.dump(recipe_token_lists, f)\n",
        "\n",
        "    ingredient_vocab = build_vocab(ingredient_token_lists, min_freq=1)\n",
        "    recipe_vocab = build_vocab(recipe_token_lists, min_freq=2)\n",
        "\n",
        "    checklist_vocab = None\n",
        "    if use_checklist:\n",
        "        if os.path.exists(checklist_cache_path):\n",
        "            with open(checklist_cache_path, \"rb\") as f:\n",
        "                checklist_token_lists = pickle.load(f)\n",
        "            print(\"‚úÖ Loaded checklist token cache.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No checklist cache ‚Üí Tokenizing...\")\n",
        "            checklist_token_lists = [tokenizer_checklist(text) for text in tqdm(train_df['Ingredients'], desc=\"Checklist tokenize\")]\n",
        "            with open(checklist_cache_path, \"wb\") as f:\n",
        "                pickle.dump(checklist_token_lists, f)\n",
        "\n",
        "        checklist_vocab = build_vocab(checklist_token_lists, min_freq=1)\n",
        "\n",
        "    return ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe, checklist_vocab, tokenizer_checklist\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_checklist_tensor(checklist_vocab, checklist_tokenizer, ingredient_texts, device, embedding_layer):\n",
        "    batch_ids = []\n",
        "\n",
        "\n",
        "\n",
        "    for text in ingredient_texts:\n",
        "        tokens = checklist_tokenizer(text)\n",
        "        ids = [checklist_vocab[token] for token in tokens]\n",
        "        batch_ids.append(torch.tensor(ids, dtype=torch.long))\n",
        "\n",
        "    checklist_padded = pad_sequence(batch_ids, batch_first=True, padding_value=checklist_vocab['<pad>']).to(device)\n",
        "    checklist_mask = (checklist_padded != checklist_vocab['<pad>']).float().to(device)\n",
        "    checklist_embeds = embedding_layer(checklist_padded)\n",
        "\n",
        "\n",
        "\n",
        "    return checklist_embeds, checklist_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u3aRuH1BcoQQ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe):\n",
        "        self.df = df\n",
        "        self.ingredient_vocab = ingredient_vocab\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "        self.tokenizer_ingredient = tokenizer_ingredient\n",
        "        self.tokenizer_recipe = tokenizer_recipe\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ingredient_text = self.df.iloc[idx]['Ingredients']\n",
        "        recipe_text = self.df.iloc[idx]['Recipe']\n",
        "\n",
        "        ingredient_tokens = self.tokenizer_ingredient(ingredient_text)\n",
        "        recipe_tokens = self.tokenizer_recipe(recipe_text)\n",
        "\n",
        "        ingredient_ids = [self.ingredient_vocab['<sos>']] + [self.ingredient_vocab[token] for token in ingredient_tokens] + [self.ingredient_vocab['<eos>']]\n",
        "        recipe_ids = [self.recipe_vocab['<sos>']] + [self.recipe_vocab[token] for token in recipe_tokens] + [self.recipe_vocab['<eos>']]\n",
        "\n",
        "        return torch.tensor(ingredient_ids), torch.tensor(recipe_ids), ingredient_text  # ‚úÖ 3Í∞ú Î∞òÌôò\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zvtpEXhJyzRN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, ingredient_vocab, recipe_vocab, device):\n",
        "    ingredients, recipes, ingredient_texts = zip(*batch)  # ingredient_texts: str\n",
        "    ingredients_padded = pad_sequence(ingredients, batch_first=True, padding_value=ingredient_vocab['<pad>'])\n",
        "    recipes_padded = pad_sequence(recipes, batch_first=True, padding_value=recipe_vocab['<pad>'])\n",
        "    return ingredients_padded.to(device), recipes_padded.to(device), list(ingredient_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHuvOqpGoe5N"
      },
      "outputs": [],
      "source": [
        "class Encoder_GRU(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        \n",
        "\n",
        "        # GRU Î†àÏù¥Ïñ¥\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # ÎìúÎ°≠ÏïÑÏõÉ\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src : [batch_size, src_len]\n",
        "        src = src.long() \n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded : [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # gru ÌÜµÍ≥º\n",
        "        outputs, hidden = self.gru(embedded) # h0Î•º Îî∞Î°ú Ï£ºÏßÄ ÏïäÏúºÎ©¥, ÎîîÌè¥Ìä∏Î°ú h0Í∞Ä 0Î°ú Ï¥àÍ∏∞ÌôîÎêòÏÑú Îì§Ïñ¥Í∞ê\n",
        "        # outputs: [batch_size, src_len, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        return outputs,hidden\n",
        "\n",
        "class Encoder_GRU_extension(nn.Module):\n",
        "    def __init__(self, ingredient_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio,\n",
        "                 embedding_weights=None, freeze=False):\n",
        "        super().__init__()\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding = nn.Embedding.from_pretrained(embedding_weights, freeze=freeze)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(ingredient_vocab_size, embedding_dim)\n",
        "        self.ingredient_vocab_size = ingredient_vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        self.skip_proj = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self._init_weights()  # ‚úÖ Ï¥àÍ∏∞Ìôî Ï†ÅÏö©\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # embedding Ï¥àÍ∏∞Ìôî (from_pretrained ÏïÑÎãå Í≤ΩÏö∞Îßå)\n",
        "        if not hasattr(self.embedding, 'weight') or self.embedding.weight.requires_grad:\n",
        "            nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        # GRU ÎÇ¥Î∂Ä weight Ï¥àÍ∏∞Ìôî\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='leaky_relu')\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "        # skip connection projection Ï¥àÍ∏∞Ìôî\n",
        "        nn.init.kaiming_normal_(self.skip_proj.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        nn.init.constant_(self.skip_proj.bias, 0)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = src.long()\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        skip = self.skip_proj(embedded)\n",
        "        outputs = self.leaky_relu(outputs + skip)\n",
        "        outputs = self.layer_norm(outputs)\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "\n",
        "class Decoder_GRU(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_dim, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU Î†àÏù¥Ïñ¥\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          n_layers,\n",
        "                          dropout=dropout_ratio if n_layers>1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        # fc Î†àÏù¥Ïñ¥\n",
        "        self.fc_out = nn.Linear(hidden_dim, recipe_vocab_size)\n",
        "\n",
        "        # ÎìúÎ°≠ÏïÑÏõÉ\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.long()\n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1]\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_dim]\n",
        "\n",
        "        # GRU ÌÜµÍ≥º\n",
        "        outputs, hidden = self.gru(embedded,hidden)\n",
        "        # outputs: [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_size]\n",
        "        # hidden: [n_layers, batch_size, hidden_size]\n",
        "\n",
        "        # fc ÌÜµÍ≥º\n",
        "        prediction = self.fc_out(outputs.squeeze(1))\n",
        "        # prediction: [batch_size, vocab_size]\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "# Define a decoder with attention mechanism using PyTorch's nn.Module\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size,embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        # Initialize the base nn.Module class\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Save parameters\n",
        "        self.recipe_vocab_size = recipe_vocab_size              # Size of the output vocabulary\n",
        "        self.embedding_dim = embedding_dim                  # Dropout probability\n",
        "        self.hidden_size = hidden_size              # Size of the hidden state in GRU\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "                  \n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(self.recipe_vocab_size, self.hidden_size)  # Converts word indices to dense vectors\n",
        "        self.dropout = nn.Dropout(self.dropout_ratio)                          # Applies dropout for regularization\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.n_layers, dropout=self.dropout_ratio if self.n_layers>1 else 0, batch_first=True)\n",
        "             # GRU to process the embedded inputs\n",
        "        self.out = nn.Linear(self.hidden_size * 2, self.recipe_vocab_size)       # Linear layer for generating final output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.long() \n",
        "        # input : [batch_size]\n",
        "        input = input.unsqueeze(1)\n",
        "        # input : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1]\n",
        "\n",
        "        # ÏûÑÎ≤†Îî©\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded : [batch_size, Îã®Ïñ¥Ïùò Í∞úÏàò=1, hidden_dim]\n",
        "\n",
        "        # Pass through GRU\n",
        "        output, hidden = self.gru(embedded, hidden)  # output: [batch, 1, hidden_size]\n",
        "\n",
        "        # Compute attention weights using dot-product attention:\n",
        "        # hidden[-1]: [batch, hidden_size]\n",
        "        # encoder_outputs: [batch, src_len, hidden_size]\n",
        "    \n",
        "        attn_weights = F.softmax(\n",
        "            torch.bmm(output, encoder_outputs.transpose(1, 2)), # [batch, 1, hidden_size] x [batch, hidden_size, src_len]\n",
        "            dim=-1\n",
        "        )  # [batch, 1, src_len]\n",
        "\n",
        "        # Apply attention weights to encoder outputs to get context vector\n",
        "        # attn_weights: (1, 1, max_length)\n",
        "        # encoder_outputs.unsqueeze(0): (1, max_length, hidden_size)\n",
        "        attn_output = torch.bmm(attn_weights, encoder_outputs)  # [batch, 1, hidden_size]\n",
        "\n",
        "        # Concatenate attention output and decoder hidden state\n",
        "        concat_output = torch.cat((output, attn_output), dim=2)  # [batch, 1, hidden*2]\n",
        "\n",
        "        # Pass through linear layer and softmax to get output word probabilities\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)  # [batch, vocab_size]\n",
        "\n",
        "        # Return output word distribution, updated hidden state, and attention weights\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "class AttnDecoderRNN_extension(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_size, n_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size * 2, recipe_vocab_size)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self._init_weights()  # ‚úÖ He Ï¥àÍ∏∞Ìôî Ìò∏Ï∂ú\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Embedding\n",
        "        nn.init.kaiming_normal_(self.embedding.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "        # GRU weights & biases\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='leaky_relu')\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "        # Linear layer\n",
        "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        nn.init.constant_(self.out.bias, 0)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.long().unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.leaky_relu(output)\n",
        "        output = self.layer_norm(output)\n",
        "\n",
        "        attn_weights = F.softmax(torch.bmm(output, encoder_outputs.transpose(1, 2)), dim=-1)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)\n",
        "        concat_output = torch.cat((output, context), dim=2)\n",
        "        output = F.log_softmax(self.out(concat_output).squeeze(1), dim=1)\n",
        "        return output, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "class DecoderWithChecklistCopy(nn.Module):\n",
        "    def __init__(self, recipe_vocab_size, embedding_dim, hidden_size, n_layers, dropout_ratio,\n",
        "                 checklist_vocab_size, checklist_vocab, tokenizer_checklist,\n",
        "                 use_checklist=True, use_copy=False):\n",
        "        super().__init__()\n",
        "        self.recipe_vocab_size = recipe_vocab_size\n",
        "        self.embedding = nn.Embedding(recipe_vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers,\n",
        "                          dropout=dropout_ratio if n_layers > 1 else 0,\n",
        "                          batch_first=True)\n",
        "\n",
        "        self.out_proj = nn.Linear(hidden_size, recipe_vocab_size)\n",
        "        self.attn_proj = nn.Linear(hidden_size, hidden_size)  # for both checklist & encoder attention\n",
        "        self.ref_selector = nn.Linear(hidden_size, 3)\n",
        "\n",
        "        self.use_checklist = use_checklist\n",
        "        self.use_copy = use_copy\n",
        "\n",
        "        # Checklist\n",
        "        if self.use_checklist:\n",
        "            self.checklist_embedding = nn.Embedding(checklist_vocab_size, hidden_size)\n",
        "            self.checklist_max_len = checklist_vocab_size\n",
        "            self.checklist_vocab = checklist_vocab\n",
        "            self.tokenizer_checklist = tokenizer_checklist\n",
        "            self.a_prev_list = []\n",
        "\n",
        "        # Copy\n",
        "        if self.use_copy:\n",
        "            self.copy_attn = nn.Linear(hidden_size, hidden_size)\n",
        "            self.copy_score = nn.Linear(hidden_size, 1)  # to compute p_gen\n",
        "\n",
        "    def forward(self, input_token, hidden, encoder_outputs=None,\n",
        "                ingredient_texts=None, a_prev=None, checklist_embeds=None,\n",
        "                checklist_mask=None, encoder_input_ids=None, **kwargs):\n",
        "\n",
        "        input_token = input_token.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        gru_out, hidden = self.gru(embedded, hidden)\n",
        "        h_t = gru_out.squeeze(1)  # [batch, hidden_dim]\n",
        "\n",
        "        # === Checklist ===\n",
        "        if self.use_checklist and ingredient_texts is not None and a_prev is not None:\n",
        "            batch_ids = []\n",
        "            for text in ingredient_texts:\n",
        "                tokens = self.tokenizer_checklist(text)\n",
        "                ids = [self.checklist_vocab[token] for token in tokens]\n",
        "                batch_ids.append(torch.tensor(ids, dtype=torch.long))\n",
        "            padded = pad_sequence(batch_ids, batch_first=True, padding_value=0)\n",
        "            checklist_embeds = self.checklist_embedding(padded.to(input_token.device))\n",
        "            checklist_mask = (padded != 0).float().to(input_token.device)\n",
        "\n",
        "            used_mask = a_prev.clamp(0, 1).unsqueeze(2)\n",
        "            unused_mask = (1 - a_prev).clamp(0, 1).unsqueeze(2)\n",
        "            E_new = checklist_embeds * unused_mask\n",
        "            E_used = checklist_embeds * used_mask\n",
        "\n",
        "            h_proj = self.attn_proj(h_t).unsqueeze(2)\n",
        "            scores_new = torch.bmm(E_new, h_proj).squeeze(2)\n",
        "            scores_used = torch.bmm(E_used, h_proj).squeeze(2)\n",
        "\n",
        "            scores_new = scores_new.masked_fill(checklist_mask == 0, -1e9)\n",
        "            scores_used = scores_used.masked_fill(checklist_mask == 0, -1e9)\n",
        "\n",
        "            alpha_new = F.softmax(scores_new, dim=1)\n",
        "            alpha_used = F.softmax(scores_used, dim=1)\n",
        "\n",
        "            c_new = torch.bmm(alpha_new.unsqueeze(1), checklist_embeds).squeeze(1)\n",
        "            c_used = torch.bmm(alpha_used.unsqueeze(1), checklist_embeds).squeeze(1)\n",
        "        else:\n",
        "            alpha_new = alpha_used = None\n",
        "            c_new = c_used = torch.zeros_like(h_t)\n",
        "\n",
        "        # === Copy ===\n",
        "        if self.use_copy and encoder_outputs is not None:\n",
        "            attn_scores = torch.bmm(encoder_outputs, h_t.unsqueeze(2)).squeeze(2)\n",
        "            attn_weights = F.softmax(attn_scores, dim=1)\n",
        "            context_vector = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
        "            # p_gen gate\n",
        "            p_gen_input = torch.cat([h_t, context_vector], dim=1)\n",
        "            p_gen = torch.sigmoid(self.copy_score(p_gen_input))\n",
        "        else:\n",
        "            context_vector = torch.zeros_like(h_t)\n",
        "            p_gen = torch.ones((h_t.size(0), 1), device=h_t.device)\n",
        "\n",
        "        # === Output ===\n",
        "        f_logits = self.ref_selector(h_t)\n",
        "        f = F.softmax(f_logits, dim=-1)\n",
        "        f_gru, f_new, f_used = f.chunk(3, dim=1)\n",
        "\n",
        "        o_t = f_gru * h_t + f_new * c_new + f_used * c_used + context_vector\n",
        "        output = self.out_proj(o_t)\n",
        "\n",
        "        # === Coverage update ===\n",
        "        if self.use_checklist and self.training:\n",
        "            if not hasattr(self, \"a_prev_list\"):\n",
        "                self.a_prev_list = []\n",
        "            self.a_prev_list.append((a_prev.detach(), alpha_new.detach()))\n",
        "\n",
        "        a_t = a_prev + f_new * alpha_new if self.use_checklist else None\n",
        "        return output, hidden, a_t, alpha_new, alpha_used\n",
        "\n",
        "\n",
        "class IngredientAutoEncoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, src):\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        input_token = src[:, 0]  # <sos>\n",
        "        outputs = torch.zeros(src.size(0), src.size(1) - 1, self.vocab_size).to(src.device)\n",
        "\n",
        "        for t in range(1, src.size(1)):\n",
        "            output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            outputs[:, t-1, :] = output\n",
        "            input_token = src[:, t]  # teacher forcing\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, use_attention, recipe_vocab):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.use_attention = use_attention\n",
        "        self.recipe_vocab = recipe_vocab\n",
        "\n",
        "    def forward(self, src, ingredient_texts=None, target=None,\n",
        "                teacher_forcing_ratio=0.5, max_len=50):\n",
        "        \n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        batch_size = src.size(0)\n",
        "        vocab_size = self.decoder.recipe_vocab_size\n",
        "\n",
        "        # ‚úÖ Decoder Í∏∞Îä• ÌåêÎã®\n",
        "        use_checklist = getattr(self.decoder, 'use_checklist', False)\n",
        "        use_copy = getattr(self.decoder, 'use_copy', False)\n",
        "\n",
        "        # ‚úÖ Checklist Ï§ÄÎπÑ\n",
        "        checklist_embed, checklist_mask = None, None\n",
        "        if use_checklist:\n",
        "            checklist_embed, checklist_mask = get_checklist_tensor(\n",
        "                checklist_vocab=self.decoder.checklist_vocab,\n",
        "                checklist_tokenizer=self.decoder.tokenizer_checklist,\n",
        "                ingredient_texts=ingredient_texts,\n",
        "                device=self.device,\n",
        "                embedding_layer=self.decoder.checklist_embedding\n",
        "            )\n",
        "\n",
        "        a_prev = None\n",
        "        if checklist_mask is not None:\n",
        "            checklist_len = checklist_mask.size(1)\n",
        "            a_prev = torch.zeros(batch_size, checklist_len, device=self.device)\n",
        "\n",
        "        # ‚ñ∂Ô∏è Inference Mode\n",
        "        if target is None:\n",
        "            outputs = []\n",
        "            input_token = torch.tensor([self.recipe_vocab['<sos>']] * batch_size).to(self.device).long()\n",
        "\n",
        "            for _ in range(max_len):\n",
        "                if use_checklist or use_copy:\n",
        "                    output, hidden, a_prev, *_ = self.decoder(\n",
        "                        input_token, hidden, encoder_outputs,\n",
        "                        ingredient_texts=ingredient_texts,\n",
        "                        a_prev=a_prev,\n",
        "                        checklist_embeds=checklist_embed,\n",
        "                        checklist_mask=checklist_mask,\n",
        "                        encoder_input_ids=src\n",
        "                    )\n",
        "                elif self.use_attention:\n",
        "                    result = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                    output, hidden = result[:2] if isinstance(result, (tuple, list)) else result\n",
        "                else:\n",
        "                    output, hidden = self.decoder(input_token, hidden)\n",
        "\n",
        "                top1 = output.argmax(1)\n",
        "                outputs.append(top1.unsqueeze(1))\n",
        "                input_token = top1\n",
        "\n",
        "            return torch.cat(outputs, dim=1)\n",
        "\n",
        "        # üü¢ Training Mode\n",
        "        target = target.long()\n",
        "        target_len = target.shape[1]\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
        "        input_token = target[:, 0].long()\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            if use_checklist or use_copy:\n",
        "                output, hidden, a_prev, *_ = self.decoder(\n",
        "                    input_token, hidden, encoder_outputs,\n",
        "                    ingredient_texts=ingredient_texts,\n",
        "                    a_prev=a_prev,\n",
        "                    checklist_embeds=checklist_embed,\n",
        "                    checklist_mask=checklist_mask,\n",
        "                    encoder_input_ids=src\n",
        "                )\n",
        "            elif self.use_attention:\n",
        "                result = self.decoder(input_token, hidden, encoder_outputs)\n",
        "                output, hidden = result[:2] if isinstance(result, (tuple, list)) else result\n",
        "            else:\n",
        "                output, hidden = self.decoder(input_token, hidden)\n",
        "\n",
        "            outputs[:, t, :] = output\n",
        "            top1 = output.argmax(1)\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            input_token = target[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_encoder_decoder(model_type, config, input_dim, output_dim, embedding_weights=None, freeze_embedding=False, checklist_vocab=None, tokenizer_checklist=None):\n",
        "    use_attention = config[\"USE_ATTENTION\"]\n",
        "    is_extension = \"extension\" in model_type\n",
        "\n",
        "    if is_extension:\n",
        "        encoder = Encoder_GRU_extension(\n",
        "            ingredient_vocab_size=input_dim,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"],\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze=freeze_embedding\n",
        "        )\n",
        "        if config.get(\"USE_CHECKLIST\", False):\n",
        "            decoder = DecoderWithChecklistCopy(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"],\n",
        "                checklist_vocab_size=len(checklist_vocab),\n",
        "                checklist_vocab=checklist_vocab,\n",
        "                tokenizer_checklist=tokenizer_checklist\n",
        "            )\n",
        "        else:\n",
        "            decoder = AttnDecoderRNN_extension(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "    else:\n",
        "        encoder = Encoder_GRU(\n",
        "            ingredient_vocab_size=input_dim,\n",
        "            embedding_dim=config[\"EMBED_DIM\"],\n",
        "            hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "            n_layers=config[\"N_LAYERS\"],\n",
        "            dropout_ratio=config[\"DROPOUT\"],\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze=freeze_embedding\n",
        "        )\n",
        "        if use_attention:\n",
        "            decoder = AttnDecoderRNN(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_size=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "        else:\n",
        "            decoder = Decoder_GRU(\n",
        "                recipe_vocab_size=output_dim,\n",
        "                embedding_dim=config[\"EMBED_DIM\"],\n",
        "                hidden_dim=config[\"HIDDEN_DIM\"],\n",
        "                n_layers=config[\"N_LAYERS\"],\n",
        "                dropout_ratio=config[\"DROPOUT\"]\n",
        "            )\n",
        "\n",
        "    return encoder, decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_glove_embedding_matrix(glove_path, vocab, glove_dim=200):\n",
        "    print(\"üîé Loading GloVe vectors...\")\n",
        "    glove_embeddings = {}\n",
        "\n",
        "    with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            word = values[0]\n",
        "            vector = torch.tensor(list(map(float, values[1:])))\n",
        "            glove_embeddings[word] = vector\n",
        "\n",
        "    # Initialize matrix with random vectors\n",
        "    embedding_matrix = torch.randn(len(vocab), glove_dim)\n",
        "\n",
        "    for word, idx in vocab.get_stoi().items():\n",
        "        if word in glove_embeddings:\n",
        "            embedding_matrix[idx] = glove_embeddings[word]\n",
        "\n",
        "    print(\"‚úÖ GloVe embedding matrix created.\")\n",
        "    return embedding_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_epoch(model, dataloader, criterion, optimizer=None,\n",
        "               teacher_forcing_ratio=0.5, max_len=50,\n",
        "               USE_PENALTY=False, penalty_lambda=0.2):\n",
        "    total_loss = 0\n",
        "    batch_losses = []\n",
        "\n",
        "    if hasattr(model.decoder, \"a_prev_list\"):\n",
        "        model.decoder.a_prev_list = []\n",
        "\n",
        "    for i, (src_batch, trg_batch, ingredient_texts) in enumerate(dataloader):\n",
        "        src_batch = src_batch.to(DEVICE)\n",
        "        trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "        output = model(src_batch, ingredient_texts, trg_batch,\n",
        "                       teacher_forcing_ratio=teacher_forcing_ratio,\n",
        "                       max_len=max_len)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:, :].reshape(-1, output_dim)\n",
        "        trg = trg_batch[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        if USE_PENALTY and hasattr(model.decoder, 'a_prev_list'):\n",
        "            penalty = 0.0\n",
        "            for a_prev, alpha_new in model.decoder.a_prev_list:\n",
        "                penalty += torch.sum(torch.min(a_prev, alpha_new))\n",
        "            penalty = penalty / src_batch.size(0)\n",
        "            loss += penalty_lambda * penalty\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item() * src_batch.shape[0]\n",
        "        batch_losses.append(batch_loss)\n",
        "        total_loss += batch_loss\n",
        "        print(f\"Batch {i+1}/{len(dataloader)} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader.dataset)\n",
        "    return epoch_loss, batch_losses\n",
        "\n",
        "\n",
        "def Train(model, train_loader, val_loader, criterion, optimizer, recipe_vocab,\n",
        "          EPOCHS, BATCH_SIZE, TRAIN_RATIO,\n",
        "          save_model_path, save_history_path, TEACHER_FORCING_RATIO, MAX_LEN, **kwargs):\n",
        "\n",
        "    lr_step = kwargs.get(\"LR_STEP\")\n",
        "    lr_gamma = kwargs.get(\"LR_GAMMA\")\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=lr_gamma) if lr_step and lr_gamma else None\n",
        "\n",
        "    USE_PENALTY = kwargs.get(\"USE_PENALTY\", False)\n",
        "    PENALTY_LAMBDA = kwargs.get(\"PENALTY_LAMBDA\", 0.2)\n",
        "\n",
        "    loss_history = {\"train_epoch\": [], \"train_iter\": [], \"val_epoch\": []}\n",
        "    best_val_loss = float('inf')\n",
        "    train_start_time = time.time()\n",
        "    best_epoch = -1\n",
        "    best_train_loss = None\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        ep_start_time = time.time()\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        print(f\"[Epoch: {ep+1}/{EPOCHS}] current_LR = {current_lr}\")\n",
        "\n",
        "        model.train()\n",
        "        train_epoch_loss, train_batch_loss = loss_epoch(\n",
        "            model, train_loader, criterion, optimizer,\n",
        "            teacher_forcing_ratio=TEACHER_FORCING_RATIO,\n",
        "            max_len=MAX_LEN,\n",
        "            USE_PENALTY=USE_PENALTY,\n",
        "            penalty_lambda=PENALTY_LAMBDA\n",
        "        )\n",
        "        loss_history[\"train_epoch\"].append(train_epoch_loss)\n",
        "        loss_history[\"train_iter\"].append(train_batch_loss)\n",
        "        print(f\"{ep+1} Epoch Train Completed!\")\n",
        "\n",
        "        print(\"Validation Start!\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, _ = loss_epoch(\n",
        "                model, val_loader, criterion, optimizer=None,\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                max_len=MAX_LEN,\n",
        "                USE_PENALTY=USE_PENALTY,\n",
        "                penalty_lambda=PENALTY_LAMBDA\n",
        "            )\n",
        "            loss_history[\"val_epoch\"].append(val_loss)\n",
        "        print(\"Validation Completed!\")\n",
        "\n",
        "        ep_elapsed_time = time.time() - ep_start_time\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"[Epoch {ep+1}/{EPOCHS}] \")\n",
        "        print(f\"Train Loss: {train_epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {ep_elapsed_time:.2f}s\")\n",
        "        bleu, meteor, bert_f1 = compute_metrics(model, val_loader, recipe_vocab, max_len=MAX_LEN)\n",
        "        print(f\"Validation Metrics:\")\n",
        "        print(f\"üìä BLEU: {bleu:.4f} | METEOR: {meteor:.4f} | BERTScore-F1: {bert_f1:.4f}\")  \n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = ep+1\n",
        "            best_train_loss = train_epoch_loss\n",
        "            best_bleu, best_meteor, best_bert_f1 = bleu, meteor, bert_f1\n",
        "            os.makedirs(\"results\", exist_ok=True)\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"epoch\": ep+1,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"train_loss\": train_epoch_loss,\n",
        "            }, save_model_path)\n",
        "            print(\"Best model saved!\")\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    final_model_path = save_model_path.replace(\".pt\", \"_final.pt\")\n",
        "    torch.save({\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"epoch\": EPOCHS,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"train_loss\": train_epoch_loss,\n",
        "    }, final_model_path)\n",
        "    print(\"Final model saved!\")\n",
        "\n",
        "    train_elapsed_time = time.time() - train_start_time\n",
        "    total_iterations = sum(len(batch_list) for batch_list in loss_history[\"train_iter\"])\n",
        "    torch.save({\n",
        "        \"loss_history\": loss_history,\n",
        "        \"EPOCHS\": EPOCHS,\n",
        "        \"BATCH_SIZE\": BATCH_SIZE,   \n",
        "        \"TRAIN_RATIO\": TRAIN_RATIO,\n",
        "        \"train_elapsed_time\": train_elapsed_time,\n",
        "        \"total_iterations\": total_iterations,\n",
        "        \"LR_STEP\": kwargs.get(\"LR_STEP\"),\n",
        "        \"LR_GAMMA\": kwargs.get(\"LR_GAMMA\")\n",
        "    }, save_history_path)\n",
        "    print(\"Training Completed!\")\n",
        "    print(f\"Total number of iteration : {total_iterations}\")\n",
        "    print(f\"Total Time for Training: {train_elapsed_time:.2f}s\")\n",
        "\n",
        "    print(\"\\n======= Training Summary =======\")\n",
        "    print(f\"Best Model:    Epoch {best_epoch}\")\n",
        "    if best_epoch == EPOCHS:\n",
        "        print(f\"(Best model is the final model)\")\n",
        "    print(f\"Train Loss:    {best_train_loss:.4f}\")\n",
        "    print(f\"Val Loss:      {best_val_loss:.4f}\")\n",
        "    print(f\"BLEU:          {best_bleu:.4f}\")\n",
        "    print(f\"METEOR:        {best_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1:  {best_bert_f1:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"Final Model:   Epoch {EPOCHS}\")\n",
        "    print(f\"Train Loss:    {train_epoch_loss:.4f}\")\n",
        "    print(f\"Val Loss:      {val_loss:.4f}\")\n",
        "    print(f\"BLEU:          {bleu:.4f}\")\n",
        "    print(f\"METEOR:        {meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1:  {bert_f1:.4f}\")\n",
        "    print(f\"Total Time:     {train_elapsed_time:.2f}s\")\n",
        "    print(\"==================================\\n\")\n",
        "    return loss_history\n",
        "\n",
        "def train_autoencoder(model, dataloader, criterion, optimizer, epochs, device, label=\"AutoEncoder\"):\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src_batch, _, _ in tqdm(dataloader, desc=f\"Epoch {ep+1}/{epochs}\"):\n",
        "            src_batch = src_batch.to(device)\n",
        "            output = model(src_batch)\n",
        "            trg = src_batch[:, 1:].contiguous()\n",
        "\n",
        "            output = output.view(-1, output.size(-1))\n",
        "            trg = trg.view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"[Epoch {ep+1}/{epochs}] {label} Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "def Test(model, test_loader, criterion, recipe_vocab, MAX_LEN,\n",
        "         USE_PENALTY=False, penalty_lambda=0.2):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_loss, _ = loss_epoch(\n",
        "            model,\n",
        "            test_loader,\n",
        "            criterion,\n",
        "            optimizer=None,\n",
        "            teacher_forcing_ratio=0.0,\n",
        "            max_len=MAX_LEN,\n",
        "            USE_PENALTY=USE_PENALTY,\n",
        "            penalty_lambda=penalty_lambda\n",
        "        )\n",
        "\n",
        "    # ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞\n",
        "    bleu_score, meteor_avg, bertscore_f1 = compute_metrics(model, test_loader, recipe_vocab)\n",
        "\n",
        "    print(f\"Test Loss      : {test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score   : {bleu_score:.4f}\")\n",
        "    print(f\"METEOR Score   : {meteor_avg:.4f}\")\n",
        "    print(f\"BERTScore (F1) : {bertscore_f1:.4f}\")\n",
        "\n",
        "    return test_loss, bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(model, dataloader, recipe_vocab, max_len=50):\n",
        "    \"\"\"\n",
        "    ÌÖåÏä§Ìä∏ÏÖã Ï†ÑÏ≤¥ÏóêÏÑú BLEU, METEOR, BERTScore Í≥ÑÏÇ∞\n",
        "\n",
        "    Returns:\n",
        "        bleu_score (float), meteor_avg (float), bertscore_f1 (float)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    ref_list = []\n",
        "    hyp_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_batch, trg_batch, ingredient_texts in tqdm(dataloader, desc=\"Evaluating Metrics\"):\n",
        "\n",
        "            src_batch = src_batch.to(DEVICE)\n",
        "            trg_batch = trg_batch.to(DEVICE)\n",
        "\n",
        "            generated = model(src_batch, target=None, teacher_forcing_ratio=0.0, max_len=max_len)\n",
        "\n",
        "            for i in range(src_batch.size(0)):\n",
        "                pred_tokens = generated[i].tolist()\n",
        "                trg_tokens = trg_batch[i].tolist()\n",
        "\n",
        "                # <eos> Í∏∞Ï§ÄÏúºÎ°ú ÏûêÎ•¥Í∏∞\n",
        "                if recipe_vocab['<eos>'] in pred_tokens:\n",
        "                    pred_tokens = pred_tokens[:pred_tokens.index(recipe_vocab['<eos>'])]\n",
        "                if recipe_vocab['<eos>'] in trg_tokens:\n",
        "                    trg_tokens = trg_tokens[:trg_tokens.index(recipe_vocab['<eos>'])]\n",
        "\n",
        "                pred_words = [recipe_vocab.get_itos()[idx] for idx in pred_tokens]\n",
        "                trg_words = [recipe_vocab.get_itos()[idx] for idx in trg_tokens]\n",
        "\n",
        "                ref_list.append(trg_words)\n",
        "                hyp_list.append(pred_words)\n",
        "\n",
        "    # BLEU-4\n",
        "    bleu_score = corpus_bleu([[ref] for ref in ref_list], hyp_list, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie) \n",
        "\n",
        "    # METEOR\n",
        "    meteor_scores = [meteor_score([ref], hyp) for ref, hyp in zip(ref_list, hyp_list)]\n",
        "    meteor_avg = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "    # BERTScore\n",
        "    refs = [\" \".join(ref) for ref in ref_list]\n",
        "    hyps = [\" \".join(hyp) for hyp in hyp_list]\n",
        "    _, _, f1 = bert_score_fn(hyps, refs, lang='en', verbose=False)\n",
        "    bertscore_f1 = f1.mean().item()\n",
        "\n",
        "    return bleu_score, meteor_avg, bertscore_f1\n",
        "\n",
        "\n",
        "def plot_loss_epoch(name, loss_history):\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    train_loss = loss_history[\"train_epoch\"]\n",
        "    val_loss = loss_history[\"val_epoch\"]\n",
        "\n",
        "    plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Train Loss\", color=\"blue\")\n",
        "    plt.plot(range(1, len(val_loss) + 1), val_loss, label=\"Validation Loss\", color=\"red\")\n",
        "\n",
        "    plt.xlabel(\"Epoch\", fontsize=10)\n",
        "    plt.ylabel(\"Loss\", fontsize=10)\n",
        "    plt.title(f\"Loss per Epoch: {name}\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(model_type: str, config: dict,\n",
        "         train_df, dev_df, test_df,\n",
        "         glove_path: str = \"./glove.6B.200d.txt\"):\n",
        "\n",
        "    # 1. Tokenize & Vocab\n",
        "    ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe, checklist_vocab, tokenizer_checklist = load_or_tokenize_data(model_type, train_df, config)\n",
        "\n",
        "    # 2. GloVe ÏûÑÎ≤†Îî© Ï†ÅÏö© Ïó¨Î∂Ä\n",
        "    embedding_weights = None\n",
        "    freeze_embedding = config.get(\"freeze_embedding\", False)\n",
        "    if config.get(\"use_glove\", False):\n",
        "        print(f\"üîé Using GloVe embeddings for {model_type}\")\n",
        "        ingredient_embedding_matrix = build_glove_embedding_matrix(\n",
        "            glove_path, ingredient_vocab, glove_dim=config[\"EMBED_DIM\"]\n",
        "        )\n",
        "        embedding_weights = ingredient_embedding_matrix\n",
        "\n",
        "    # 3. Dataset & DataLoader\n",
        "    BATCH_SIZE = config.get(\"BATCH_SIZE\", 64)\n",
        "    train_dataset = CustomDataset(train_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    dev_dataset = CustomDataset(dev_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    test_dataset = CustomDataset(test_df, ingredient_vocab, recipe_vocab, tokenizer_ingredient, tokenizer_recipe)\n",
        "    collate = partial(collate_fn, ingredient_vocab=ingredient_vocab, recipe_vocab=recipe_vocab, device=DEVICE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate)\n",
        "\n",
        "    # ‚úÖ 4. AutoEncoder ÏÇ¨Ï†ÑÌïôÏäµ Ïó¨Î∂ÄÏóê Îî∞Îùº ÏÇ¨Ï†ÑÌïôÏäµ Ïã§Ìñâ (ingredient_vocab ÏÇ¨Ïö©)\n",
        "    if config.get(\"USE_AUTOENCODER\", False):\n",
        "        encoder_path = f\"results/{model_type}_encoder_pretrained.pt\"\n",
        "        if os.path.exists(encoder_path):\n",
        "            print(f\"AutoEncoder encoder weights already exist for {model_type}\")\n",
        "            pass\n",
        "        else:\n",
        "            print(f\"üì¶ AutoEncoder pretraining required for {model_type}\")\n",
        "            MakingAutoEncoder(\n",
        "                model_type=model_type,\n",
        "                config=config,\n",
        "                input_vocab=ingredient_vocab,\n",
        "                train_loader=train_loader_autoencoder,\n",
        "                embedding_weights=embedding_weights,\n",
        "                freeze_embedding=freeze_embedding,\n",
        "                device=DEVICE\n",
        "            )\n",
        "\n",
        "    # 5. Model Íµ¨ÏÑ± (recipe_vocab ÏÇ¨Ïö©)\n",
        "    INPUT_DIM = len(ingredient_vocab)\n",
        "    OUTPUT_DIM = len(recipe_vocab)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "\n",
        "    encoder, decoder = get_encoder_decoder(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=OUTPUT_DIM,\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze_embedding=freeze_embedding,\n",
        "        checklist_vocab=checklist_vocab,\n",
        "        tokenizer_checklist=tokenizer_checklist\n",
        "    )\n",
        "\n",
        "    # ‚úÖ 6. ÏÇ¨Ï†ÑÌïôÏäµÎêú AutoEncoder Ïù∏ÏΩîÎçî Í∞ÄÏ§ëÏπòÎßå Î°úÎìú\n",
        "    if config.get(\"USE_AUTOENCODER\", False):\n",
        "        encoder_path = f\"results/{model_type}_encoder_pretrained.pt\"\n",
        "        print(f\"üîÅ Loading pretrained AutoEncoder encoder weights for {model_type}\")\n",
        "        encoder.load_state_dict(torch.load(encoder_path, map_location=DEVICE))\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE, use_attention=config[\"USE_ATTENTION\"], recipe_vocab=recipe_vocab).to(DEVICE)\n",
        "\n",
        "    # 7. ÌïôÏäµ ÎòêÎäî Î°úÎìú\n",
        "    save_model_path = f\"results/{model_type}.pt\"\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    if config[\"new_model_train\"]:\n",
        "        print(f\"Training model: {model_type}\")\n",
        "        print(model)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config[\"LR\"])\n",
        "        loss_history = Train(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=dev_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            recipe_vocab=recipe_vocab,\n",
        "            EPOCHS=config[\"EPOCHS\"],\n",
        "            BATCH_SIZE=BATCH_SIZE,\n",
        "            TRAIN_RATIO=1.0,\n",
        "            save_model_path=save_model_path,\n",
        "            save_history_path=save_history_path,\n",
        "            TEACHER_FORCING_RATIO=config[\"TEACHER_FORCING_RATIO\"],\n",
        "            MAX_LEN=config[\"MAX_LEN\"],\n",
        "            LR_STEP=config.get(\"LR_STEP\"),\n",
        "            LR_GAMMA=config.get(\"LR_GAMMA\"),\n",
        "            USE_PENALTY=config.get(\"USE_PENALTY\", False),\n",
        "            PENALTY_LAMBDA=config.get(\"PENALTY_LAMBDA\", 0.2)\n",
        "        )\n",
        "        return model, encoder, decoder, loss_history, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab\n",
        "\n",
        "    else:\n",
        "        return model, encoder, decoder, None, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï†ÄÏû•\n",
        "experiment_configs = {\n",
        "    \"baseline1\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": False,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"baseline2\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 128,\n",
        "        \"HIDDEN_DIM\": 256,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 1,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 50,\n",
        "        \"BATCH_SIZE\": 64\n",
        "    },\n",
        "    \"mild_extension1\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 200,\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 2,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.7,\n",
        "        \"use_glove\": True,\n",
        "        \"freeze_embedding\": False,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"BATCH_SIZE\": 64,\n",
        "        \"USE_AUTOENCODER\": True,\n",
        "        \"AUTOENCODER_EPOCHS\": 5,\n",
        "    },\n",
        "    \"mild_extension2\": {\n",
        "        \"new_model_train\" : False,\n",
        "        \"EMBED_DIM\": 200,  # GloVe 6B 200DÏôÄ ÏùºÏπò\n",
        "        \"HIDDEN_DIM\": 512,\n",
        "        \"DROPOUT\": 0.5,\n",
        "        \"N_LAYERS\": 2,\n",
        "        \"LR\": 0.001,\n",
        "        \"EPOCHS\": 5,\n",
        "        \"USE_ATTENTION\": True,\n",
        "        \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "        \"MAX_LEN\": 100,\n",
        "        \"LR_STEP\": 1,         \n",
        "        \"LR_GAMMA\": 0.7,\n",
        "        \"use_glove\": True,   \n",
        "        \"freeze_embedding\": False,\n",
        "        \"BATCH_SIZE\": 64,\n",
        "        \"USE_AUTOENCODER\": True,\n",
        "        \"AUTOENCODER_EPOCHS\": 10,\n",
        "    },\n",
        "    \"spicy_extension1\": {\n",
        "    \"new_model_train\": False,\n",
        "    \"EMBED_DIM\": 256,\n",
        "    \"HIDDEN_DIM\": 512,\n",
        "    \"DROPOUT\": 0.5,\n",
        "    \"N_LAYERS\": 3,\n",
        "    \"LR\": 0.001,\n",
        "    \"EPOCHS\": 2,\n",
        "    \"USE_ATTENTION\": True,\n",
        "    \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "    \"MAX_LEN\": 100,\n",
        "    \"LR_STEP\": 1,\n",
        "    \"LR_GAMMA\": 0.7,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"USE_CHECKLIST\": True,       # checklist Î©îÏª§ÎãàÏ¶ò\n",
        "    \"USE_PENALTY\": True,         # coverage loss ÏÇ¨Ïö©\n",
        "    \"PENALTY_LAMBDA\": 0.2        # coverage loss Í∞ÄÏ§ëÏπò\n",
        "},\n",
        "\"spicy_extension2\": {\n",
        "    \"new_model_train\": False,\n",
        "    \"EMBED_DIM\": 256,\n",
        "    \"HIDDEN_DIM\": 512,\n",
        "    \"DROPOUT\": 0.5,\n",
        "    \"N_LAYERS\": 2,\n",
        "    \"LR\": 0.001,\n",
        "    \"EPOCHS\": 2,\n",
        "    \"USE_ATTENTION\": True,\n",
        "    \"TEACHER_FORCING_RATIO\": 0.5,\n",
        "    \"MAX_LEN\": 100,\n",
        "    \"LR_STEP\": 1,\n",
        "    \"LR_GAMMA\": 0.7,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"USE_CHECKLIST\": True,   # checklist attention\n",
        "    \"USE_COPY\": True         # copy mechanism\n",
        "}\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MakingAutoEncoder(model_type, config, input_vocab, train_loader,\n",
        "                      embedding_weights=None, freeze_embedding=False,device=DEVICE):\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "    INPUT_DIM = len(input_vocab)\n",
        "\n",
        "    # 1. Encoder / Decoder Ï§ÄÎπÑ (ÏûÖÎ†• = Ï∂úÎ†•)\n",
        "    encoder, decoder = get_encoder_decoder(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        input_dim=INPUT_DIM,\n",
        "        output_dim=INPUT_DIM,\n",
        "        embedding_weights=embedding_weights,\n",
        "        freeze_embedding=freeze_embedding\n",
        "    )\n",
        "\n",
        "    # 2. AutoEncoder Íµ¨ÏÑ±\n",
        "    autoencoder = IngredientAutoEncoder(encoder, decoder, vocab_size=INPUT_DIM).to(device)\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=config.get(\"LR\", 0.001))\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=input_vocab['<pad>'])\n",
        "\n",
        "    # 3. ÌïôÏäµ\n",
        "    print(f\"üöÄ Pretraining AutoEncoder for {model_type}\")\n",
        "    train_autoencoder(autoencoder, train_loader, criterion, optimizer,\n",
        "                      epochs=config.get(\"AUTOENCODER_EPOCHS\", 5), device=device)\n",
        "\n",
        "    # 4. Ï†ÄÏû•\n",
        "    torch.save(encoder.state_dict(), f\"results/{model_type}_encoder_pretrained.pt\")\n",
        "    torch.save(decoder.state_dict(), f\"results/{model_type}_decoder_pretrained.pt\")\n",
        "    print(f\"‚úÖ Saved pretrained encoder/decoder for {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_trained_model(model_type: str, config: dict, device=DEVICE):\n",
        "    \"\"\"\n",
        "    best modelÍ≥º final modelÏùÑ Î™®Îëê Î∂àÎü¨ÏòµÎãàÎã§.\n",
        "\n",
        "    Args:\n",
        "        model_type (str): Ï†ÄÏû• ÌååÏùº Ïù¥Î¶Ñ Í≤∞Ï†ïÏóê ÏÇ¨Ïö©ÎêòÎäî Î™®Îç∏ Ïù¥Î¶Ñ\n",
        "        config (dict): ÏÑ§Ï†ï Ï†ïÎ≥¥ (input_dim, output_dim, attention Îì± Ìè¨Ìï®)\n",
        "        device (torch.device): Î™®Îç∏ÏùÑ Î°úÎìúÌï† ÎîîÎ∞îÏù¥Ïä§\n",
        "\n",
        "    Returns:\n",
        "        best_model (nn.Module)\n",
        "        final_model (nn.Module)\n",
        "        loss_history (dict)\n",
        "        best_checkpoint (dict)\n",
        "        final_checkpoint (dict)\n",
        "    \"\"\"\n",
        "    # Í≤ΩÎ°ú Íµ¨ÏÑ±\n",
        "    best_model_path = f\"results/{model_type}.pt\"\n",
        "    final_model_path = best_model_path.replace(\".pt\", \"_final.pt\")\n",
        "    save_history_path = f\"results/{model_type}_history.pt\"\n",
        "\n",
        "    INPUT_DIM = config[\"input_dim\"]\n",
        "    OUTPUT_DIM = config[\"output_dim\"]\n",
        "    embedding_weights = config.get(\"embedding_weights\", None)\n",
        "    freeze_embedding = config.get(\"freeze_embedding\", False)\n",
        "    checklist_vocab = config.get(\"checklist_vocab\", None)\n",
        "    tokenizer_checklist = config.get(\"tokenizer_checklist\", None)\n",
        "    recipe_vocab = config[\"recipe_vocab\"]\n",
        "\n",
        "    def build_model():\n",
        "        encoder, decoder = get_encoder_decoder(\n",
        "            model_type=model_type,\n",
        "            config=config,\n",
        "            input_dim=INPUT_DIM,\n",
        "            output_dim=OUTPUT_DIM,\n",
        "            embedding_weights=embedding_weights,\n",
        "            freeze_embedding=freeze_embedding,\n",
        "            checklist_vocab=checklist_vocab,\n",
        "            tokenizer_checklist=tokenizer_checklist\n",
        "        )\n",
        "        return Seq2Seq(encoder, decoder, device, use_attention=config[\"USE_ATTENTION\"], recipe_vocab=recipe_vocab).to(device)\n",
        "\n",
        "    # ‚úÖ Best model\n",
        "    best_model = build_model()\n",
        "    best_checkpoint = torch.load(best_model_path, map_location=device)\n",
        "    best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    # ‚úÖ Final model\n",
        "    final_model = build_model()\n",
        "    final_checkpoint = torch.load(final_model_path, map_location=device)\n",
        "    final_model.load_state_dict(final_checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    # ‚úÖ ÌïôÏäµ Ïù¥Î†•\n",
        "    history = torch.load(save_history_path, map_location=device)\n",
        "    loss_history = history[\"loss_history\"]\n",
        "\n",
        "    print(f\"üì• Loaded BEST model (Epoch {best_checkpoint['epoch']})\")\n",
        "    print(f\"üì• Loaded FINAL model (Epoch {final_checkpoint['epoch']})\")\n",
        "\n",
        "    return best_model, final_model, loss_history, best_checkpoint, final_checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_and_test_model(model_type: str,\n",
        "                             config: dict,\n",
        "                             ingredient_vocab,\n",
        "                             recipe_vocab,\n",
        "                             test_loader,\n",
        "                             criterion,\n",
        "                             tokenizer_checklist=None,\n",
        "                             checklist_vocab=None,\n",
        "                             embedding_weights=None,\n",
        "                             device=DEVICE):\n",
        "    \"\"\"\n",
        "    Ï†ÄÏû•Îêú best/final Î™®Îç∏ÏùÑ Î∂àÎü¨ÏôÄ summary, Í∑∏ÎûòÌîÑ, ÌÖåÏä§Ìä∏ ÏàòÌñâ\n",
        "    \"\"\"\n",
        "\n",
        "    # configÏóê input/output dim Îì± ÌïÑÏöîÌïú Ï†ïÎ≥¥ Ï∂îÍ∞Ä (ÏõêÎ≥∏ ÏÜêÏÉÅ X)\n",
        "    config = config.copy()\n",
        "    config[\"input_dim\"] = len(ingredient_vocab)\n",
        "    config[\"output_dim\"] = len(recipe_vocab)\n",
        "    config[\"recipe_vocab\"] = recipe_vocab\n",
        "    config[\"embedding_weights\"] = embedding_weights\n",
        "    config[\"checklist_vocab\"] = checklist_vocab\n",
        "    config[\"tokenizer_checklist\"] = tokenizer_checklist\n",
        "\n",
        "    # ‚úÖ Î™®Îç∏ Îëê Í∞ú Î™®Îëê Î∂àÎü¨Ïò§Í∏∞\n",
        "    best_model, final_model, loss_history, best_ckpt, final_ckpt = load_trained_model(\n",
        "        model_type, config, device\n",
        "    )\n",
        "\n",
        "    # ‚úÖ ÏÜêÏã§ Í≥°ÏÑ† ÏãúÍ∞ÅÌôî\n",
        "    plot_loss_epoch(model_type, loss_history)\n",
        "\n",
        "    # ‚úÖ BEST Î™®Îç∏ ÌèâÍ∞Ä\n",
        "    print(f\"\\n========== BEST MODEL SUMMARY ({model_type}) ==========\")\n",
        "    print(f\"Epoch:         {best_ckpt['epoch']}\")\n",
        "    print(f\"Train Loss:    {best_ckpt['train_loss']:.4f}\")\n",
        "    print(f\"Val Loss:      {best_ckpt['val_loss']:.4f}\")\n",
        "    print(f\"Parameters:    {sum(p.numel() for p in best_model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    print(\"\\nRunning test on BEST model...\")\n",
        "    best_test_loss, best_bleu, best_meteor, best_bert = Test(\n",
        "        best_model, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"]\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- BEST MODEL TEST RESULTS ---\")\n",
        "    print(f\"Test Loss    : {best_test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score : {best_bleu:.4f}\")\n",
        "    print(f\"METEOR Score : {best_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1 : {best_bert:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # ‚úÖ FINAL Î™®Îç∏ ÌèâÍ∞Ä\n",
        "    print(f\"\\n========== FINAL MODEL SUMMARY ({model_type}) ==========\")\n",
        "    print(f\"Epoch:         {final_ckpt['epoch']}\")\n",
        "    print(f\"Train Loss:    {final_ckpt['train_loss']:.4f}\")\n",
        "    print(f\"Val Loss:      {final_ckpt['val_loss']:.4f}\")\n",
        "    print(f\"Parameters:    {sum(p.numel() for p in final_model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    print(\"\\nRunning test on FINAL model...\")\n",
        "    final_test_loss, final_bleu, final_meteor, final_bert = Test(\n",
        "        final_model, test_loader, criterion, recipe_vocab, MAX_LEN=config[\"MAX_LEN\"]\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- FINAL MODEL TEST RESULTS ---\")\n",
        "    print(f\"Test Loss    : {final_test_loss:.4f}\")\n",
        "    print(f\"BLEU-4 Score : {final_bleu:.4f}\")\n",
        "    print(f\"METEOR Score : {final_meteor:.4f}\")\n",
        "    print(f\"BERTScore-F1 : {final_bert:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return {\n",
        "        \"best\": {\n",
        "            \"test_loss\": best_test_loss,\n",
        "            \"BLEU\": best_bleu,\n",
        "            \"METEOR\": best_meteor,\n",
        "            \"BERTScore\": best_bert,\n",
        "        },\n",
        "        \"final\": {\n",
        "            \"test_loss\": final_test_loss,\n",
        "            \"BLEU\": final_bleu,\n",
        "            \"METEOR\": final_meteor,\n",
        "            \"BERTScore\": final_bert,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================== üîß Training & Evaluating: baseline1 ==================\n",
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "‚ö†Ô∏è Checkpoint for baseline1 not found. Skipping evaluation.\n",
            "\n",
            "\n",
            "================== üîß Training & Evaluating: baseline2 ==================\n",
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "‚ö†Ô∏è Checkpoint for baseline2 not found. Skipping evaluation.\n",
            "\n",
            "\n",
            "================== üîß Training & Evaluating: mild_extension1 ==================\n",
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "‚ö†Ô∏è Checkpoint for mild_extension1 not found. Skipping evaluation.\n",
            "\n",
            "\n",
            "================== üîß Training & Evaluating: mild_extension2 ==================\n",
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "üîé Using GloVe embeddings for mild_extension2\n",
            "üîé Loading GloVe vectors...\n",
            "‚úÖ GloVe embedding matrix created.\n",
            "üì¶ AutoEncoder pretraining required for mild_extension2\n",
            "üöÄ Pretraining AutoEncoder for mild_extension2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:   0%|          | 0/2546 [00:00<?, ?it/s]/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "Epoch 1/10:  15%|‚ñà‚ñç        | 374/2546 [16:15<1:51:35,  3.08s/it]"
          ]
        }
      ],
      "source": [
        "for model_type, base_config in experiment_configs.items():\n",
        "    print(f\"\\n================== üîß Training & Evaluating: {model_type} ==================\")\n",
        "\n",
        "    # ‚úÖ config Î≥µÏÇ¨ Î∞è ÏÑ§Ï†ï\n",
        "    config = base_config.copy()\n",
        "\n",
        "    # main Ïã§Ìñâ\n",
        "    model, encoder, decoder, _, save_model_path, save_history_path, test_loader, recipe_vocab, ingredient_vocab = main(\n",
        "        model_type, config, train_df, dev_df, test_df\n",
        "    )\n",
        "\n",
        "    # ‚úÖ configÏóê ÌïÑÏöîÌïú Ï†ïÎ≥¥ Ï∂îÍ∞Ä\n",
        "    config[\"input_dim\"] = len(ingredient_vocab)\n",
        "    config[\"output_dim\"] = len(recipe_vocab)\n",
        "    config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "    # optional: GloVe embeddingÏù¥ ÏÇ¨Ïö©ÎêòÏóàÎã§Î©¥ Ï†ÑÎã¨\n",
        "    config[\"embedding_weights\"] = config.get(\"embedding_weights\", None)\n",
        "\n",
        "    # optional: checklist/copy Í¥ÄÎ†® ÌÇ§ Ï∂îÍ∞Ä\n",
        "    config[\"checklist_vocab\"] = config.get(\"checklist_vocab\", None)\n",
        "    config[\"tokenizer_checklist\"] = config.get(\"tokenizer_checklist\", None)\n",
        "\n",
        "    # üî∏ ÌååÏùº Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
        "    if not os.path.exists(save_model_path) or not os.path.exists(save_history_path):\n",
        "        print(f\"‚ö†Ô∏è Checkpoint for {model_type} not found. Skipping evaluation.\\n\")\n",
        "        continue\n",
        "\n",
        "    # ÏÜêÏã§ Ìï®Ïàò Ï†ïÏùò\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=recipe_vocab['<pad>'])\n",
        "\n",
        "    # ÌèâÍ∞Ä Ïã§Ìñâ\n",
        "    summarize_and_test_model(\n",
        "        model_type=model_type,\n",
        "        config=config,\n",
        "        ingredient_vocab=ingredient_vocab,\n",
        "        recipe_vocab=recipe_vocab,\n",
        "        test_loader=test_loader,\n",
        "        criterion=criterion,\n",
        "        checklist_vocab=config.get(\"checklist_vocab\"),\n",
        "        tokenizer_checklist=config.get(\"tokenizer_checklist\"),\n",
        "        embedding_weights=config.get(\"embedding_weights\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot for all model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def plot_loss_iter_multi(model_list, experiment_configs, device=DEVICE):\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "    \n",
        "#     for model_type in model_list:\n",
        "#         config = experiment_configs[model_type].copy()\n",
        "#         ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "#             load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "    \n",
        "#         config[\"input_dim\"] = len(ingredient_vocab)\n",
        "#         config[\"output_dim\"] = len(recipe_vocab)\n",
        "#         config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "#         # üì• Î™®Îç∏, Í∏∞Î°ù Î∂àÎü¨Ïò§Í∏∞\n",
        "#         _, _, loss_history, _, _ = load_trained_model(model_type, config, device)\n",
        "#         train_iter_loss = loss_history[\"train_iter\"]  # Î¶¨Ïä§Ìä∏ of Î¶¨Ïä§Ìä∏\n",
        "\n",
        "#         # Î¶¨Ïä§Ìä∏ ÌèâÌÉÑÌôî (iteration Í∏∞Ï§Ä)\n",
        "#         iter_losses = [loss for epoch_losses in train_iter_loss for loss in epoch_losses]\n",
        "#         plt.plot(iter_losses, label=model_type)\n",
        "\n",
        "#     plt.title(\"Training Loss per Iteration\")\n",
        "#     plt.xlabel(\"Iteration\")\n",
        "#     plt.ylabel(\"Loss\")\n",
        "#     plt.legend()\n",
        "#     plt.grid(True)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def smooth(values, window=100):\n",
        "    return np.convolve(values, np.ones(window)/window, mode='valid')\n",
        "\n",
        "def plot_loss_iter_multi(model_list, experiment_configs, device=DEVICE):\n",
        "    plt.style.use(\"seaborn-v0_8\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for model_type in model_list:\n",
        "        config = experiment_configs[model_type].copy()\n",
        "        ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "            load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "\n",
        "        config[\"input_dim\"] = len(ingredient_vocab)\n",
        "        config[\"output_dim\"] = len(recipe_vocab)\n",
        "        config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "        _, _, loss_history, _, _ = load_trained_model(model_type, config, device)\n",
        "        train_iter_loss = loss_history[\"train_iter\"]\n",
        "\n",
        "        iter_losses = [loss for epoch in train_iter_loss for loss in epoch]\n",
        "        smoothed = smooth(iter_losses, window=100)\n",
        "\n",
        "        plt.plot(smoothed, label=model_type, linewidth=2)\n",
        "\n",
        "    plt.title(\"Smoothed Training Loss per Iteration\", fontsize=14)\n",
        "    plt.xlabel(\"Iteration\", fontsize=12)\n",
        "    plt.ylabel(\"Loss\", fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/baseline1.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_loss_iter_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbaseline1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbaseline2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_configs\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[21], line 48\u001b[0m, in \u001b[0;36mplot_loss_iter_multi\u001b[0;34m(model_list, experiment_configs, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(recipe_vocab)\n\u001b[1;32m     46\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipe_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m recipe_vocab\n\u001b[0;32m---> 48\u001b[0m _, _, loss_history, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m train_iter_loss \u001b[38;5;241m=\u001b[39m loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     51\u001b[0m iter_losses \u001b[38;5;241m=\u001b[39m [loss \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m train_iter_loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m epoch]\n",
            "Cell \u001b[0;32mIn[18], line 45\u001b[0m, in \u001b[0;36mload_trained_model\u001b[0;34m(model_type, config, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ‚úÖ Best model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m best_model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[0;32m---> 45\u001b[0m best_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m best_model\u001b[38;5;241m.\u001b[39mload_state_dict(best_checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# ‚úÖ Final model\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/baseline1.pt'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss_iter_multi(\n",
        "    model_list=[\"baseline1\", \"baseline2\"],\n",
        "    experiment_configs=experiment_configs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes(sample_raw, model_names, experiment_configs):\n",
        "    \"\"\"\n",
        "    Ïó¨Îü¨ Î™®Îç∏ÏùÑ Î∂àÎü¨ÏôÄ Ï£ºÏñ¥ÏßÑ inputÏóê ÎåÄÌï¥ recipeÎ•º ÏÉùÏÑ±ÌïòÎäî Ìï®Ïàò\n",
        "    \"\"\"\n",
        "    # üßæ ÏûÖÎ†•ÏùÑ Î¶¨Ïä§Ìä∏Î°ú Ï†ïÎ¶¨\n",
        "    if isinstance(sample_raw, str):\n",
        "        ingredient_list = [i.strip() for i in sample_raw.split(',')]\n",
        "    elif isinstance(sample_raw, list):\n",
        "        ingredient_list = sample_raw\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a comma-separated string or a list.\")\n",
        "\n",
        "    print(f\"üßæ Ingredients: {ingredient_list}\")\n",
        "\n",
        "    results = {}\n",
        "    for model_type in model_names:\n",
        "        print(f\"\\nüîç Generating with model: {model_type}\")\n",
        "        config = experiment_configs[model_type].copy()\n",
        "\n",
        "        # ‚úÖ vocab, tokenizer Î∂àÎü¨Ïò§Í∏∞\n",
        "        ingredient_token_lists, recipe_token_lists, ingredient_vocab, recipe_vocab, tokenizer_ing, tokenizer_rec, checklist_vocab, tokenizer_checklist = \\\n",
        "            load_or_tokenize_data(model_type, pd.DataFrame(), config)\n",
        "\n",
        "        config[\"input_dim\"] = len(ingredient_vocab)\n",
        "        config[\"output_dim\"] = len(recipe_vocab)\n",
        "        config[\"recipe_vocab\"] = recipe_vocab\n",
        "\n",
        "        # ‚úÖ Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
        "        _, final_model, _, _, _ = load_trained_model(model_type, config, device=DEVICE)\n",
        "\n",
        "        # ‚úÖ ingredient_list ‚Üí Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò ÌõÑ ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï\n",
        "        ingredient_str = str(ingredient_list)\n",
        "        tokenized = tokenizer_ing(ingredient_str)\n",
        "        input_ids = torch.tensor([ingredient_vocab[token] for token in tokenized], dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        # ‚úÖ ÏòàÏ∏°\n",
        "        final_model.eval()\n",
        "        with torch.no_grad():\n",
        "            prediction_ids = final_model(input_ids, ingredient_texts=[ingredient_list], target=None)\n",
        "\n",
        "        # ‚úÖ ÎîîÏΩîÎî©\n",
        "        pred_tokens = [recipe_vocab.lookup_token(tok.item()) for tok in prediction_ids[0]]\n",
        "        recipe = ' '.join([\n",
        "            t for t in pred_tokens \n",
        "            if t not in [ '', ',', '[', ']', '\"'] # '<pad>', '<sos>', '<eos>',\n",
        "        ]).strip()\n",
        "        results[model_type] = recipe\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßæ Ingredients: ['8 oz philadelphia cream cheese', '14 oz can sweetened condensed milk', '1 ts vanilla', '1/3 c  lemon juice', '48 oz canned cherries', '8 inch graham cracker', 'pie crusts']\n",
            "\n",
            "üîç Generating with model: baseline1\n",
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "üì• Loaded BEST model (Epoch 4)\n",
            "üì• Loaded FINAL model (Epoch 5)\n",
            "\n",
            "üîç Generating with model: baseline2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded ingredient token cache.\n",
            "‚úÖ Loaded recipe token cache.\n",
            "üì• Loaded BEST model (Epoch 3)\n",
            "üì• Loaded FINAL model (Epoch 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeeeunkim/Desktop/FIT5217_NLP/NLP/.venv/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Model: baseline1\n",
            "üçΩÔ∏è Recipe: combine first 5 ingredients in a large saucepan . stir in milk\n",
            "--------------------------------------------------\n",
            "\n",
            "üß† Model: baseline2\n",
            "üçΩÔ∏è Recipe: in a large bowl combine cream cheese milk add milk and milk . beat until smooth . add in milk and beat until smooth . fold in whipped cream .\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "sample1_raw = \"sugar, lemon juice,  water,  orange juice, strawberries, icecream\"\n",
        "sample2_raw = \"8 oz philadelphia cream cheese, 14 oz can sweetened condensed milk, 1 ts vanilla, 1/3 c  lemon juice, 48 oz canned cherries, 8 inch graham cracker,  pie crusts\"\n",
        "\n",
        "# ÏòàÏãú config\n",
        "model_names = [\"baseline1\", \"baseline2\"]\n",
        "results = generate_recipes(sample2_raw, model_names, experiment_configs)\n",
        "\n",
        "for model, recipe in results.items():\n",
        "    print(f\"\\nüß† Model: {model}\\nüçΩÔ∏è Recipe: {recipe}\")\n",
        "    print(\"-\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fill in the XLSX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_recipes_from_excel(xlsx_path, output_path, model_names, experiment_configs):\n",
        "    df = pd.read_excel(xlsx_path)\n",
        "\n",
        "    # Í≤∞Í≥º Ïª¨Îüº Ï¥àÍ∏∞Ìôî\n",
        "    for model in model_names:\n",
        "        col_name = f\"Recipe - {model}\"\n",
        "        if col_name not in df.columns:\n",
        "            df[col_name] = \"\"\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Recipes\"):\n",
        "        try:\n",
        "            ingredient_raw = row[\"Ingredients\"]\n",
        "            ingredient_list = ast.literal_eval(ingredient_raw) if isinstance(ingredient_raw, str) else ingredient_raw\n",
        "            results = generate_recipes(\n",
        "                sample_raw=ingredient_list,\n",
        "                model_names=model_names,\n",
        "                tokenizer_ingredient=None,  # ÎÇ¥Î∂ÄÏóêÏÑú Ï≤òÎ¶¨\n",
        "                experiment_configs=experiment_configs\n",
        "            )\n",
        "            for model in model_names:\n",
        "                df.at[i, f\"Recipe - {model}\"] = results.get(model, \"\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error at row {i}: {e}\")\n",
        "\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"‚úÖ Saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xlsx_path = \"recipes_input.xlsx\"\n",
        "output_path = \"recipes_output.xlsx\"\n",
        "model_names = [\"Baseline 1\", \"Mild Ext 1\", \"Spicy Ext 1\"]\n",
        "generate_recipes_from_excel(xlsx_path, output_path, model_names, experiment_configs)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
